# ADR-007: Cluster Autoscaler Strategy

**Status:** ‚úÖ APPROVED
**Data:** 2026-01-28
**Decisores:** DevOps Team + Claude Sonnet 4.5
**Tags:** `autoscaling`, `kubernetes`, `cost-optimization`, `eks`

---

## Contexto

Com a plataforma Kubernetes operacional (Marco 2 Fases 1-5 completas), precis√°vamos implementar **auto-scaling de nodes** para:
- Reduzir custos durante per√≠odos de baixa demanda (noites, fins de semana)
- Escalar automaticamente quando workloads exigirem mais recursos
- Manter alta disponibilidade sem provisionamento excessivo
- Otimizar utiliza√ß√£o de nodes (FinOps)

**Situa√ß√£o Atual:**
- 7 nodes rodando 24/7 (2 system + 3 workloads + 2 critical)
- Node group "workloads" com demanda vari√°vel (3 nodes fixos)
- Custo mensal: ~$550 (nodes sempre ligados)
- Possibilidade de economia: ~15-30% com scale-down inteligente

---

## Decis√£o

**Implementar Cluster Autoscaler com escopo limitado ao node group "workloads"**

### Componentes da Solu√ß√£o

| Componente | Tecnologia | Justificativa |
|------------|------------|---------------|
| **Autoscaler** | Kubernetes Cluster Autoscaler v1.31.x | Maturidade, n√£o invasivo, compat√≠vel com ASGs existentes |
| **IAM** | IRSA (IAM Roles for Service Accounts) | Least privilege, sem access keys |
| **IaC** | Terraform Helm module | Versionamento, reprodutibilidade |
| **Escopo** | Node group "workloads" apenas | Minimizar risco, proteger nodes cr√≠ticos |

---

## Alternativas Consideradas

### ‚ùå Op√ß√£o 1: Karpenter (Substituir Cluster Autoscaler)

**Rejeitada:**
- üî¥ **Invasivo:** Substitui Auto Scaling Groups por Custom Resources (CRDs)
- üî¥ **Migra√ß√£o complexa:** Requer refatora√ß√£o dos node groups existentes
- üü° **Maturidade:** Relativamente novo (2 anos em produ√ß√£o)
- ‚úÖ **Performance:** Excelente (< 10s para provisionar nodes)
- ‚úÖ **Spot Instances:** Suporte nativo avan√ßado

**Decis√£o:** Considerar Karpenter em Marco 4 (futuro) ap√≥s validar Cluster Autoscaler

---

### ‚ùå Op√ß√£o 2: Manual Scaling (AWS CLI/Scripts)

**Rejeitada:**
- üî¥ **Overhead operacional:** Requer monitoramento manual
- üî¥ **Reativo:** N√£o escala automaticamente baseado em pending pods
- üü° **Scheduled Scaling:** Funciona apenas para padr√µes previs√≠veis
- ‚úÖ **Custo zero:** Sem componentes adicionais

**Decis√£o:** Insuficiente para demanda din√¢mica de workloads

---

### ‚úÖ Op√ß√£o 3: Cluster Autoscaler (ESCOLHIDA)

**Aprovada:**
- ‚úÖ **N√£o invasivo:** Trabalha com ASGs existentes sem refatora√ß√£o
- ‚úÖ **Maturidade:** Produ√ß√£o-ready h√° 5+ anos (CNCF graduated project)
- ‚úÖ **Simplicidade:** Configura√ß√£o via Helm chart + IAM policy
- ‚úÖ **Revers√≠vel:** Pode desabilitar sem breaking changes
- ‚úÖ **Observabilidade:** M√©tricas Prometheus integradas
- üü° **Performance:** Bom (30-60s para provisionar nodes)

---

## Configura√ß√£o Implementada

### Node Groups e Autoscaling

| Node Group | Tipo | Min | Max | Desired | Autoscaling | Raz√£o |
|------------|------|-----|-----|---------|-------------|-------|
| **system** | t3.medium | 2 | 4 | 2 | ‚ùå DESABILITADO | Servi√ßos de sistema precisam estar sempre dispon√≠veis |
| **workloads** | t3.large | 2 | 6 | 3 | ‚úÖ HABILITADO | Carga vari√°vel, pode escalar com demanda |
| **critical** | t3.xlarge | 2 | 4 | 2 | ‚ùå DESABILITADO | Stateful workloads (bancos de dados, Prometheus) |

### Pol√≠ticas de Scaling

```yaml
Scale-Up:
  Trigger: Pods em Pending por falta de recursos
  Timing: 30-60 segundos
  Strategy: least-waste (escolhe tipo de node mais econ√¥mico)

Scale-Down:
  Trigger: Node com < 50% utiliza√ß√£o por 10 minutos
  Timing: Ap√≥s 10 minutos de baixa utiliza√ß√£o
  Delay ap√≥s scale-up: 10 minutos (evita flapping)
  Max graceful termination: 600 segundos (10 minutos)
```

### IAM Policy (Least Privilege)

```json
{
  "Effect": "Allow",
  "Action": [
    "autoscaling:SetDesiredCapacity",
    "autoscaling:TerminateInstanceInAutoScalingGroup"
  ],
  "Resource": "*",
  "Condition": {
    "StringEquals": {
      "autoscaling:ResourceTag/k8s.io/cluster-autoscaler/k8s-platform-prod": "owned"
    }
  }
}
```

**Seguran√ßa:** Policy s√≥ permite modificar ASGs com tag espec√≠fica do cluster.

---

## Tagging de Auto Scaling Groups

### ASG "workloads" (Autoscaling ENABLED)

```hcl
tags = {
  "k8s.io/cluster-autoscaler/enabled"                = "true"
  "k8s.io/cluster-autoscaler/k8s-platform-prod"      = "owned"
}
```

### ASGs "system" e "critical" (Autoscaling DISABLED)

```hcl
tags = {
  "k8s.io/cluster-autoscaler/enabled"                = "false"
  "k8s.io/cluster-autoscaler/k8s-platform-prod"      = "disabled"
}
```

---

## Impacto

### Custo (Economia Esperada)

**Cen√°rio Base:** 3 nodes workloads 24/7
- Custo mensal: 3 nodes √ó $44 √ó 730h = $132/m√™s

**Cen√°rio com Autoscaling:** Scale-down durante baixa demanda
- Hor√°rio comercial (8h-18h, seg-sex): 3 nodes (50 horas/semana)
- Noite/fim de semana: 2 nodes (118 horas/semana)
- **Economia:** ~1 node desligado 70% do tempo = ~$31/m√™s (**23% economia**)
- **Economia anual:** ~$372/ano

**ROI:**
- Custo de implementa√ß√£o: $0 (apenas configura√ß√£o)
- Payback: Imediato
- Economia acumulada 12 meses: $372

### Seguran√ßa (Benef√≠cios)

- ‚úÖ IRSA pattern: Sem access keys expostas
- ‚úÖ Least privilege: IAM policy restrita por tags
- ‚úÖ Auditoria: CloudTrail registra todas as scaling actions
- ‚úÖ Network Policies: Cluster Autoscaler respeitando egress rules

### Seguran√ßa (Riscos Mitigados)

| Risco | Probabilidade | Impacto | Mitiga√ß√£o Implementada |
|-------|---------------|---------|------------------------|
| **IAM sobre-permissivo** | BAIXO | ALTO | Policy com condition baseada em tags |
| **Scale-down agressivo (quebra servi√ßos)** | M√âDIO | M√âDIO | Thresholds conservadores (50% utiliza√ß√£o, 10min) |
| **Flapping (scale up/down r√°pido)** | BAIXO | M√âDIO | Delay de 10 min ap√≥s scale-up antes de scale-down |
| **Cluster Autoscaler pod down (sem scaling)** | BAIXO | M√âDIO | Priority class: system-cluster-critical |

---

## Riscos e Limita√ß√µes

### Limita√ß√µes Conhecidas

1. **‚ö†Ô∏è Scale-up delay:** 30-60 segundos para provisionar novos nodes
   - **Impacto:** Pods ficam Pending temporariamente
   - **Mitiga√ß√£o:** Configurar min=2 nodes (sempre dispon√≠veis)

2. **‚ö†Ô∏è Stateful pods bloqueiam scale-down:**
   - Pods com PersistentVolumeClaims ou local storage impedem remo√ß√£o de nodes
   - **Mitiga√ß√£o:** Usar node affinity para fixar stateful pods em node group "critical"

3. **‚ö†Ô∏è N√£o otimiza custos de Spot Instances:**
   - Cluster Autoscaler funciona com On-Demand apenas
   - **Futuro:** Migrar para Karpenter (suporte nativo a Spot)

### M√©tricas de Monitoramento

```promql
# Nodes gerenciados pelo Cluster Autoscaler
cluster_autoscaler_nodes_count{state="ready"}

# Pods aguardando scale-up
cluster_autoscaler_unschedulable_pods_count

# Opera√ß√µes de scaling (success/fail)
cluster_autoscaler_scaled_up_nodes_total
cluster_autoscaler_scaled_down_nodes_total
cluster_autoscaler_failed_scale_ups_total
```

---

## Valida√ß√£o P√≥s-Deploy

### Checklist de Sucesso ‚úÖ

- [ ] Cluster Autoscaler pod Running em node group "system"
- [ ] Service Account com annotation `eks.amazonaws.com/role-arn`
- [ ] IAM Role com trust policy OIDC v√°lida
- [ ] ASG "workloads" com tags corretas
- [ ] Logs sem erros de permiss√£o IAM
- [ ] Prometheus ServiceMonitor criado
- [ ] M√©tricas `cluster_autoscaler_*` dispon√≠veis

### Testes de Valida√ß√£o

**Teste 1: Scale-Up (Deploy workload que exige > 3 nodes)**
```bash
kubectl apply -f test-scale-up.yaml
# Esperar: New node provisionado em ~60s
kubectl get nodes --watch
```

**Teste 2: Scale-Down (Deletar workload, aguardar 10min)**
```bash
kubectl delete -f test-scale-up.yaml
# Esperar: Node removido ap√≥s 10 min de baixa utiliza√ß√£o
kubectl get nodes --watch
```

**Teste 3: Verificar Logs**
```bash
kubectl logs -n kube-system -l app.kubernetes.io/name=cluster-autoscaler --tail=100
# Buscar: "Expanding scale up" ou "Attempting to scale down"
```

---

## Pr√≥ximos Passos

### Curto Prazo (1-2 semanas)
1. [ ] **Deploy Cluster Autoscaler via Terraform** (Marco 2 Fase 6)
2. [ ] **Aplicar tags nos ASGs do Marco 1** (habilitar discovery)
3. [ ] **Executar testes de scale-up e scale-down**
4. [ ] **Monitorar m√©tricas por 7 dias** - Validar economia e estabilidade

### M√©dio Prazo (1-3 meses)
5. [ ] **Dashboard Grafana** - Visualizar scale events e economia
6. [ ] **Alertas Prometheus** - Notificar scale-up failures
7. [ ] **Scheduled Scaling (opcional)** - Pre-scaling durante hor√°rio comercial

### Longo Prazo (6+ meses)
8. [ ] **Avaliar Karpenter** - Migra√ß√£o quando Spot Instances forem necess√°rios
9. [ ] **Cluster Autoscaler em nodes critical?** - Ap√≥s validar estabilidade
10. [ ] **HPA (Horizontal Pod Autoscaler)** - Complementar com scaling de pods

---

## Refer√™ncias

- [Kubernetes Cluster Autoscaler GitHub](https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler)
- [Cluster Autoscaler AWS Provider](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/README.md)
- [EKS Best Practices - Autoscaling](https://aws.github.io/aws-eks-best-practices/cluster-autoscaling/)
- [Cluster Autoscaler FAQ](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md)
- [Karpenter vs Cluster Autoscaler](https://aws.amazon.com/blogs/containers/amazon-eks-cluster-autoscaler-vs-karpenter/)

---

**Decis√£o tomada em:** 2026-01-28
**Implementado em:** Marco 2 - Fase 6
**Pr√≥xima revis√£o:** Ap√≥s 7 dias de monitoramento (2026-02-04)

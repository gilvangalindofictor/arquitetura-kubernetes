# Plano de ExecuÃ§Ã£o AWS - Plataforma Kubernetes Corporativa

**VersÃ£o:** 1.1
**Data:** 2026-01-22 (atualizado com novas prÃ¡ticas de autenticaÃ§Ã£o AWS)
**Projeto:** Arquitetura Multi-DomÃ­nio Kubernetes
**RegiÃ£o Principal:** us-east-1 (N. Virginia)
**Ambientes:** HomologaÃ§Ã£o + ProduÃ§Ã£o

---

## 1ï¸âƒ£ VisÃ£o Geral da EstratÃ©gia Cloud

### Arquitetura Escolhida

**Amazon EKS (Elastic Kubernetes Service)** como plataforma de orquestraÃ§Ã£o para hospedar os 6 domÃ­nios da plataforma corporativa de engenharia:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           AWS CLOUD (us-east-1)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         VPC (10.0.0.0/16)                        â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚   â”‚
â”‚  â”‚  â”‚  AZ-1a       â”‚  â”‚  AZ-1b       â”‚  â”‚  AZ-1c       â”‚          â”‚   â”‚
â”‚  â”‚  â”‚ Public Sub   â”‚  â”‚ Public Sub   â”‚  â”‚ Public Sub   â”‚          â”‚   â”‚
â”‚  â”‚  â”‚ 10.0.1.0/24  â”‚  â”‚ 10.0.2.0/24  â”‚  â”‚ 10.0.3.0/24  â”‚          â”‚   â”‚
â”‚  â”‚  â”‚ (NAT + ALB)  â”‚  â”‚              â”‚  â”‚              â”‚          â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚   â”‚
â”‚  â”‚  â”‚ Private Sub  â”‚  â”‚ Private Sub  â”‚  â”‚ Private Sub  â”‚          â”‚   â”‚
â”‚  â”‚  â”‚ 10.0.11.0/24 â”‚  â”‚ 10.0.12.0/24 â”‚  â”‚ 10.0.13.0/24 â”‚          â”‚   â”‚
â”‚  â”‚  â”‚ (EKS Nodes)  â”‚  â”‚ (EKS Nodes)  â”‚ â”‚ (EKS Nodes)  â”‚          â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚   â”‚
â”‚  â”‚  â”‚ DB Subnet    â”‚  â”‚ DB Subnet    â”‚  â”‚ DB Subnet    â”‚          â”‚   â”‚
â”‚  â”‚  â”‚ 10.0.21.0/24 â”‚  â”‚ 10.0.22.0/24 â”‚  â”‚ 10.0.23.0/24 â”‚          â”‚   â”‚
â”‚  â”‚  â”‚ (RDS/Cache)  â”‚  â”‚ (RDS/Cache)  â”‚ â”‚ (RDS/Cache)  â”‚          â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    AMAZON EKS CLUSTER                            â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚
â”‚  â”‚  â”‚ system      â”‚  â”‚ workloads   â”‚  â”‚ critical    â”‚              â”‚   â”‚
â”‚  â”‚  â”‚ t3.medium   â”‚  â”‚ t3.large    â”‚  â”‚ t3.xlarge   â”‚              â”‚   â”‚
â”‚  â”‚  â”‚ 2 nodes     â”‚  â”‚ 3 nodes     â”‚  â”‚ 2 nodes     â”‚              â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ RDS         â”‚  â”‚ ElastiCache â”‚  â”‚ S3          â”‚  â”‚ Route53     â”‚   â”‚
â”‚  â”‚ PostgreSQL  â”‚  â”‚ Redis       â”‚  â”‚ Buckets     â”‚  â”‚ DNS         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Justificativa TÃ©cnica

| DecisÃ£o | Justificativa |
|---------|---------------|
| **EKS** | Kubernetes gerenciado, integraÃ§Ã£o nativa com IAM, ALB, CloudWatch |
| **Multi-AZ** | Alta disponibilidade obrigatÃ³ria para produÃ§Ã£o |
| **Node Groups separados** | Isolamento de workloads (system, workloads, critical) |
| **RDS PostgreSQL** | HA Multi-AZ, backups automÃ¡ticos, performance otimizada |
| **S3** | Storage ilimitado para backups, logs, artifacts |

### ServiÃ§os AWS Envolvidos

| ServiÃ§o | PropÃ³sito | Criticidade |
|---------|-----------|-------------|
| **VPC** | Rede isolada e segmentada | Alta |
| **EKS** | Cluster Kubernetes gerenciado | Alta |
| **EC2** | Node Groups do EKS | Alta |
| **RDS** | PostgreSQL para GitLab, Keycloak, SonarQube | Alta |
| **ElastiCache** | Redis para cache e sessÃµes | MÃ©dia |
| **S3** | Backups, logs, artifacts, Terraform state | Alta |
| **ALB** | Load Balancer para ingress | Alta |
| **Route53** | DNS gerenciado | Alta |
| **IAM** | Identidade e polÃ­ticas | Alta |
| **KMS** | Criptografia de dados | Alta |
| **CloudWatch** | Logs e mÃ©tricas AWS | MÃ©dia |
| **Secrets Manager** | Secrets sensÃ­veis | Alta |
| **WAF** | ProteÃ§Ã£o de aplicaÃ§Ãµes web | MÃ©dia |
| **ACM** | Certificados TLS | Alta |

---

## 2ï¸âƒ£ Arquitetura AWS (NÃ­vel LÃ³gico)

### Componentes e RelaÃ§Ãµes

```
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚   Route53   â”‚
                                    â”‚   DNS       â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                                    â”‚     WAF     â”‚
                                    â”‚  (Firewall) â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                                    â”‚     ALB     â”‚
                                    â”‚ (Ingress)   â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                    VPC   â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                              EKS Cluster                                     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚                        NAMESPACES / DOMÃNIOS                         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ platform-core â”‚  â”‚ observability â”‚  â”‚ cicd-platform â”‚            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  - Kong       â”‚  â”‚  - Prometheus â”‚  â”‚  - GitLab     â”‚            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  - Keycloak   â”‚  â”‚  - Grafana    â”‚  â”‚  - ArgoCD     â”‚            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  - Linkerd    â”‚  â”‚  - Loki       â”‚  â”‚  - Harbor     â”‚            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  - Ingress    â”‚  â”‚  - Tempo      â”‚  â”‚  - SonarQube  â”‚            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ data-services â”‚  â”‚ secrets-mgmt  â”‚  â”‚ security      â”‚            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  - PostgreSQL â”‚  â”‚  - Vault      â”‚  â”‚  - Kyverno    â”‚            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  - Redis Op   â”‚  â”‚  - ESO        â”‚  â”‚  - Falco      â”‚            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  - RabbitMQ   â”‚  â”‚               â”‚  â”‚  - Trivy      â”‚            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  - Velero     â”‚  â”‚               â”‚  â”‚               â”‚            â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚ RDS PostgreSQL  â”‚  â”‚ ElastiCache     â”‚  â”‚ S3 Buckets      â”‚                    â”‚
â”‚  â”‚ (Multi-AZ)      â”‚  â”‚ (Redis Cluster) â”‚  â”‚ - backups       â”‚                    â”‚
â”‚  â”‚ - gitlab        â”‚  â”‚ - gitlab-cache  â”‚  â”‚ - artifacts     â”‚                    â”‚
â”‚  â”‚ - keycloak      â”‚  â”‚ - sessions      â”‚  â”‚ - logs          â”‚                    â”‚
â”‚  â”‚ - sonarqube     â”‚  â”‚                 â”‚  â”‚ - terraform     â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### SeparaÃ§Ã£o de Ambientes

| Recurso | HomologaÃ§Ã£o (staging) | ProduÃ§Ã£o (prod) |
|---------|----------------------|-----------------|
| **VPC** | `vpc-staging` (10.1.0.0/16) | `vpc-prod` (10.0.0.0/16) |
| **EKS Cluster** | `k8s-platform-staging` | `k8s-platform-prod` |
| **Node Count** | 3 nodes (mÃ­nimo) | 7 nodes (mÃ­nimo) |
| **RDS** | db.t3.small, Single-AZ | db.t3.medium, Multi-AZ |
| **Disponibilidade** | HorÃ¡rio comercial (scheduled) | 24/7 |
| **Backup** | 3 dias | 7 dias |

### ConsideraÃ§Ãµes de SeguranÃ§a

| Camada | Controle | ImplementaÃ§Ã£o |
|--------|----------|---------------|
| **Identidade** | IAM com menor privilÃ©gio | Roles especÃ­ficas por serviÃ§o |
| **Rede** | SegmentaÃ§Ã£o VPC | Public/Private/DB subnets |
| **TrÃ¡fego** | Security Groups | Regras especÃ­ficas por porta |
| **AplicaÃ§Ã£o** | WAF | ProteÃ§Ã£o OWASP Top 10 |
| **Dados** | KMS | Criptografia at-rest e in-transit |
| **Secrets** | Secrets Manager | RotaÃ§Ã£o automÃ¡tica |
| **Auditoria** | CloudTrail | Logs de todas as aÃ§Ãµes |

---

## 3ï¸âƒ£ Passo a Passo no Console da AWS (MUITO DETALHADO)

### ðŸ”¹ ServiÃ§o: IAM (Identity and Access Management)

> **Contexto:** Criar roles e polÃ­ticas ANTES de qualquer outro recurso. PrincÃ­pio de menor privilÃ©gio Ã© obrigatÃ³rio.

#### 3.1.1 Criar PolÃ­tica para EKS Cluster

**Passo a passo no console:**

1. Acesse o Console AWS: https://console.aws.amazon.com/
2. Na barra de busca superior, digite `IAM` e clique em **IAM**
3. No menu lateral esquerdo, clique em **Policies**
4. Clique no botÃ£o **Create policy** (azul, canto superior direito)
5. Selecione a aba **JSON**
6. Cole a seguinte polÃ­tica:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "EKSClusterPolicy",
            "Effect": "Allow",
            "Action": [
                "eks:*",
                "ec2:DescribeSubnets",
                "ec2:DescribeSecurityGroups",
                "ec2:DescribeVpcs",
                "iam:GetRole",
                "iam:PassRole"
            ],
            "Resource": "*",
            "Condition": {
                "StringEquals": {
                    "aws:RequestedRegion": "us-east-1"
                }
            }
        }
    ]
}
```

7. Clique em **Next**
8. Preencha os campos:
   - **Policy name:** `k8s-platform-eks-policy`
   - **Description:** `PolAtica-para-gerenciamento-do-cluster-EKS-da-plataforma-Kubernetes`
   - **Tags:**
     - `Project` = `k8s-platform`
     - `Environment` = `shared`
     - `Owner` = `devops-team`
     - `CostCenter` = `infrastructure`
9. Clique em **Create policy**

---

#### 3.1.2 Criar Role para EKS Cluster

**Passo a passo no console:**

1. No IAM, menu lateral, clique em **Roles**
2. Clique em **Create role**
3. Em **Trusted entity type**, selecione **AWS service**
4. Em **Use case**, selecione **EKS** â†’ **EKS - Cluster**
5. Clique em **Next**
6. As polÃ­ticas `AmazonEKSClusterPolicy` jÃ¡ estarÃ£o selecionadas
7. Clique em **Next**
8. Preencha:
   - **Role name:** `k8s-platform-eks-cluster-role`
   - **Description:** `Role-para-o-cluster-EKS-da-plataforma-Kubernetes-corporativa`
   - **Tags:**
     - `Project` = `k8s-platform`
     - `Environment` = `prod`
     - `Owner` = `devops-team`
9. Clique em **Create role**

---

#### 3.1.3 Criar Role para EKS Node Group

**Passo a passo no console:**

1. Em **Roles**, clique em **Create role**
2. Selecione **AWS service** â†’ **EC2**
3. Clique em **Next**
4. Busque e selecione as seguintes polÃ­ticas:
   - `AmazonEKSWorkerNodePolicy`
   - `AmazonEKS_CNI_Policy`
   - `AmazonEC2ContainerRegistryReadOnly`
   - `AmazonSSMManagedInstanceCore` (para acesso via Session Manager)
5. Clique em **Next**
6. Preencha:
   - **Role name:** `k8s-platform-eks-node-role`
   - **Description:** `Role-para-os-Node-Groups-do-EKS`
   - **Tags:** (mesmas tags anteriores)
7. Clique em **Create role**

---

#### 3.1.4 Configurar AutenticaÃ§Ã£o AWS CLI

> **âš ï¸ ATUALIZAÃ‡ÃƒO IMPORTANTE (2026):** A AWS recomenda NÃƒO usar Access Keys para pessoas. Prefira sempre AWS CloudShell ou IAM Identity Center (SSO).

**Escolha UMA das opÃ§Ãµes abaixo:**

---

**OPÃ‡ÃƒO 1: AWS CloudShell (RECOMENDADA para testes rÃ¡pidos)**

1. Acesse o Console AWS: https://console.aws.amazon.com/
2. No **canto superior direito**, clique no Ã­cone `>_` (CloudShell)
3. Aguarde inicializaÃ§Ã£o (10-30 segundos)
4. Teste a conexÃ£o:

```bash
aws sts get-caller-identity
```

**Vantagens:**
- âœ… Zero configuraÃ§Ã£o
- âœ… Credenciais automÃ¡ticas do console
- âœ… Sem risco de vazamento de Access Keys

---

**OPÃ‡ÃƒO 2: IAM Identity Center (SSO) - Para uso diÃ¡rio**

1. Na barra de busca, digite `IAM Identity Center`
2. Clique em **Enable** (primeira vez)
3. Configure MFA como obrigatÃ³rio
4. Crie grupo `k8s-platform-admins`
5. Adicione usuÃ¡rios ao grupo
6. Crie permission set `K8sPlatformPowerUser`
7. Configure AWS CLI V2 localmente:

```bash
aws configure sso
# SSO start URL: https://sua-empresa.awsapps.com/start
# SSO Region: us-east-1
# CLI profile name: k8s-platform-prod
```

**Vantagens:**
- âœ… IntegraÃ§Ã£o com Azure AD/Okta
- âœ… MFA obrigatÃ³rio
- âœ… Credenciais temporÃ¡rias

---

**OPÃ‡ÃƒO 3: Access Keys (APENAS para CI/CD ou Terraform)**

> **âš ï¸ USE APENAS PARA:** Pipelines CI/CD (GitHub Actions, GitLab CI), Terraform automatizado

1. Em **Users**, clique em **Create user**
2. Preencha:
   - **User name:** `terraform-k8s-platform`
   - **Provide user access to console:** âŒ NÃƒO marque
3. Clique em **Next**
4. Selecione **Attach policies directly**
5. Busque e selecione:
   - `PowerUserAccess` (temporÃ¡rio, restringir depois)
6. Clique em **Next** â†’ **Create user**
7. Clique no usuÃ¡rio criado
8. Aba **Security credentials** â†’ **Create access key**
9. Selecione **Command Line Interface (CLI)**
10. Marque o checkbox de confirmaÃ§Ã£o
11. Clique em **Next** â†’ **Create access key**
12. **ARMAZENE COM SEGURANÃ‡A:**

```bash
# OpÃ§Ã£o A: AWS Secrets Manager (RECOMENDADO)
aws secretsmanager create-secret \
    --name k8s-platform/terraform/aws-credentials \
    --secret-string '{
        "access_key_id": "AKIAIOSFODNN7EXAMPLE",
        "secret_access_key": "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
    }' \
    --kms-key-id alias/k8s-platform-prod

# OpÃ§Ã£o B: Arquivo local ~/.aws/credentials
cat > ~/.aws/credentials <<EOF
[k8s-platform-terraform]
aws_access_key_id = AKIAIOSFODNN7EXAMPLE
aws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
EOF
chmod 600 ~/.aws/credentials
```

**âš ï¸ ROTAÃ‡ÃƒO OBRIGATÃ“RIA:** Rotacione Access Keys a cada 90 dias

```bash
# Criar nova key
aws iam create-access-key --user-name terraform-k8s-platform

# Deletar key antiga
aws iam delete-access-key --user-name terraform-k8s-platform --access-key-id AKIAOLDKEY
```

---

### ðŸ”¹ ServiÃ§o: VPC (Virtual Private Cloud)

> **Contexto:** A VPC isola toda a infraestrutura. SegmentaÃ§Ã£o em subnets pÃºblicas, privadas e de banco de dados Ã© essencial para seguranÃ§a.

#### 3.2.1 Criar VPC com Wizard

**Passo a passo no console:**

1. Na barra de busca, digite `VPC` e clique em **VPC**
2. Clique em **Create VPC**
3. Selecione **VPC and more** (wizard completo)
4. Preencha os campos:

   **Name tag auto-generation:**
   - **Auto-generate:** Marque
   - **Name:** `k8s-platform-prod`

   **IPv4 CIDR block:**
   - **IPv4 CIDR:** `10.0.0.0/16`

   **IPv6 CIDR block:**
   - Selecione **No IPv6 CIDR block**

   **Tenancy:**
   - Selecione **Default**

   **Number of Availability Zones:**
   - Selecione **3**

   **Number of public subnets:**
   - Selecione **3**

   **Number of private subnets:**
   - Selecione **3**

   **NAT gateways:**
   - Selecione **In 1 AZ** (economia de custo - para prod HA use "1 per AZ")

   **VPC endpoints:**
   - Selecione **S3 Gateway**

   **DNS options:**
   - âœ… **Enable DNS hostnames**
   - âœ… **Enable DNS resolution**

5. Revise o diagrama gerado automaticamente
6. Clique em **Create VPC**
7. Aguarde a criaÃ§Ã£o (2-3 minutos)

---

#### 3.2.2 Criar Subnets de Banco de Dados

**Passo a passo no console:**

1. No VPC Dashboard, menu lateral, clique em **Subnets**
2. Clique em **Create subnet**
3. Preencha:

   **VPC ID:** Selecione `k8s-platform-prod-vpc`

   **Subnet 1:**
   - **Subnet name:** `k8s-platform-prod-db-us-east-1a`
   - **Availability Zone:** `us-east-1a`
   - **IPv4 CIDR block:** `10.0.21.0/24`

4. Clique em **Add new subnet**

   **Subnet 2:**
   - **Subnet name:** `k8s-platform-prod-db-us-east-1b`
   - **Availability Zone:** `us-east-1b`
   - **IPv4 CIDR block:** `10.0.22.0/24`

5. Clique em **Add new subnet**

   **Subnet 3:**
   - **Subnet name:** `k8s-platform-prod-db-us-east-1c`
   - **Availability Zone:** `us-east-1c`
   - **IPv4 CIDR block:** `10.0.23.0/24`

6. Clique em **Create subnet**

---

#### 3.2.3 Criar Subnet Group para RDS

**Passo a passo no console:**

1. Na barra de busca, digite `RDS` e clique em **RDS**
2. Menu lateral, clique em **Subnet groups**
3. Clique em **Create DB subnet group**
4. Preencha:
   - **Name:** `k8s-platform-prod-db-subnet-group`
   - **Description:** `Subnet-group-para-RDS-da-plataforma-Kubernetes`
   - **VPC:** Selecione `k8s-platform-prod-vpc`

   **Add subnets:**
   - **Availability Zones:** Selecione `us-east-1a`, `us-east-1b`, `us-east-1c`
   - **Subnets:** Selecione as 3 subnets de DB criadas (10.0.21.0/24, 10.0.22.0/24, 10.0.23.0/24)

5. Clique em **Create**

---

#### 3.2.4 Adicionar Tags nas Subnets para EKS

**Passo a passo no console:**

1. Volte para **VPC** â†’ **Subnets**
2. Selecione TODAS as subnets **privadas** (uma por vez)
3. Clique na aba **Tags**
4. Clique em **Manage tags**
5. Adicione as tags:

   | Key | Value |
   |-----|-------|
   | `kubernetes.io/cluster/k8s-platform-prod` | `shared` |
   | `kubernetes.io/role/internal-elb` | `1` |

6. Repita para as subnets **pÃºblicas** com tags diferentes:

   | Key | Value |
   |-----|-------|
   | `kubernetes.io/cluster/k8s-platform-prod` | `shared` |
   | `kubernetes.io/role/elb` | `1` |

---

### ðŸ”¹ ServiÃ§o: Security Groups

> **Contexto:** Security Groups atuam como firewall stateful. Cada componente deve ter seu prÃ³prio SG com regras mÃ­nimas necessÃ¡rias.

#### 3.3.1 Criar Security Group para EKS Cluster

**Passo a passo no console:**

1. Em **VPC** â†’ **Security groups**
2. Clique em **Create security group**
3. Preencha:
   - **Security group name:** `k8s-platform-prod-eks-cluster-sg`
   - **Description:** `Security-Group-para-o-EKS-Control-Plane`
   - **VPC:** Selecione `k8s-platform-prod-vpc`

4. **Inbound rules:** (deixe vazio por enquanto, serÃ¡ configurado automaticamente pelo EKS)

5. **Outbound rules:**
   - **Type:** All traffic
   - **Destination:** 0.0.0.0/0

6. **Tags:**
   - `Name` = `k8s-platform-prod-eks-cluster-sg`
   - `Project` = `k8s-platform`

7. Clique em **Create security group**

---

#### 3.3.2 Criar Security Group para RDS

**Passo a passo no console:**

1. Clique em **Create security group**
2. Preencha:
   - **Security group name:** `k8s-platform-prod-rds-sg`
   - **Description:** `Security-Group-para-RDS-PostgreSQL`
   - **VPC:** Selecione `k8s-platform-prod-vpc`

3. **Inbound rules:**
   - Clique em **Add rule**
   - **Type:** PostgreSQL
   - **Port:** 5432
   - **Source:** Custom â†’ Selecione `k8s-platform-prod-eks-cluster-sg`
   - **Description:** `Acesso-do-EKS-ao-RDS`

4. **Outbound rules:**
   - **Type:** All traffic
   - **Destination:** 0.0.0.0/0

5. **Tags:**
   - `Name` = `k8s-platform-prod-rds-sg`
   - `Project` = `k8s-platform`

6. Clique em **Create security group**

---

#### 3.3.3 Criar Security Group para ElastiCache

**Passo a passo no console:**

1. Clique em **Create security group**
2. Preencha:
   - **Security group name:** `k8s-platform-prod-redis-sg`
   - **Description:** `Security-Group-para-ElastiCache-Redis`
   - **VPC:** Selecione `k8s-platform-prod-vpc`

3. **Inbound rules:**
   - **Type:** Custom TCP
   - **Port:** 6379
   - **Source:** `k8s-platform-prod-eks-cluster-sg`
   - **Description:** `Acesso-do-EKS-ao-Redis`

4. Clique em **Create security group**

---

### ðŸ”¹ ServiÃ§o: S3 (Simple Storage Service)

> **Contexto:** S3 armazenarÃ¡ backups, logs, artifacts do GitLab/Harbor e o Terraform state. Versionamento e criptografia sÃ£o obrigatÃ³rios.

#### 3.4.1 Criar Bucket para Terraform State

**Passo a passo no console:**

1. Na barra de busca, digite `S3` e clique em **S3**
2. Clique em **Create bucket**
3. Preencha:

   **General configuration:**
   - **Bucket name:** `k8s-platform-terraform-state-{account-id}` (substitua {account-id} pelo seu ID de conta)
   - **AWS Region:** `us-east-1`

   **Object Ownership:**
   - Selecione **ACLs disabled (recommended)**

   **Block Public Access settings:**
   - âœ… **Block all public access** (OBRIGATÃ“RIO)

   **Bucket Versioning:**
   - Selecione **Enable**

   **Default encryption:**
   - **Encryption type:** Server-side encryption with Amazon S3 managed keys (SSE-S3)
   - **Bucket Key:** Enable

4. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `shared`
   - `Purpose` = `terraform-state`

5. Clique em **Create bucket**

---

#### 3.4.2 Criar Bucket para Backups

**Passo a passo no console:**

1. Clique em **Create bucket**
2. Preencha:
   - **Bucket name:** `k8s-platform-backups-prod-{account-id}`
   - **AWS Region:** `us-east-1`
   - âœ… **Block all public access**
   - **Versioning:** Enable
   - **Encryption:** SSE-S3

3. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`
   - `Purpose` = `backups`

4. Clique em **Create bucket**

---

#### 3.4.3 Configurar Lifecycle Policy (Economia)

**Passo a passo no console:**

1. Clique no bucket `k8s-platform-backups-prod-{account-id}`
2. Aba **Management**
3. Clique em **Create lifecycle rule**
4. Preencha:
   - **Lifecycle rule name:** `backup-lifecycle-policy`
   - **Rule scope:** Apply to all objects in the bucket

   **Lifecycle rule actions:**
   - âœ… **Move current versions of objects between storage classes**
   - âœ… **Move noncurrent versions of objects between storage classes**
   - âœ… **Permanently delete noncurrent versions of objects**

   **Transitions:**
   - After 30 days â†’ **Standard-IA**
   - After 90 days â†’ **Glacier Instant Retrieval**
   - After 365 days â†’ **Glacier Deep Archive**

   **Noncurrent version expiration:**
   - After 90 days

5. Clique em **Create rule**

---

#### 3.4.4 Criar Bucket para GitLab Artifacts

**Passo a passo no console:**

1. Clique em **Create bucket**
2. Preencha:
   - **Bucket name:** `k8s-platform-gitlab-artifacts-{account-id}`
   - **AWS Region:** `us-east-1`
   - âœ… **Block all public access**
   - **Versioning:** Disable (artifacts sÃ£o efÃªmeros)
   - **Encryption:** SSE-S3

3. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`
   - `Purpose` = `gitlab-artifacts`

4. Clique em **Create bucket**

---

### ðŸ”¹ ServiÃ§o: KMS (Key Management Service)

> **Contexto:** KMS gerencia chaves de criptografia. Uma chave dedicada para a plataforma permite controle de acesso granular e auditoria.

#### 3.5.1 Criar Customer Managed Key

**Passo a passo no console:**

1. Na barra de busca, digite `KMS` e clique em **Key Management Service**
2. Clique em **Create key**
3. Preencha:

   **Configure key:**
   - **Key type:** Symmetric
   - **Key usage:** Encrypt and decrypt
   - **Advanced options:**
     - **Key material origin:** KMS (AWS KMS key material)
     - **Regionality:** Single-Region key

4. Clique em **Next**

   **Add labels:**
   - **Alias:** `alias/k8s-platform-prod`
   - **Description:** `Chave-de-criptografia-para-a-plataforma-Kubernetes`
   - **Tags:**
     - `Project` = `k8s-platform`
     - `Environment` = `prod`

5. Clique em **Next**

   **Define key administrative permissions:**
   - Selecione os usuÃ¡rios/roles que podem administrar a chave
   - Adicione `terraform-k8s-platform` (usuÃ¡rio criado anteriormente)

6. Clique em **Next**

   **Define key usage permissions:**
   - Adicione as roles:
     - `k8s-platform-eks-cluster-role`
     - `k8s-platform-eks-node-role`

7. Clique em **Next** â†’ **Finish**

---

### ðŸ”¹ ServiÃ§o: RDS (PostgreSQL)

> **Contexto:** RDS PostgreSQL hospedarÃ¡ os bancos de dados do GitLab, Keycloak e SonarQube. Multi-AZ garante alta disponibilidade em produÃ§Ã£o.

#### 3.6.1 Criar InstÃ¢ncia RDS PostgreSQL

**Passo a passo no console:**

1. Na barra de busca, digite `RDS` e clique em **RDS**
2. Clique em **Create database**
3. Preencha:

   **Choose a database creation method:**
   - Selecione **Standard create**

   **Engine options:**
   - **Engine type:** PostgreSQL
   - **Engine version:** PostgreSQL 15.4-R2 (ou mais recente LTS)

   **Templates:**
   - Selecione **Production**

   **Availability and durability:**
   - Selecione **Multi-AZ DB instance** (para prod)

   **Settings:**
   - **DB instance identifier:** `k8s-platform-prod-postgresql`
   - **Master username:** `postgres_admin`
   - **Credentials management:** Self managed
   - **Master password:** (gere uma senha forte de 32+ caracteres)
   - **Confirm password:** (repita a senha)

   **Instance configuration:**
   - **DB instance class:** Burstable classes (includes t classes)
   - Selecione **db.t3.medium** (2 vCPU, 4 GB RAM)

   **Storage:**
   - **Storage type:** General Purpose SSD (gp3)
   - **Allocated storage:** 100 GB
   - **Storage autoscaling:** âœ… Enable
   - **Maximum storage threshold:** 500 GB

   **Connectivity:**
   - **Compute resource:** Don't connect to an EC2 compute resource
   - **Network type:** IPv4
   - **VPC:** `k8s-platform-prod-vpc`
   - **DB subnet group:** `k8s-platform-prod-db-subnet-group`
   - **Public access:** **No**
   - **VPC security group:** Choose existing
   - **Existing VPC security groups:** Selecione `k8s-platform-prod-rds-sg`
   - **Availability Zone:** No preference

   **Database authentication:**
   - Selecione **Password authentication**

   **Monitoring:**
   - âœ… **Enable Enhanced monitoring**
   - **Monitoring Role:** Create new role
   - **Granularity:** 60 seconds

   **Additional configuration:**
   - **Initial database name:** `platform`
   - **DB parameter group:** default.postgres15
   - **Backup:**
     - âœ… **Enable automated backups**
     - **Backup retention period:** 7 days
     - **Backup window:** Select window â†’ `03:00-04:00 UTC`
   - **Encryption:**
     - âœ… **Enable encryption**
     - **AWS KMS key:** Selecione `alias/k8s-platform-prod`
   - **Log exports:** (selecione todos)
     - âœ… PostgreSQL log
     - âœ… Upgrade log
   - **Maintenance:**
     - âœ… **Enable auto minor version upgrade**
     - **Maintenance window:** Select window â†’ `sun:04:00-sun:05:00 UTC`
   - **Deletion protection:**
     - âœ… **Enable deletion protection**

4. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`
   - `Owner` = `devops-team`
   - `CostCenter` = `infrastructure`

5. Clique em **Create database**
6. Aguarde a criaÃ§Ã£o (10-15 minutos)

---

#### 3.6.2 Criar Databases Individuais

**Passo a passo no console:**

ApÃ³s a instÃ¢ncia estar disponÃ­vel, conecte via cliente PostgreSQL (pgAdmin, DBeaver, ou psql via bastion host) e execute:

```sql
-- Criar databases para cada serviÃ§o
CREATE DATABASE gitlab_production;
CREATE DATABASE keycloak;
CREATE DATABASE sonarqube;
CREATE DATABASE harbor;

-- Criar usuÃ¡rios especÃ­ficos (princÃ­pio de menor privilÃ©gio)
CREATE USER gitlab_user WITH ENCRYPTED PASSWORD 'senha_segura_gitlab_32chars';
CREATE USER keycloak_user WITH ENCRYPTED PASSWORD 'senha_segura_keycloak_32chars';
CREATE USER sonarqube_user WITH ENCRYPTED PASSWORD 'senha_segura_sonar_32chars';
CREATE USER harbor_user WITH ENCRYPTED PASSWORD 'senha_segura_harbor_32chars';

-- Conceder privilÃ©gios
GRANT ALL PRIVILEGES ON DATABASE gitlab_production TO gitlab_user;
GRANT ALL PRIVILEGES ON DATABASE keycloak TO keycloak_user;
GRANT ALL PRIVILEGES ON DATABASE sonarqube TO sonarqube_user;
GRANT ALL PRIVILEGES ON DATABASE harbor TO harbor_user;
```

---

### ðŸ”¹ ServiÃ§o: ElastiCache (Redis)

> **Contexto:** Redis serÃ¡ usado como cache para GitLab e sessÃµes do Keycloak. Cluster mode oferece melhor performance e disponibilidade.

#### 3.7.1 Criar Cluster ElastiCache Redis

**Passo a passo no console:**

1. Na barra de busca, digite `ElastiCache` e clique em **ElastiCache**
2. Clique em **Create cluster** â†’ **Create Redis cluster**
3. Preencha:

   **Cluster creation method:**
   - Selecione **Configure and create a new cluster**

   **Cluster mode:**
   - Selecione **Disabled** (para simplificar, ou Enabled para escala)

   **Cluster info:**
   - **Name:** `k8s-platform-prod-redis`
   - **Description:** `Redis-cache-para-plataforma-Kubernetes`

   **Location:**
   - Selecione **AWS Cloud**

   **Multi-AZ:**
   - âœ… **Enable** (para produÃ§Ã£o)

   **Auto-failover:**
   - âœ… **Enable**

   **Node type:**
   - **Family:** t3
   - **Node type:** `cache.t3.medium`

   **Number of replicas:**
   - `2` (1 primary + 2 replicas = 3 nodes)

   **Subnet group settings:**
   - **Subnet group:** Create new
   - **Name:** `k8s-platform-prod-redis-subnet-group`
   - **VPC ID:** `k8s-platform-prod-vpc`
   - **Subnets:** Selecione as 3 subnets de DB

   **Availability Zone placements:**
   - Deixe como **No preference**

   **Security:**
   - **Security groups:** Selecione `k8s-platform-prod-redis-sg`
   - **Encryption at-rest:** âœ… **Enable**
   - **Encryption key:** `alias/k8s-platform-prod`
   - **Encryption in-transit:** âœ… **Enable**

   **Logs:**
   - âœ… **Slow logs**
   - **Log format:** JSON
   - **Destination:** CloudWatch Logs
   - **Log group:** `/aws/elasticache/k8s-platform-prod-redis`

   **Backup:**
   - âœ… **Enable automatic backups**
   - **Backup retention period:** 7 days
   - **Backup window:** `05:00-06:00 UTC`

   **Maintenance:**
   - **Maintenance window:** `sun:06:00-sun:07:00 UTC`
   - âœ… **Auto upgrade minor versions**

4. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`

5. Clique em **Create**

---

### ðŸ”¹ ServiÃ§o: EKS (Elastic Kubernetes Service)

> **Contexto:** EKS Ã© o coraÃ§Ã£o da plataforma. Node Groups separados permitem isolamento de workloads e otimizaÃ§Ã£o de recursos.

#### 3.8.1 Criar Cluster EKS

**Passo a passo no console:**

1. Na barra de busca, digite `EKS` e clique em **Elastic Kubernetes Service**
2. Clique em **Add cluster** â†’ **Create**
3. Preencha:

   **Step 1 - Configure cluster:**

   **Name:**
   - **Name:** `k8s-platform-prod`

   **Kubernetes version:**
   - Selecione a versÃ£o mais recente estÃ¡vel (ex: 1.29)

   **Cluster service role:**
   - Selecione `k8s-platform-eks-cluster-role`

   **Secrets encryption:**
   - âœ… **Turn on envelope encryption of Kubernetes secrets**
   - **KMS key:** `alias/k8s-platform-prod`

   **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`
   - `Owner` = `devops-team`

4. Clique em **Next**

   **Step 2 - Specify networking:**

   **VPC:**
   - Selecione `k8s-platform-prod-vpc`

   **Subnets:**
   - Selecione TODAS as subnets privadas:
     - `k8s-platform-prod-subnet-private1-us-east-1a`
     - `k8s-platform-prod-subnet-private2-us-east-1b`
     - `k8s-platform-prod-subnet-private3-us-east-1c`

   **Security groups:**
   - Selecione `k8s-platform-prod-eks-cluster-sg`

   **Cluster endpoint access:**
   - Selecione **Public and private**

   **Advanced settings:**
   - **Public access CIDR:** Adicione apenas os IPs permitidos (ex: IP do seu escritÃ³rio)

5. Clique em **Next**

   **Step 3 - Configure observability:**

   **Control plane logging:**
   - âœ… **API server**
   - âœ… **Audit**
   - âœ… **Authenticator**
   - âœ… **Controller manager**
   - âœ… **Scheduler**

6. Clique em **Next**

   **Step 4 - Select add-ons:**

   Selecione os add-ons padrÃ£o:
   - âœ… **Amazon VPC CNI** (networking)
   - âœ… **CoreDNS** (DNS interno)
   - âœ… **kube-proxy** (network proxy)
   - âœ… **Amazon EBS CSI Driver** (storage)

7. Clique em **Next**

   **Step 5 - Configure selected add-ons settings:**
   - Deixe as configuraÃ§Ãµes padrÃ£o para todos os add-ons
   - Selecione a versÃ£o mais recente de cada um

8. Clique em **Next** â†’ **Create**

9. Aguarde a criaÃ§Ã£o (15-20 minutos)

---

#### 3.8.2 Criar Node Group: system

**Passo a passo no console:**

1. ApÃ³s o cluster estar `Active`, clique no nome do cluster
2. Aba **Compute** â†’ **Add node group**
3. Preencha:

   **Step 1 - Configure node group:**

   **Name:**
   - **Name:** `system`
   - **Node IAM role:** Selecione `k8s-platform-eks-node-role`

   **Node group scaling configuration:**
   - **Desired size:** 2
   - **Minimum size:** 2
   - **Maximum size:** 4

   **Node group update configuration:**
   - **Maximum unavailable:** Number â†’ 1

   **Labels:**
   - `node-type` = `system`
   - `workload` = `platform`

   **Taints:** (deixe vazio para system nodes)

   **Tags:**
   - `Project` = `k8s-platform`
   - `NodeGroup` = `system`

4. Clique em **Next**

   **Step 2 - Set compute and scaling configuration:**

   **AMI type:**
   - Selecione **Amazon Linux 2 (AL2_x86_64)**

   **Capacity type:**
   - Selecione **On-Demand**

   **Instance types:**
   - Selecione **t3.medium**

   **Disk size:**
   - `30` GB

5. Clique em **Next**

   **Step 3 - Specify networking:**

   **Subnets:**
   - Selecione as 3 subnets privadas

   **Configure remote access to nodes:**
   - Selecione **Don't allow remote access to nodes** (use Session Manager)

6. Clique em **Next** â†’ **Create**

---

#### 3.8.3 Criar Node Group: workloads

**Passo a passo no console:**

1. Clique em **Add node group**
2. Preencha:

   **Name:** `workloads`
   **Node IAM role:** `k8s-platform-eks-node-role`

   **Scaling:**
   - **Desired:** 3
   - **Min:** 2
   - **Max:** 6

   **Labels:**
   - `node-type` = `workloads`
   - `workload` = `applications`

   **Instance types:** `t3.large`
   **Disk size:** `50` GB

3. Complete os passos e clique em **Create**

---

#### 3.8.4 Criar Node Group: critical

**Passo a passo no console:**

1. Clique em **Add node group**
2. Preencha:

   **Name:** `critical`
   **Node IAM role:** `k8s-platform-eks-node-role`

   **Scaling:**
   - **Desired:** 2
   - **Min:** 2
   - **Max:** 4

   **Labels:**
   - `node-type` = `critical`
   - `workload` = `databases`

   **Taints:**
   - **Key:** `workload`
   - **Value:** `critical`
   - **Effect:** `NoSchedule`

   **Instance types:** `t3.xlarge`
   **Disk size:** `100` GB

3. Complete os passos e clique em **Create**

---

#### 3.8.5 Configurar kubectl para Acessar o Cluster

**Passo a passo via terminal:**

```bash
# Instalar AWS CLI V2 (se nÃ£o tiver)
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install

# Verificar versÃ£o
aws --version  # Deve ser >= 2.x
```

**Escolha o mÃ©todo de autenticaÃ§Ã£o:**

**MÃ‰TODO 1: AWS CloudShell (sem configuraÃ§Ã£o local)**

```bash
# Abra CloudShell no console AWS (Ã­cone >_)
# JÃ¡ vem com kubectl instalado

# Atualizar kubeconfig
aws eks update-kubeconfig --region us-east-1 --name k8s-platform-prod

# Verificar conexÃ£o
kubectl get nodes
```

---

**MÃ‰TODO 2: SSO (IAM Identity Center) - Recomendado para desenvolvedores**

```bash
# Configurar SSO (uma vez)
aws configure sso
# SSO start URL: https://sua-empresa.awsapps.com/start
# SSO Region: us-east-1
# CLI profile name: k8s-platform-prod

# Login (quando expirar)
aws sso login --profile k8s-platform-prod

# Atualizar kubeconfig com perfil SSO
aws eks update-kubeconfig \
    --region us-east-1 \
    --name k8s-platform-prod \
    --profile k8s-platform-prod

# Verificar conexÃ£o
kubectl get nodes
```

---

**MÃ‰TODO 3: Access Keys (CI/CD ou Terraform)**

```bash
# Configurar credenciais manualmente
cat > ~/.aws/credentials <<EOF
[k8s-platform-terraform]
aws_access_key_id = AKIAIOSFODNN7EXAMPLE
aws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
EOF
chmod 600 ~/.aws/credentials

cat > ~/.aws/config <<EOF
[profile k8s-platform-terraform]
region = us-east-1
output = json
EOF

# OU usar variÃ¡veis de ambiente
export AWS_ACCESS_KEY_ID="AKIAIOSFODNN7EXAMPLE"
export AWS_SECRET_ACCESS_KEY="wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
export AWS_DEFAULT_REGION="us-east-1"

# Atualizar kubeconfig
aws eks update-kubeconfig \
    --region us-east-1 \
    --name k8s-platform-prod \
    --profile k8s-platform-terraform  # Omitir se usando variÃ¡veis de ambiente

# Verificar conexÃ£o
kubectl get nodes
```

---

### ðŸ”¹ ServiÃ§o: ALB (Application Load Balancer)

> **Contexto:** O ALB serÃ¡ gerenciado pelo AWS Load Balancer Controller instalado no EKS. Ele cria ALBs automaticamente para Ingress resources.

#### 3.9.1 Instalar AWS Load Balancer Controller

**Passo a passo via terminal:**

```bash
# âš ï¸ IMPORTANTE: Use o mesmo perfil AWS configurado anteriormente
# Se usando SSO: aws sso login --profile k8s-platform-prod
# Se usando Access Keys: export AWS_PROFILE=k8s-platform-terraform

# Obter Account ID
export ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
echo "Account ID: $ACCOUNT_ID"

# Criar IAM Policy para o controller
curl -o iam_policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.7.0/docs/install/iam_policy.json

aws iam create-policy \
    --policy-name AWSLoadBalancerControllerIAMPolicy \
    --policy-document file://iam_policy.json \
    ${AWS_PROFILE:+--profile $AWS_PROFILE}

# Criar IRSA (IAM Role for Service Accounts)
# Adicione --profile se necessÃ¡rio
eksctl create iamserviceaccount \
  --cluster=k8s-platform-prod \
  --namespace=kube-system \
  --name=aws-load-balancer-controller \
  --role-name AmazonEKSLoadBalancerControllerRole \
  --attach-policy-arn=arn:aws:iam::${ACCOUNT_ID}:policy/AWSLoadBalancerControllerIAMPolicy \
  --approve \
  --region us-east-1 \
  ${AWS_PROFILE:+--profile $AWS_PROFILE}

# Instalar via Helm
helm repo add eks https://aws.github.io/eks-charts
helm repo update

helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
  -n kube-system \
  --set clusterName=k8s-platform-prod \
  --set serviceAccount.create=false \
  --set serviceAccount.name=aws-load-balancer-controller

# Verificar instalaÃ§Ã£o
kubectl get pods -n kube-system | grep aws-load-balancer-controller
```

---

### ðŸ”¹ ServiÃ§o: Route53

> **Contexto:** Route53 gerenciarÃ¡ o DNS para todos os serviÃ§os da plataforma. IntegraÃ§Ã£o com cert-manager permite certificados automÃ¡ticos.

#### 3.10.1 Criar Hosted Zone

**Passo a passo no console:**

1. Na barra de busca, digite `Route53` e clique em **Route 53**
2. Clique em **Hosted zones** â†’ **Create hosted zone**
3. Preencha:
   - **Domain name:** `k8s-platform.seudominio.com.br`
   - **Description:** `DNS-zone-para-plataforma-Kubernetes`
   - **Type:** Public hosted zone

4. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`

5. Clique em **Create hosted zone**

6. **IMPORTANTE:** Copie os 4 nameservers (NS) exibidos e configure-os no seu registrador de domÃ­nio

---

### ðŸ”¹ ServiÃ§o: ACM (AWS Certificate Manager)

> **Contexto:** ACM fornece certificados TLS gratuitos e renovaÃ§Ã£o automÃ¡tica. SerÃ¡ usado pelo ALB para HTTPS.

#### 3.11.1 Solicitar Certificado SSL

**Passo a passo no console:**

1. Na barra de busca, digite `ACM` e clique em **Certificate Manager**
2. Clique em **Request certificate**
3. Selecione **Request a public certificate** â†’ **Next**
4. Preencha:

   **Domain names:**
   - `*.k8s-platform.seudominio.com.br`
   - `k8s-platform.seudominio.com.br`

   **Validation method:**
   - Selecione **DNS validation (recommended)**

   **Key algorithm:**
   - Selecione **RSA 2048**

5. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`

6. Clique em **Request**

7. Na lista de certificados, clique no certificado pendente
8. Clique em **Create records in Route 53** para validaÃ§Ã£o automÃ¡tica
9. Aguarde o status mudar para `Issued` (5-30 minutos)

---

### ðŸ”¹ ServiÃ§o: Secrets Manager

> **Contexto:** Secrets Manager armazena credenciais de forma segura com rotaÃ§Ã£o automÃ¡tica. Integra com EKS via External Secrets Operator.

#### 3.12.1 Criar Secret para RDS

**Passo a passo no console:**

1. Na barra de busca, digite `Secrets Manager` e clique em **Secrets Manager**
2. Clique em **Store a new secret**
3. Preencha:

   **Secret type:**
   - Selecione **Credentials for Amazon RDS database**

   **Credentials:**
   - **User name:** `postgres_admin`
   - **Password:** (a senha master do RDS)

   **Database:**
   - Selecione `k8s-platform-prod-postgresql`

   **Encryption key:**
   - Selecione `alias/k8s-platform-prod`

4. Clique em **Next**

   **Secret name and description:**
   - **Secret name:** `k8s-platform/prod/rds/master`
   - **Description:** `Credenciais-master-do-RDS-PostgreSQL`

   **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`

5. Clique em **Next**

   **Configure rotation:**
   - âœ… **Automatic rotation**
   - **Rotation schedule:** 30 days
   - **Rotation function:** Create a new Lambda function

6. Clique em **Next** â†’ **Store**

---

#### 3.12.2 Criar Secrets para AplicaÃ§Ãµes

Repita o processo para cada aplicaÃ§Ã£o:

| Secret Name | Tipo | ConteÃºdo |
|-------------|------|----------|
| `k8s-platform/prod/gitlab/db` | Other type of secret | `{"username":"gitlab_user","password":"..."}` |
| `k8s-platform/prod/keycloak/db` | Other type of secret | `{"username":"keycloak_user","password":"..."}` |
| `k8s-platform/prod/sonarqube/db` | Other type of secret | `{"username":"sonarqube_user","password":"..."}` |
| `k8s-platform/prod/redis` | Other type of secret | `{"auth_token":"..."}` |

---

### ðŸ”¹ ServiÃ§o: CloudWatch

> **Contexto:** CloudWatch centraliza logs e mÃ©tricas AWS. Container Insights oferece observabilidade nativa para EKS.

#### 3.13.1 Criar Log Groups

**Passo a passo no console:**

1. Na barra de busca, digite `CloudWatch` e clique em **CloudWatch**
2. Menu lateral â†’ **Logs** â†’ **Log groups**
3. Clique em **Create log group**
4. Preencha:
   - **Log group name:** `/aws/eks/k8s-platform-prod/cluster`
   - **Retention setting:** 30 days
   - **KMS key:** `alias/k8s-platform-prod`

5. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`

6. Clique em **Create**

Repita para:
- `/aws/rds/instance/k8s-platform-prod-postgresql/postgresql`
- `/aws/elasticache/k8s-platform-prod-redis`

---

#### 3.13.2 Habilitar Container Insights

**Passo a passo no console:**

1. Em **CloudWatch**, menu lateral â†’ **Container Insights**
2. Clique em **View container insights**
3. Se nÃ£o estiver configurado, clique em **Quick Start**
4. Selecione o cluster `k8s-platform-prod`
5. Siga o wizard para instalar o CloudWatch Agent via Helm:

```bash
# Instalar CloudWatch Agent
FluentBitHttpPort='2020'
FluentBitReadFromHead='Off'
[[ ${FluentBitReadFromHead} = 'On' ]] && FluentBitReadFromTail='Off'|| FluentBitReadFromTail='On'
[[ -z ${FluentBitHttpPort} ]] && FluentBitHttpServer='Off' || FluentBitHttpServer='On'

ClusterName=k8s-platform-prod
RegionName=us-east-1
LogRegion=us-east-1

curl https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/quickstart/cwagent-fluent-bit-quickstart.yaml | sed 's/{{cluster_name}}/'${ClusterName}'/;s/{{region_name}}/'${RegionName}'/;s/{{http_server_toggle}}/"'${FluentBitHttpServer}'"/;s/{{http_server_port}}/"'${FluentBitHttpPort}'"/;s/{{read_from_head}}/"'${FluentBitReadFromHead}'"/;s/{{read_from_tail}}/"'${FluentBitReadFromTail}'"/' | kubectl apply -f -
```

---

### ðŸ”¹ ServiÃ§o: WAF (Web Application Firewall)

> **Contexto:** WAF protege aplicaÃ§Ãµes web contra ataques OWASP Top 10 (SQL Injection, XSS, etc.). SerÃ¡ associado ao ALB.

#### 3.14.1 Criar Web ACL

**Passo a passo no console:**

1. Na barra de busca, digite `WAF` e clique em **WAF & Shield**
2. Clique em **Web ACLs** â†’ **Create web ACL**
3. Preencha:

   **Step 1 - Describe web ACL:**
   - **Resource type:** Regional resources (Application Load Balancer, API Gateway, etc.)
   - **Region:** US East (N. Virginia)
   - **Name:** `k8s-platform-prod-waf`
   - **Description:** `WAF-para-proteAAo-da-plataforma-Kubernetes`
   - **CloudWatch metric name:** `k8s-platform-prod-waf`

4. Clique em **Next**

   **Step 2 - Add rules and rule groups:**

   Clique em **Add rules** â†’ **Add managed rule groups**

   Selecione os seguintes **AWS managed rule groups** (gratuitos):
   - âœ… **Core rule set (CRS)** - ProteÃ§Ã£o geral
   - âœ… **Known bad inputs** - Inputs maliciosos conhecidos
   - âœ… **SQL database** - SQL Injection
   - âœ… **Linux operating system** - Ataques especÃ­ficos Linux

   **Default action:**
   - Selecione **Allow**

5. Clique em **Next**

   **Step 3 - Set rule priority:**
   - Deixe a ordem padrÃ£o

6. Clique em **Next**

   **Step 4 - Configure metrics:**
   - âœ… **Enable CloudWatch metrics**
   - âœ… **Enable sampling of requests**

7. Clique em **Next**

   **Step 5 - Review and create:**
   - Revise as configuraÃ§Ãµes

8. Clique em **Create web ACL**

---

### ðŸ”¹ ServiÃ§o: AWS Backup

> **Contexto:** AWS Backup centraliza backups de RDS, EBS e outros serviÃ§os. Essencial para Disaster Recovery.

#### 3.15.1 Criar Backup Plan

**Passo a passo no console:**

1. Na barra de busca, digite `AWS Backup` e clique em **AWS Backup**
2. Clique em **Backup plans** â†’ **Create backup plan**
3. Selecione **Build a new plan**
4. Preencha:

   **Backup plan name:**
   - **Backup plan name:** `k8s-platform-prod-backup-plan`

   **Backup rule configuration:**
   - **Backup rule name:** `daily-backup`
   - **Backup vault:** Create new vault
     - **Vault name:** `k8s-platform-prod-vault`
     - **Encryption key:** `alias/k8s-platform-prod`
   - **Backup frequency:** Daily
   - **Backup window:** Start within 2 hours of 03:00 UTC
   - **Transition to cold storage:** After 30 days
   - **Retention period:** 90 days
   - âœ… **Enable continuous backups for supported resources** (point-in-time recovery)

5. Clique em **Create plan**

---

#### 3.15.2 Associar Recursos ao Backup Plan

**Passo a passo no console:**

1. No backup plan criado, clique em **Assign resources**
2. Preencha:
   - **Resource assignment name:** `k8s-platform-prod-resources`
   - **IAM role:** Default role

   **Define resource selection:**
   - Selecione **Include specific resource types**
   - **Select specific resource types:**
     - âœ… **RDS**
     - âœ… **EBS**
     - âœ… **S3**

   **Refine selection using tags:**
   - **Tag key:** `Project`
   - **Tag value:** `k8s-platform`

3. Clique em **Assign resources**

---

## 4ï¸âƒ£ Boas PrÃ¡ticas DevOps AWS (ObrigatÃ³rio)

### 4.1 IAM - Menor PrivilÃ©gio

| PrÃ¡tica | ImplementaÃ§Ã£o |
|---------|---------------|
| **Roles por serviÃ§o** | Uma IAM Role para cada componente (EKS, Nodes, etc.) |
| **IRSA** | IAM Roles for Service Accounts - pods com permissÃµes especÃ­ficas |
| **Sem root** | Nunca usar conta root para operaÃ§Ãµes |
| **MFA obrigatÃ³rio** | Todos os usuÃ¡rios IAM devem ter MFA habilitado |
| **Access Keys rotativas** | RotaÃ§Ã£o a cada 90 dias |

### 4.2 Tags ObrigatÃ³rias

**Todas** as resources devem ter estas tags:

| Tag | DescriÃ§Ã£o | Exemplo |
|-----|-----------|---------|
| `Project` | Nome do projeto | `k8s-platform` |
| `Environment` | Ambiente | `prod`, `staging`, `dev` |
| `Owner` | Time responsÃ¡vel | `devops-team` |
| `CostCenter` | Centro de custo | `infrastructure` |
| `ManagedBy` | Gerenciamento | `terraform`, `manual` |

### 4.3 SeparaÃ§Ã£o de Ambientes

```
OpÃ§Ã£o 1: VPCs separadas (recomendado)
â”œâ”€â”€ VPC-staging (10.1.0.0/16) â†’ Conta AWS: staging
â””â”€â”€ VPC-prod (10.0.0.0/16)    â†’ Conta AWS: prod

OpÃ§Ã£o 2: Namespaces no EKS (custo menor)
â”œâ”€â”€ k8s-platform-prod
â”‚   â”œâ”€â”€ ns: platform-core
â”‚   â”œâ”€â”€ ns: platform-core-staging
â”‚   â””â”€â”€ ...
```

### 4.4 IaC com Terraform

**Estrutura obrigatÃ³ria:**

```
platform-provisioning/
â”œâ”€â”€ aws/
â”‚   â”œâ”€â”€ environments/
â”‚   â”‚   â”œâ”€â”€ prod/
â”‚   â”‚   â”‚   â”œâ”€â”€ terraform.tfvars
â”‚   â”‚   â”‚   â””â”€â”€ backend.tf
â”‚   â”‚   â””â”€â”€ staging/
â”‚   â”‚       â”œâ”€â”€ terraform.tfvars
â”‚   â”‚       â””â”€â”€ backend.tf
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ vpc/
â”‚   â”‚   â”œâ”€â”€ eks/
â”‚   â”‚   â”œâ”€â”€ rds/
â”‚   â”‚   â””â”€â”€ s3/
â”‚   â””â”€â”€ main.tf
```

**Backend S3 (obrigatÃ³rio):**

```hcl
terraform {
  backend "s3" {
    bucket         = "k8s-platform-terraform-state-{account-id}"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-state-lock"
    # profile       = "k8s-platform-terraform"  # Se usando AWS CLI profile
  }
}
```

**AutenticaÃ§Ã£o Terraform:**

**OpÃ§Ã£o 1: VariÃ¡veis de Ambiente (CI/CD)**

```bash
export AWS_ACCESS_KEY_ID="AKIAIOSFODNN7EXAMPLE"
export AWS_SECRET_ACCESS_KEY="wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
export AWS_DEFAULT_REGION="us-east-1"

terraform init
terraform plan
terraform apply
```

**OpÃ§Ã£o 2: AWS Profile (Local)**

```bash
# Usar perfil do ~/.aws/credentials
export AWS_PROFILE=k8s-platform-terraform

terraform init
terraform plan
terraform apply
```

**OpÃ§Ã£o 3: SSO (Desenvolvedor)**

```bash
# Login SSO
aws sso login --profile k8s-platform-prod

# Usar perfil SSO
export AWS_PROFILE=k8s-platform-prod

terraform init
terraform plan
```

**OpÃ§Ã£o 4: IAM Role (EC2/Lambda)**

```hcl
# provider.tf - Terraform assume automaticamente a role da instÃ¢ncia
provider "aws" {
  region = "us-east-1"
  # Sem credenciais explÃ­citas - usa EC2 Instance Profile
}
```

**GitHub Actions CI/CD:**

```yaml
# .github/workflows/terraform.yml
name: Terraform Apply

on:
  push:
    branches: [main]

jobs:
  terraform:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.7.0

      - name: Terraform Init
        run: terraform init
        working-directory: aws/environments/prod

      - name: Terraform Plan
        run: terraform plan -out=tfplan
        working-directory: aws/environments/prod

      - name: Terraform Apply
        if: github.ref == 'refs/heads/main'
        run: terraform apply -auto-approve tfplan
        working-directory: aws/environments/prod
```

### 4.5 Logs e Monitoramento

| Componente | Destino | RetenÃ§Ã£o |
|------------|---------|----------|
| EKS Control Plane | CloudWatch Logs | 30 dias |
| Container Logs | Loki (S3 backend) | 90 dias |
| RDS Logs | CloudWatch Logs | 30 dias |
| VPC Flow Logs | CloudWatch Logs | 7 dias |
| CloudTrail | S3 | 365 dias |

---

## 5ï¸âƒ£ EstratÃ©gia de Testes e ValidaÃ§Ã£o

### 5.1 VPC e Networking

| Teste | Comando/AÃ§Ã£o | Resultado Esperado |
|-------|--------------|-------------------|
| Subnets criadas | Console VPC â†’ Subnets | 9 subnets (3 public + 3 private + 3 db) |
| NAT Gateway | Console VPC â†’ NAT Gateways | Status: Available |
| Route Tables | Console VPC â†’ Route Tables | Rotas corretas por subnet |
| Conectividade privada | Ping entre subnets | Resposta OK |

### 5.2 EKS Cluster

| Teste | Comando | Resultado Esperado |
|-------|---------|-------------------|
| Cluster ativo | `kubectl cluster-info` | URLs do cluster |
| Nodes prontos | `kubectl get nodes` | Todos os nodes `Ready` |
| Core DNS | `kubectl get pods -n kube-system` | CoreDNS running |
| Networking | `kubectl run test --image=nginx --restart=Never` | Pod running |

### 5.3 RDS e ElastiCache

| Teste | AÃ§Ã£o | Resultado Esperado |
|-------|------|-------------------|
| RDS disponÃ­vel | Console RDS | Status: Available |
| ConexÃ£o PostgreSQL | `psql -h <endpoint> -U postgres_admin` | ConexÃ£o bem-sucedida |
| Redis disponÃ­vel | Console ElastiCache | Status: Available |
| ConexÃ£o Redis | `redis-cli -h <endpoint> PING` | PONG |

### 5.4 Teste de Carga

```bash
# Instalar k6 para teste de carga
kubectl run k6 --image=grafana/k6 --restart=Never -- run - <<EOF
import http from 'k6/http';
export default function () {
  http.get('https://gitlab.k8s-platform.seudominio.com.br');
}
EOF
```

### 5.5 MÃ©tricas a Observar

| MÃ©trica | Threshold Warning | Threshold Critical |
|---------|-------------------|-------------------|
| CPU Nodes | >70% | >85% |
| Memory Nodes | >75% | >90% |
| RDS CPU | >70% | >85% |
| RDS Connections | >80% max | >90% max |
| EBS IOPS | >80% provisioned | >90% provisioned |

---

## 6ï¸âƒ£ GestÃ£o de Custos (FinOps)

### 6.1 Ativar AWS Billing e Cost Explorer

**Passo a passo no console:**

1. Clique no nome da conta (canto superior direito)
2. Clique em **Billing Dashboard**
3. Menu lateral â†’ **Cost Management** â†’ **Cost Explorer**
4. Clique em **Enable Cost Explorer** (se nÃ£o estiver ativo)
5. Aguarde 24 horas para dados aparecerem

### 6.2 Criar OrÃ§amento (Budget)

**Passo a passo no console:**

1. Em **Billing** â†’ **Budgets**
2. Clique em **Create budget**
3. Selecione **Customized - Advanced**
4. Preencha:

   **Budget setup:**
   - **Name:** `k8s-platform-monthly-budget`
   - **Period:** Monthly
   - **Budget effective date:** Recurring budget
   - **Start month:** (mÃªs atual)
   - **Budgeting method:** Fixed
   - **Enter your budgeted amount:** `1000` (USD)

   **Budget scope:**
   - **Filter:** Tag â†’ `Project` = `k8s-platform`

5. Clique em **Next**

   **Configure alerts:**

   **Alert 1:**
   - **Threshold:** 50% of budgeted amount
   - **Trigger:** Actual
   - **Email:** devops-team@empresa.com.br

   **Alert 2:**
   - **Threshold:** 80% of budgeted amount
   - **Trigger:** Actual
   - **Email:** devops-team@empresa.com.br, finops@empresa.com.br

   **Alert 3:**
   - **Threshold:** 100% of budgeted amount
   - **Trigger:** Forecasted
   - **Email:** (todos + gerÃªncia)

6. Clique em **Create budget**

### 6.3 ServiÃ§os Mais CrÃ­ticos em Custo

| ServiÃ§o | Custo Estimado | % Total | AÃ§Ã£o de OtimizaÃ§Ã£o |
|---------|---------------|---------|-------------------|
| **EC2 (Node Groups)** | $486/mÃªs | 44% | Reserved Instances |
| **RDS PostgreSQL** | $215/mÃªs | 19% | Rightsizing ou RI |
| **NAT Gateway** | $121/mÃªs | 11% | Reduzir para 1 NAT |
| **ALB** | $75/mÃªs | 7% | - |
| **ElastiCache** | $50/mÃªs | 4% | - |
| **EKS Control Plane** | $73/mÃªs | 6% | - |

### 6.4 EstratÃ©gias de ReduÃ§Ã£o de Custo

| EstratÃ©gia | Economia Estimada | EsforÃ§o |
|------------|------------------|---------|
| Reserved Instances (1 ano) | 31% em EC2/RDS | MÃ©dio |
| Savings Plans | 15-20% adicional | Baixo |
| 1 NAT Gateway (dev/staging) | $81/mÃªs | Baixo |
| Spot Instances (workloads tolerantes) | 70% em EC2 | Alto |
| S3 Lifecycle (Glacier) | 80% em storage antigo | Baixo |
| Rightsizing RDS | AtÃ© $100/mÃªs | MÃ©dio |

---

## 7ï¸âƒ£ EstratÃ©gia de Desligamento e Economia

### 7.1 Ambiente Staging - Scheduled Stop

**Passo a passo para agendar stop dos nodes:**

1. Crie uma Lambda para stop/start:

```python
# lambda_function.py
import boto3

def lambda_handler(event, context):
    action = event.get('action', 'stop')
    client = boto3.client('eks')
    asg = boto3.client('autoscaling')

    # Obter ASGs do node group staging
    asgs = asg.describe_auto_scaling_groups(
        Filters=[{'Name': 'tag:eks:nodegroup-name', 'Values': ['system', 'workloads']}]
    )

    for group in asgs['AutoScalingGroups']:
        if 'staging' in group['AutoScalingGroupName']:
            if action == 'stop':
                asg.update_auto_scaling_group(
                    AutoScalingGroupName=group['AutoScalingGroupName'],
                    MinSize=0, MaxSize=0, DesiredCapacity=0
                )
            else:
                asg.update_auto_scaling_group(
                    AutoScalingGroupName=group['AutoScalingGroupName'],
                    MinSize=2, MaxSize=4, DesiredCapacity=2
                )

    return {'status': 'success', 'action': action}
```

2. Crie EventBridge Rules:

**Stop (20:00 BRT = 23:00 UTC):**
- Cron: `cron(0 23 ? * MON-FRI *)`
- Target: Lambda â†’ `eks-staging-scheduler`
- Input: `{"action": "stop"}`

**Start (08:00 BRT = 11:00 UTC):**
- Cron: `cron(0 11 ? * MON-FRI *)`
- Target: Lambda â†’ `eks-staging-scheduler`
- Input: `{"action": "start"}`

### 7.2 RDS Stop/Start

**Passo a passo no console:**

1. **RDS** â†’ Selecione a instÃ¢ncia staging
2. **Actions** â†’ **Stop temporarily**
3. **IMPORTANTE:** RDS para automaticamente apÃ³s 7 dias. Para paradas mais longas, use snapshot + delete.

### 7.3 S3 Lifecycle para Logs

```json
{
    "Rules": [
        {
            "ID": "move-to-glacier",
            "Status": "Enabled",
            "Transitions": [
                {
                    "Days": 30,
                    "StorageClass": "STANDARD_IA"
                },
                {
                    "Days": 90,
                    "StorageClass": "GLACIER"
                }
            ],
            "Expiration": {
                "Days": 365
            }
        }
    ]
}
```

### 7.4 Riscos de Esquecer Recursos Ligados

| Recurso | Custo se Esquecido | MitigaÃ§Ã£o |
|---------|-------------------|-----------|
| **NAT Gateway** | $32/mÃªs (idle) | Budget alert |
| **RDS Multi-AZ** | $200+/mÃªs | Lambda scheduled stop |
| **EKS Nodes** | $480+/mÃªs | ASG MinSize=0 fora horÃ¡rio |
| **ALB** | $16/mÃªs (idle) | Aceitar custo mÃ­nimo |
| **EBS nÃ£o anexados** | VariÃ¡vel | Tag `DeleteAfter` + Lambda cleanup |

---

## 8ï¸âƒ£ Checklist Final DevOps

### SeguranÃ§a

- [ ] MFA habilitado para todas as contas IAM
- [ ] IAM Roles com menor privilÃ©gio
- [ ] **AutenticaÃ§Ã£o AWS CLI configurada** (CloudShell, SSO ou Access Keys com rotaÃ§Ã£o)
- [ ] Access Keys armazenadas no AWS Secrets Manager (se aplicÃ¡vel)
- [ ] RotaÃ§Ã£o de Access Keys a cada 90 dias validada (se aplicÃ¡vel)
- [ ] VPC com subnets pÃºblicas/privadas separadas
- [ ] Security Groups com regras mÃ­nimas
- [ ] KMS encryption habilitada em RDS, S3, EBS, EKS secrets
- [ ] WAF configurado e ativo
- [ ] CloudTrail habilitado
- [ ] Secrets no AWS Secrets Manager (nÃ£o em cÃ³digo)
- [ ] Network Policies no Kubernetes
- [ ] Pod Security Standards aplicados

### Custo

- [ ] Budgets configurados com alertas
- [ ] Tags obrigatÃ³rias em todos os recursos
- [ ] Cost Explorer ativado
- [ ] Reserved Instances avaliadas
- [ ] S3 Lifecycle configurado
- [ ] Scheduled stop para staging
- [ ] Rightsizing inicial validado

### Monitoramento

- [ ] CloudWatch Logs habilitados (EKS, RDS, ElastiCache)
- [ ] Container Insights ativo
- [ ] MÃ©tricas customizadas definidas
- [ ] Alertas de threshold configurados
- [ ] Dashboard de custo criado
- [ ] Prometheus + Grafana instalados no cluster

### Testes

- [ ] Conectividade de rede validada
- [ ] EKS cluster acessÃ­vel via kubectl
- [ ] RDS conexÃ£o testada
- [ ] Redis conexÃ£o testada
- [ ] DNS resolvendo corretamente
- [ ] Certificado SSL vÃ¡lido
- [ ] ALB respondendo

### Desligamento

- [ ] Lambda de scheduled stop criada
- [ ] EventBridge rules configuradas
- [ ] Procedimento de DR documentado
- [ ] Backups validados (restore test)

### Pronto para ProduÃ§Ã£o?

**Status:** âš ï¸ **Parcial**

**Justificativa:**

| CritÃ©rio | Status | ComentÃ¡rio |
|----------|--------|------------|
| Infraestrutura base | âœ… | VPC, EKS, RDS prontos |
| SeguranÃ§a | âš ï¸ | Falta validar Network Policies |
| HA/DR | âœ… | Multi-AZ configurado |
| Backups | âœ… | AWS Backup ativo |
| Monitoramento | âš ï¸ | Falta Prometheus/Grafana |
| CI/CD | âŒ | GitLab nÃ£o instalado ainda |
| DocumentaÃ§Ã£o | âœ… | ADRs e runbooks |

**PrÃ³ximos passos para produÃ§Ã£o:**
1. Deploy dos domÃ­nios Kubernetes (platform-core â†’ cicd-platform)
2. ValidaÃ§Ã£o de Network Policies
3. Teste de DR completo
4. AprovaÃ§Ã£o do time de seguranÃ§a

---

## Anexos

### A. Comandos Ãšteis

```bash
# Verificar custos via CLI
aws ce get-cost-and-usage \
    --time-period Start=2026-01-01,End=2026-01-31 \
    --granularity MONTHLY \
    --metrics "BlendedCost" \
    --filter '{"Tags":{"Key":"Project","Values":["k8s-platform"]}}'

# Listar recursos por tag
aws resourcegroupstaggingapi get-resources \
    --tag-filters Key=Project,Values=k8s-platform

# Verificar status do cluster
aws eks describe-cluster --name k8s-platform-prod --query 'cluster.status'

# Verificar nodes
aws eks list-nodegroups --cluster-name k8s-platform-prod
```

### B. Links Ãšteis

**DocumentaÃ§Ã£o AWS:**
- [AWS EKS Best Practices](https://aws.github.io/aws-eks-best-practices/)
- [AWS Well-Architected Framework](https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html)
- [EKS Workshop](https://www.eksworkshop.com/)
- [AWS Pricing Calculator](https://calculator.aws/)

**AutenticaÃ§Ã£o e SeguranÃ§a:**
- [AWS CLI V2 - SSO Configuration](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-sso.html)
- [AWS CloudShell User Guide](https://docs.aws.amazon.com/cloudshell/latest/userguide/welcome.html)
- [IAM Identity Center (SSO) Best Practices](https://docs.aws.amazon.com/singlesignon/latest/userguide/best-practices.html)
- [IAM Roles for Service Accounts (IRSA)](https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html)
- [AWS Security Best Practices](https://aws.amazon.com/architecture/security-identity-compliance/)

---

**Documento gerado em:** 2026-01-19
**Ãšltima atualizaÃ§Ã£o:** 2026-01-22
**Autor:** DevOps AWS Specialist
**VersÃ£o:** 1.1
**AlteraÃ§Ãµes (v1.1):**
- Atualizada seÃ§Ã£o 3.1.4 com recomendaÃ§Ãµes AWS 2026 (CloudShell, SSO, Access Keys)
- Atualizada seÃ§Ã£o 3.8.5 com mÃºltiplos mÃ©todos de autenticaÃ§Ã£o kubectl
- Atualizada seÃ§Ã£o 3.9.1 com suporte a perfis AWS
- Atualizada seÃ§Ã£o 4.4 com autenticaÃ§Ã£o Terraform e CI/CD
- Adicionados itens de checklist para validaÃ§Ã£o de autenticaÃ§Ã£o
**PrÃ³xima revisÃ£o:** ApÃ³s deploy inicial




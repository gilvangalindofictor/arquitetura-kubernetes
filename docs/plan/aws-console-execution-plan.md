# Plano de Execu√ß√£o AWS - Plataforma Kubernetes Corporativa

**Vers√£o:** 1.0
**Data:** 2026-01-19
**Projeto:** Arquitetura Multi-Dom√≠nio Kubernetes
**Regi√£o Principal:** us-east-1 (N. Virginia)
**Ambientes:** Homologa√ß√£o + Produ√ß√£o

---

## 1Ô∏è‚É£ Vis√£o Geral da Estrat√©gia Cloud

### Arquitetura Escolhida

**Amazon EKS (Elastic Kubernetes Service)** como plataforma de orquestra√ß√£o para hospedar os 6 dom√≠nios da plataforma corporativa de engenharia:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           AWS CLOUD (us-east-1)                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                         VPC (10.0.0.0/16)                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  AZ-1a       ‚îÇ  ‚îÇ  AZ-1b       ‚îÇ  ‚îÇ  AZ-1c       ‚îÇ          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Public Sub   ‚îÇ  ‚îÇ Public Sub   ‚îÇ  ‚îÇ Public Sub   ‚îÇ          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ 10.0.1.0/24  ‚îÇ  ‚îÇ 10.0.2.0/24  ‚îÇ  ‚îÇ 10.0.3.0/24  ‚îÇ          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (NAT + ALB)  ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Private Sub  ‚îÇ  ‚îÇ Private Sub  ‚îÇ  ‚îÇ Private Sub  ‚îÇ          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ 10.0.11.0/24 ‚îÇ  ‚îÇ 10.0.12.0/24 ‚îÇ  ‚îÇ 10.0.13.0/24 ‚îÇ          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (EKS Nodes)  ‚îÇ  ‚îÇ (EKS Nodes)  ‚îÇ ‚îÇ (EKS Nodes)  ‚îÇ          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ DB Subnet    ‚îÇ  ‚îÇ DB Subnet    ‚îÇ  ‚îÇ DB Subnet    ‚îÇ          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ 10.0.21.0/24 ‚îÇ  ‚îÇ 10.0.22.0/24 ‚îÇ  ‚îÇ 10.0.23.0/24 ‚îÇ          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (RDS/Cache)  ‚îÇ  ‚îÇ (RDS/Cache)  ‚îÇ ‚îÇ (RDS/Cache)  ‚îÇ          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                    AMAZON EKS CLUSTER                            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ system      ‚îÇ  ‚îÇ workloads   ‚îÇ  ‚îÇ critical    ‚îÇ              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ t3.medium   ‚îÇ  ‚îÇ t3.large    ‚îÇ  ‚îÇ t3.xlarge   ‚îÇ              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ 2 nodes     ‚îÇ  ‚îÇ 3 nodes     ‚îÇ  ‚îÇ 2 nodes     ‚îÇ              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ RDS         ‚îÇ  ‚îÇ ElastiCache ‚îÇ  ‚îÇ S3          ‚îÇ  ‚îÇ Route53     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ PostgreSQL  ‚îÇ  ‚îÇ Redis       ‚îÇ  ‚îÇ Buckets     ‚îÇ  ‚îÇ DNS         ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Justificativa T√©cnica

| Decis√£o | Justificativa |
|---------|---------------|
| **EKS** | Kubernetes gerenciado, integra√ß√£o nativa com IAM, ALB, CloudWatch |
| **Multi-AZ** | Alta disponibilidade obrigat√≥ria para produ√ß√£o |
| **Node Groups separados** | Isolamento de workloads (system, workloads, critical) |
| **RDS PostgreSQL** | HA Multi-AZ, backups autom√°ticos, performance otimizada |
| **S3** | Storage ilimitado para backups, logs, artifacts |

### Servi√ßos AWS Envolvidos

| Servi√ßo | Prop√≥sito | Criticidade |
|---------|-----------|-------------|
| **VPC** | Rede isolada e segmentada | Alta |
| **EKS** | Cluster Kubernetes gerenciado | Alta |
| **EC2** | Node Groups do EKS | Alta |
| **RDS** | PostgreSQL para GitLab, Keycloak, SonarQube | Alta |
| **ElastiCache** | Redis para cache e sess√µes | M√©dia |
| **S3** | Backups, logs, artifacts, Terraform state | Alta |
| **ALB** | Load Balancer para ingress | Alta |
| **Route53** | DNS gerenciado | Alta |
| **IAM** | Identidade e pol√≠ticas | Alta |
| **KMS** | Criptografia de dados | Alta |
| **CloudWatch** | Logs e m√©tricas AWS | M√©dia |
| **Secrets Manager** | Secrets sens√≠veis | Alta |
| **WAF** | Prote√ß√£o de aplica√ß√µes web | M√©dia |
| **ACM** | Certificados TLS | Alta |

---

## 2Ô∏è‚É£ Arquitetura AWS (N√≠vel L√≥gico)

### Componentes e Rela√ß√µes

```
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ   Route53   ‚îÇ
                                    ‚îÇ   DNS       ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                           ‚îÇ
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ     WAF     ‚îÇ
                                    ‚îÇ  (Firewall) ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                           ‚îÇ
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ     ALB     ‚îÇ
                                    ‚îÇ (Ingress)   ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                           ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                    VPC   ‚îÇ                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                              EKS Cluster                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                        NAMESPACES / DOM√çNIOS                         ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ platform-core ‚îÇ  ‚îÇ observability ‚îÇ  ‚îÇ cicd-platform ‚îÇ            ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  - Kong       ‚îÇ  ‚îÇ  - Prometheus ‚îÇ  ‚îÇ  - GitLab     ‚îÇ            ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  - Keycloak   ‚îÇ  ‚îÇ  - Grafana    ‚îÇ  ‚îÇ  - ArgoCD     ‚îÇ            ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  - Linkerd    ‚îÇ  ‚îÇ  - Loki       ‚îÇ  ‚îÇ  - Harbor     ‚îÇ            ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  - Ingress    ‚îÇ  ‚îÇ  - Tempo      ‚îÇ  ‚îÇ  - SonarQube  ‚îÇ            ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ data-services ‚îÇ  ‚îÇ secrets-mgmt  ‚îÇ  ‚îÇ security      ‚îÇ            ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  - PostgreSQL ‚îÇ  ‚îÇ  - Vault      ‚îÇ  ‚îÇ  - Kyverno    ‚îÇ            ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  - Redis Op   ‚îÇ  ‚îÇ  - ESO        ‚îÇ  ‚îÇ  - Falco      ‚îÇ            ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  - RabbitMQ   ‚îÇ  ‚îÇ               ‚îÇ  ‚îÇ  - Trivy      ‚îÇ            ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  - Velero     ‚îÇ  ‚îÇ               ‚îÇ  ‚îÇ               ‚îÇ            ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ
‚îÇ  ‚îÇ RDS PostgreSQL  ‚îÇ  ‚îÇ ElastiCache     ‚îÇ  ‚îÇ S3 Buckets      ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ (Multi-AZ)      ‚îÇ  ‚îÇ (Redis Cluster) ‚îÇ  ‚îÇ - backups       ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ - gitlab        ‚îÇ  ‚îÇ - gitlab-cache  ‚îÇ  ‚îÇ - artifacts     ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ - keycloak      ‚îÇ  ‚îÇ - sessions      ‚îÇ  ‚îÇ - logs          ‚îÇ                    ‚îÇ
‚îÇ  ‚îÇ - sonarqube     ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ - terraform     ‚îÇ                    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Separa√ß√£o de Ambientes

| Recurso | Homologa√ß√£o (staging) | Produ√ß√£o (prod) |
|---------|----------------------|-----------------|
| **VPC** | `vpc-staging` (10.1.0.0/16) | `vpc-prod` (10.0.0.0/16) |
| **EKS Cluster** | `k8s-platform-staging` | `k8s-platform-prod` |
| **Node Count** | 3 nodes (m√≠nimo) | 7 nodes (m√≠nimo) |
| **RDS** | db.t3.small, Single-AZ | db.t3.medium, Multi-AZ |
| **Disponibilidade** | Hor√°rio comercial (scheduled) | 24/7 |
| **Backup** | 3 dias | 7 dias |

### Considera√ß√µes de Seguran√ßa

| Camada | Controle | Implementa√ß√£o |
|--------|----------|---------------|
| **Identidade** | IAM com menor privil√©gio | Roles espec√≠ficas por servi√ßo |
| **Rede** | Segmenta√ß√£o VPC | Public/Private/DB subnets |
| **Tr√°fego** | Security Groups | Regras espec√≠ficas por porta |
| **Aplica√ß√£o** | WAF | Prote√ß√£o OWASP Top 10 |
| **Dados** | KMS | Criptografia at-rest e in-transit |
| **Secrets** | Secrets Manager | Rota√ß√£o autom√°tica |
| **Auditoria** | CloudTrail | Logs de todas as a√ß√µes |

---

## 3Ô∏è‚É£ Passo a Passo no Console da AWS (MUITO DETALHADO)

### üîπ Servi√ßo: IAM (Identity and Access Management)

> **Contexto:** Criar roles e pol√≠ticas ANTES de qualquer outro recurso. Princ√≠pio de menor privil√©gio √© obrigat√≥rio.

#### 3.1.1 Criar Pol√≠tica para EKS Cluster

**Passo a passo no console:**

1. Acesse o Console AWS: https://console.aws.amazon.com/
2. Na barra de busca superior, digite `IAM` e clique em **IAM**
3. No menu lateral esquerdo, clique em **Policies**
4. Clique no bot√£o **Create policy** (azul, canto superior direito)
5. Selecione a aba **JSON**
6. Cole a seguinte pol√≠tica:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "EKSClusterPolicy",
            "Effect": "Allow",
            "Action": [
                "eks:*",
                "ec2:DescribeSubnets",
                "ec2:DescribeSecurityGroups",
                "ec2:DescribeVpcs",
                "iam:GetRole",
                "iam:PassRole"
            ],
            "Resource": "*",
            "Condition": {
                "StringEquals": {
                    "aws:RequestedRegion": "us-east-1"
                }
            }
        }
    ]
}
```

7. Clique em **Next**
8. Preencha os campos:
   - **Policy name:** `k8s-platform-eks-policy`
   - **Description:** `Pol√≠tica para gerenciamento do cluster EKS da plataforma Kubernetes`
   - **Tags:**
     - `Project` = `k8s-platform`
     - `Environment` = `shared`
     - `Owner` = `devops-team`
     - `CostCenter` = `infrastructure`
9. Clique em **Create policy**

---

#### 3.1.2 Criar Role para EKS Cluster

**Passo a passo no console:**

1. No IAM, menu lateral, clique em **Roles**
2. Clique em **Create role**
3. Em **Trusted entity type**, selecione **AWS service**
4. Em **Use case**, selecione **EKS** ‚Üí **EKS - Cluster**
5. Clique em **Next**
6. As pol√≠ticas `AmazonEKSClusterPolicy` j√° estar√£o selecionadas
7. Clique em **Next**
8. Preencha:
   - **Role name:** `k8s-platform-eks-cluster-role`
   - **Description:** `Role para o cluster EKS da plataforma Kubernetes corporativa`
   - **Tags:**
     - `Project` = `k8s-platform`
     - `Environment` = `prod`
     - `Owner` = `devops-team`
9. Clique em **Create role**

---

#### 3.1.3 Criar Role para EKS Node Group

**Passo a passo no console:**

1. Em **Roles**, clique em **Create role**
2. Selecione **AWS service** ‚Üí **EC2**
3. Clique em **Next**
4. Busque e selecione as seguintes pol√≠ticas:
   - `AmazonEKSWorkerNodePolicy`
   - `AmazonEKS_CNI_Policy`
   - `AmazonEC2ContainerRegistryReadOnly`
   - `AmazonSSMManagedInstanceCore` (para acesso via Session Manager)
5. Clique em **Next**
6. Preencha:
   - **Role name:** `k8s-platform-eks-node-role`
   - **Description:** `Role para os Node Groups do EKS`
   - **Tags:** (mesmas tags anteriores)
7. Clique em **Create role**

---

#### 3.1.4 Criar Usu√°rio para Terraform/CI

**Passo a passo no console:**

1. Em **Users**, clique em **Create user**
2. Preencha:
   - **User name:** `terraform-k8s-platform`
3. Clique em **Next**
4. Selecione **Attach policies directly**
5. Busque e selecione:
   - `PowerUserAccess` (tempor√°rio, restringir depois)
6. Clique em **Next** ‚Üí **Create user**
7. Clique no usu√°rio criado
8. Aba **Security credentials** ‚Üí **Create access key**
9. Selecione **Command Line Interface (CLI)**
10. Marque o checkbox de confirma√ß√£o
11. Clique em **Next** ‚Üí **Create access key**
12. **IMPORTANTE:** Copie e salve as credenciais em local seguro (AWS Secrets Manager ou Vault)

---

### üîπ Servi√ßo: VPC (Virtual Private Cloud)

> **Contexto:** A VPC isola toda a infraestrutura. Segmenta√ß√£o em subnets p√∫blicas, privadas e de banco de dados √© essencial para seguran√ßa.

#### 3.2.1 Criar VPC com Wizard

**Passo a passo no console:**

1. Na barra de busca, digite `VPC` e clique em **VPC**
2. Clique em **Create VPC**
3. Selecione **VPC and more** (wizard completo)
4. Preencha os campos:

   **Name tag auto-generation:**
   - **Auto-generate:** Marque
   - **Name:** `k8s-platform-prod`

   **IPv4 CIDR block:**
   - **IPv4 CIDR:** `10.0.0.0/16`

   **IPv6 CIDR block:**
   - Selecione **No IPv6 CIDR block**

   **Tenancy:**
   - Selecione **Default**

   **Number of Availability Zones:**
   - Selecione **3**

   **Number of public subnets:**
   - Selecione **3**

   **Number of private subnets:**
   - Selecione **3**

   **NAT gateways:**
   - Selecione **In 1 AZ** (economia de custo - para prod HA use "1 per AZ")

   **VPC endpoints:**
   - Selecione **S3 Gateway**

   **DNS options:**
   - ‚úÖ **Enable DNS hostnames**
   - ‚úÖ **Enable DNS resolution**

5. Revise o diagrama gerado automaticamente
6. Clique em **Create VPC**
7. Aguarde a cria√ß√£o (2-3 minutos)

---

#### 3.2.2 Criar Subnets de Banco de Dados

**Passo a passo no console:**

1. No VPC Dashboard, menu lateral, clique em **Subnets**
2. Clique em **Create subnet**
3. Preencha:

   **VPC ID:** Selecione `k8s-platform-prod-vpc`

   **Subnet 1:**
   - **Subnet name:** `k8s-platform-prod-db-us-east-1a`
   - **Availability Zone:** `us-east-1a`
   - **IPv4 CIDR block:** `10.0.21.0/24`

4. Clique em **Add new subnet**

   **Subnet 2:**
   - **Subnet name:** `k8s-platform-prod-db-us-east-1b`
   - **Availability Zone:** `us-east-1b`
   - **IPv4 CIDR block:** `10.0.22.0/24`

5. Clique em **Add new subnet**

   **Subnet 3:**
   - **Subnet name:** `k8s-platform-prod-db-us-east-1c`
   - **Availability Zone:** `us-east-1c`
   - **IPv4 CIDR block:** `10.0.23.0/24`

6. Clique em **Create subnet**

---

#### 3.2.3 Criar Subnet Group para RDS

**Passo a passo no console:**

1. Na barra de busca, digite `RDS` e clique em **RDS**
2. Menu lateral, clique em **Subnet groups**
3. Clique em **Create DB subnet group**
4. Preencha:
   - **Name:** `k8s-platform-prod-db-subnet-group`
   - **Description:** `Subnet group para RDS da plataforma Kubernetes`
   - **VPC:** Selecione `k8s-platform-prod-vpc`

   **Add subnets:**
   - **Availability Zones:** Selecione `us-east-1a`, `us-east-1b`, `us-east-1c`
   - **Subnets:** Selecione as 3 subnets de DB criadas (10.0.21.0/24, 10.0.22.0/24, 10.0.23.0/24)

5. Clique em **Create**

---

#### 3.2.4 Adicionar Tags nas Subnets para EKS

**Passo a passo no console:**

1. Volte para **VPC** ‚Üí **Subnets**
2. Selecione TODAS as subnets **privadas** (uma por vez)
3. Clique na aba **Tags**
4. Clique em **Manage tags**
5. Adicione as tags:

   | Key | Value |
   |-----|-------|
   | `kubernetes.io/cluster/k8s-platform-prod` | `shared` |
   | `kubernetes.io/role/internal-elb` | `1` |

6. Repita para as subnets **p√∫blicas** com tags diferentes:

   | Key | Value |
   |-----|-------|
   | `kubernetes.io/cluster/k8s-platform-prod` | `shared` |
   | `kubernetes.io/role/elb` | `1` |

---

### üîπ Servi√ßo: Security Groups

> **Contexto:** Security Groups atuam como firewall stateful. Cada componente deve ter seu pr√≥prio SG com regras m√≠nimas necess√°rias.

#### 3.3.1 Criar Security Group para EKS Cluster

**Passo a passo no console:**

1. Em **VPC** ‚Üí **Security groups**
2. Clique em **Create security group**
3. Preencha:
   - **Security group name:** `k8s-platform-prod-eks-cluster-sg`
   - **Description:** `Security Group para o EKS Control Plane`
   - **VPC:** Selecione `k8s-platform-prod-vpc`

4. **Inbound rules:** (deixe vazio por enquanto, ser√° configurado automaticamente pelo EKS)

5. **Outbound rules:**
   - **Type:** All traffic
   - **Destination:** 0.0.0.0/0

6. **Tags:**
   - `Name` = `k8s-platform-prod-eks-cluster-sg`
   - `Project` = `k8s-platform`

7. Clique em **Create security group**

---

#### 3.3.2 Criar Security Group para RDS

**Passo a passo no console:**

1. Clique em **Create security group**
2. Preencha:
   - **Security group name:** `k8s-platform-prod-rds-sg`
   - **Description:** `Security Group para RDS PostgreSQL`
   - **VPC:** Selecione `k8s-platform-prod-vpc`

3. **Inbound rules:**
   - Clique em **Add rule**
   - **Type:** PostgreSQL
   - **Port:** 5432
   - **Source:** Custom ‚Üí Selecione `k8s-platform-prod-eks-cluster-sg`
   - **Description:** `Acesso do EKS ao RDS`

4. **Outbound rules:**
   - **Type:** All traffic
   - **Destination:** 0.0.0.0/0

5. **Tags:**
   - `Name` = `k8s-platform-prod-rds-sg`
   - `Project` = `k8s-platform`

6. Clique em **Create security group**

---

#### 3.3.3 Criar Security Group para ElastiCache

**Passo a passo no console:**

1. Clique em **Create security group**
2. Preencha:
   - **Security group name:** `k8s-platform-prod-redis-sg`
   - **Description:** `Security Group para ElastiCache Redis`
   - **VPC:** Selecione `k8s-platform-prod-vpc`

3. **Inbound rules:**
   - **Type:** Custom TCP
   - **Port:** 6379
   - **Source:** `k8s-platform-prod-eks-cluster-sg`
   - **Description:** `Acesso do EKS ao Redis`

4. Clique em **Create security group**

---

### üîπ Servi√ßo: S3 (Simple Storage Service)

> **Contexto:** S3 armazenar√° backups, logs, artifacts do GitLab/Harbor e o Terraform state. Versionamento e criptografia s√£o obrigat√≥rios.

#### 3.4.1 Criar Bucket para Terraform State

**Passo a passo no console:**

1. Na barra de busca, digite `S3` e clique em **S3**
2. Clique em **Create bucket**
3. Preencha:

   **General configuration:**
   - **Bucket name:** `k8s-platform-terraform-state-{account-id}` (substitua {account-id} pelo seu ID de conta)
   - **AWS Region:** `us-east-1`

   **Object Ownership:**
   - Selecione **ACLs disabled (recommended)**

   **Block Public Access settings:**
   - ‚úÖ **Block all public access** (OBRIGAT√ìRIO)

   **Bucket Versioning:**
   - Selecione **Enable**

   **Default encryption:**
   - **Encryption type:** Server-side encryption with Amazon S3 managed keys (SSE-S3)
   - **Bucket Key:** Enable

4. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `shared`
   - `Purpose` = `terraform-state`

5. Clique em **Create bucket**

---

#### 3.4.2 Criar Bucket para Backups

**Passo a passo no console:**

1. Clique em **Create bucket**
2. Preencha:
   - **Bucket name:** `k8s-platform-backups-prod-{account-id}`
   - **AWS Region:** `us-east-1`
   - ‚úÖ **Block all public access**
   - **Versioning:** Enable
   - **Encryption:** SSE-S3

3. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`
   - `Purpose` = `backups`

4. Clique em **Create bucket**

---

#### 3.4.3 Configurar Lifecycle Policy (Economia)

**Passo a passo no console:**

1. Clique no bucket `k8s-platform-backups-prod-{account-id}`
2. Aba **Management**
3. Clique em **Create lifecycle rule**
4. Preencha:
   - **Lifecycle rule name:** `backup-lifecycle-policy`
   - **Rule scope:** Apply to all objects in the bucket

   **Lifecycle rule actions:**
   - ‚úÖ **Move current versions of objects between storage classes**
   - ‚úÖ **Move noncurrent versions of objects between storage classes**
   - ‚úÖ **Permanently delete noncurrent versions of objects**

   **Transitions:**
   - After 30 days ‚Üí **Standard-IA**
   - After 90 days ‚Üí **Glacier Instant Retrieval**
   - After 365 days ‚Üí **Glacier Deep Archive**

   **Noncurrent version expiration:**
   - After 90 days

5. Clique em **Create rule**

---

#### 3.4.4 Criar Bucket para GitLab Artifacts

**Passo a passo no console:**

1. Clique em **Create bucket**
2. Preencha:
   - **Bucket name:** `k8s-platform-gitlab-artifacts-{account-id}`
   - **AWS Region:** `us-east-1`
   - ‚úÖ **Block all public access**
   - **Versioning:** Disable (artifacts s√£o ef√™meros)
   - **Encryption:** SSE-S3

3. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`
   - `Purpose` = `gitlab-artifacts`

4. Clique em **Create bucket**

---

### üîπ Servi√ßo: KMS (Key Management Service)

> **Contexto:** KMS gerencia chaves de criptografia. Uma chave dedicada para a plataforma permite controle de acesso granular e auditoria.

#### 3.5.1 Criar Customer Managed Key

**Passo a passo no console:**

1. Na barra de busca, digite `KMS` e clique em **Key Management Service**
2. Clique em **Create key**
3. Preencha:

   **Configure key:**
   - **Key type:** Symmetric
   - **Key usage:** Encrypt and decrypt
   - **Advanced options:**
     - **Key material origin:** KMS (AWS KMS key material)
     - **Regionality:** Single-Region key

4. Clique em **Next**

   **Add labels:**
   - **Alias:** `alias/k8s-platform-prod`
   - **Description:** `Chave de criptografia para a plataforma Kubernetes`
   - **Tags:**
     - `Project` = `k8s-platform`
     - `Environment` = `prod`

5. Clique em **Next**

   **Define key administrative permissions:**
   - Selecione os usu√°rios/roles que podem administrar a chave
   - Adicione `terraform-k8s-platform` (usu√°rio criado anteriormente)

6. Clique em **Next**

   **Define key usage permissions:**
   - Adicione as roles:
     - `k8s-platform-eks-cluster-role`
     - `k8s-platform-eks-node-role`

7. Clique em **Next** ‚Üí **Finish**

---

### üîπ Servi√ßo: RDS (PostgreSQL)

> **Contexto:** RDS PostgreSQL hospedar√° os bancos de dados do GitLab, Keycloak e SonarQube. Multi-AZ garante alta disponibilidade em produ√ß√£o.

#### 3.6.1 Criar Inst√¢ncia RDS PostgreSQL

**Passo a passo no console:**

1. Na barra de busca, digite `RDS` e clique em **RDS**
2. Clique em **Create database**
3. Preencha:

   **Choose a database creation method:**
   - Selecione **Standard create**

   **Engine options:**
   - **Engine type:** PostgreSQL
   - **Engine version:** PostgreSQL 15.4-R2 (ou mais recente LTS)

   **Templates:**
   - Selecione **Production**

   **Availability and durability:**
   - Selecione **Multi-AZ DB instance** (para prod)

   **Settings:**
   - **DB instance identifier:** `k8s-platform-prod-postgresql`
   - **Master username:** `postgres_admin`
   - **Credentials management:** Self managed
   - **Master password:** (gere uma senha forte de 32+ caracteres)
   - **Confirm password:** (repita a senha)

   **Instance configuration:**
   - **DB instance class:** Burstable classes (includes t classes)
   - Selecione **db.t3.medium** (2 vCPU, 4 GB RAM)

   **Storage:**
   - **Storage type:** General Purpose SSD (gp3)
   - **Allocated storage:** 100 GB
   - **Storage autoscaling:** ‚úÖ Enable
   - **Maximum storage threshold:** 500 GB

   **Connectivity:**
   - **Compute resource:** Don't connect to an EC2 compute resource
   - **Network type:** IPv4
   - **VPC:** `k8s-platform-prod-vpc`
   - **DB subnet group:** `k8s-platform-prod-db-subnet-group`
   - **Public access:** **No**
   - **VPC security group:** Choose existing
   - **Existing VPC security groups:** Selecione `k8s-platform-prod-rds-sg`
   - **Availability Zone:** No preference

   **Database authentication:**
   - Selecione **Password authentication**

   **Monitoring:**
   - ‚úÖ **Enable Enhanced monitoring**
   - **Monitoring Role:** Create new role
   - **Granularity:** 60 seconds

   **Additional configuration:**
   - **Initial database name:** `platform`
   - **DB parameter group:** default.postgres15
   - **Backup:**
     - ‚úÖ **Enable automated backups**
     - **Backup retention period:** 7 days
     - **Backup window:** Select window ‚Üí `03:00-04:00 UTC`
   - **Encryption:**
     - ‚úÖ **Enable encryption**
     - **AWS KMS key:** Selecione `alias/k8s-platform-prod`
   - **Log exports:** (selecione todos)
     - ‚úÖ PostgreSQL log
     - ‚úÖ Upgrade log
   - **Maintenance:**
     - ‚úÖ **Enable auto minor version upgrade**
     - **Maintenance window:** Select window ‚Üí `sun:04:00-sun:05:00 UTC`
   - **Deletion protection:**
     - ‚úÖ **Enable deletion protection**

4. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`
   - `Owner` = `devops-team`
   - `CostCenter` = `infrastructure`

5. Clique em **Create database**
6. Aguarde a cria√ß√£o (10-15 minutos)

---

#### 3.6.2 Criar Databases Individuais

**Passo a passo no console:**

Ap√≥s a inst√¢ncia estar dispon√≠vel, conecte via cliente PostgreSQL (pgAdmin, DBeaver, ou psql via bastion host) e execute:

```sql
-- Criar databases para cada servi√ßo
CREATE DATABASE gitlab_production;
CREATE DATABASE keycloak;
CREATE DATABASE sonarqube;
CREATE DATABASE harbor;

-- Criar usu√°rios espec√≠ficos (princ√≠pio de menor privil√©gio)
CREATE USER gitlab_user WITH ENCRYPTED PASSWORD 'senha_segura_gitlab_32chars';
CREATE USER keycloak_user WITH ENCRYPTED PASSWORD 'senha_segura_keycloak_32chars';
CREATE USER sonarqube_user WITH ENCRYPTED PASSWORD 'senha_segura_sonar_32chars';
CREATE USER harbor_user WITH ENCRYPTED PASSWORD 'senha_segura_harbor_32chars';

-- Conceder privil√©gios
GRANT ALL PRIVILEGES ON DATABASE gitlab_production TO gitlab_user;
GRANT ALL PRIVILEGES ON DATABASE keycloak TO keycloak_user;
GRANT ALL PRIVILEGES ON DATABASE sonarqube TO sonarqube_user;
GRANT ALL PRIVILEGES ON DATABASE harbor TO harbor_user;
```

---

### üîπ Servi√ßo: ElastiCache (Redis)

> **Contexto:** Redis ser√° usado como cache para GitLab e sess√µes do Keycloak. Cluster mode oferece melhor performance e disponibilidade.

#### 3.7.1 Criar Cluster ElastiCache Redis

**Passo a passo no console:**

1. Na barra de busca, digite `ElastiCache` e clique em **ElastiCache**
2. Clique em **Create cluster** ‚Üí **Create Redis cluster**
3. Preencha:

   **Cluster creation method:**
   - Selecione **Configure and create a new cluster**

   **Cluster mode:**
   - Selecione **Disabled** (para simplificar, ou Enabled para escala)

   **Cluster info:**
   - **Name:** `k8s-platform-prod-redis`
   - **Description:** `Redis cache para plataforma Kubernetes`

   **Location:**
   - Selecione **AWS Cloud**

   **Multi-AZ:**
   - ‚úÖ **Enable** (para produ√ß√£o)

   **Auto-failover:**
   - ‚úÖ **Enable**

   **Node type:**
   - **Family:** t3
   - **Node type:** `cache.t3.medium`

   **Number of replicas:**
   - `2` (1 primary + 2 replicas = 3 nodes)

   **Subnet group settings:**
   - **Subnet group:** Create new
   - **Name:** `k8s-platform-prod-redis-subnet-group`
   - **VPC ID:** `k8s-platform-prod-vpc`
   - **Subnets:** Selecione as 3 subnets de DB

   **Availability Zone placements:**
   - Deixe como **No preference**

   **Security:**
   - **Security groups:** Selecione `k8s-platform-prod-redis-sg`
   - **Encryption at-rest:** ‚úÖ **Enable**
   - **Encryption key:** `alias/k8s-platform-prod`
   - **Encryption in-transit:** ‚úÖ **Enable**

   **Logs:**
   - ‚úÖ **Slow logs**
   - **Log format:** JSON
   - **Destination:** CloudWatch Logs
   - **Log group:** `/aws/elasticache/k8s-platform-prod-redis`

   **Backup:**
   - ‚úÖ **Enable automatic backups**
   - **Backup retention period:** 7 days
   - **Backup window:** `05:00-06:00 UTC`

   **Maintenance:**
   - **Maintenance window:** `sun:06:00-sun:07:00 UTC`
   - ‚úÖ **Auto upgrade minor versions**

4. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`

5. Clique em **Create**

---

### üîπ Servi√ßo: EKS (Elastic Kubernetes Service)

> **Contexto:** EKS √© o cora√ß√£o da plataforma. Node Groups separados permitem isolamento de workloads e otimiza√ß√£o de recursos.

#### 3.8.1 Criar Cluster EKS

**Passo a passo no console:**

1. Na barra de busca, digite `EKS` e clique em **Elastic Kubernetes Service**
2. Clique em **Add cluster** ‚Üí **Create**
3. Preencha:

   **Step 1 - Configure cluster:**

   **Name:**
   - **Name:** `k8s-platform-prod`

   **Kubernetes version:**
   - Selecione a vers√£o mais recente est√°vel (ex: 1.29)

   **Cluster service role:**
   - Selecione `k8s-platform-eks-cluster-role`

   **Secrets encryption:**
   - ‚úÖ **Turn on envelope encryption of Kubernetes secrets**
   - **KMS key:** `alias/k8s-platform-prod`

   **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`
   - `Owner` = `devops-team`

4. Clique em **Next**

   **Step 2 - Specify networking:**

   **VPC:**
   - Selecione `k8s-platform-prod-vpc`

   **Subnets:**
   - Selecione TODAS as subnets privadas:
     - `k8s-platform-prod-subnet-private1-us-east-1a`
     - `k8s-platform-prod-subnet-private2-us-east-1b`
     - `k8s-platform-prod-subnet-private3-us-east-1c`

   **Security groups:**
   - Selecione `k8s-platform-prod-eks-cluster-sg`

   **Cluster endpoint access:**
   - Selecione **Public and private**

   **Advanced settings:**
   - **Public access CIDR:** Adicione apenas os IPs permitidos (ex: IP do seu escrit√≥rio)

5. Clique em **Next**

   **Step 3 - Configure observability:**

   **Control plane logging:**
   - ‚úÖ **API server**
   - ‚úÖ **Audit**
   - ‚úÖ **Authenticator**
   - ‚úÖ **Controller manager**
   - ‚úÖ **Scheduler**

6. Clique em **Next**

   **Step 4 - Select add-ons:**

   Selecione os add-ons padr√£o:
   - ‚úÖ **Amazon VPC CNI** (networking)
   - ‚úÖ **CoreDNS** (DNS interno)
   - ‚úÖ **kube-proxy** (network proxy)
   - ‚úÖ **Amazon EBS CSI Driver** (storage)

7. Clique em **Next**

   **Step 5 - Configure selected add-ons settings:**
   - Deixe as configura√ß√µes padr√£o para todos os add-ons
   - Selecione a vers√£o mais recente de cada um

8. Clique em **Next** ‚Üí **Create**

9. Aguarde a cria√ß√£o (15-20 minutos)

---

#### 3.8.2 Criar Node Group: system

**Passo a passo no console:**

1. Ap√≥s o cluster estar `Active`, clique no nome do cluster
2. Aba **Compute** ‚Üí **Add node group**
3. Preencha:

   **Step 1 - Configure node group:**

   **Name:**
   - **Name:** `system`
   - **Node IAM role:** Selecione `k8s-platform-eks-node-role`

   **Node group scaling configuration:**
   - **Desired size:** 2
   - **Minimum size:** 2
   - **Maximum size:** 4

   **Node group update configuration:**
   - **Maximum unavailable:** Number ‚Üí 1

   **Labels:**
   - `node-type` = `system`
   - `workload` = `platform`

   **Taints:** (deixe vazio para system nodes)

   **Tags:**
   - `Project` = `k8s-platform`
   - `NodeGroup` = `system`

4. Clique em **Next**

   **Step 2 - Set compute and scaling configuration:**

   **AMI type:**
   - Selecione **Amazon Linux 2 (AL2_x86_64)**

   **Capacity type:**
   - Selecione **On-Demand**

   **Instance types:**
   - Selecione **t3.medium**

   **Disk size:**
   - `30` GB

5. Clique em **Next**

   **Step 3 - Specify networking:**

   **Subnets:**
   - Selecione as 3 subnets privadas

   **Configure remote access to nodes:**
   - Selecione **Don't allow remote access to nodes** (use Session Manager)

6. Clique em **Next** ‚Üí **Create**

---

#### 3.8.3 Criar Node Group: workloads

**Passo a passo no console:**

1. Clique em **Add node group**
2. Preencha:

   **Name:** `workloads`
   **Node IAM role:** `k8s-platform-eks-node-role`

   **Scaling:**
   - **Desired:** 3
   - **Min:** 2
   - **Max:** 6

   **Labels:**
   - `node-type` = `workloads`
   - `workload` = `applications`

   **Instance types:** `t3.large`
   **Disk size:** `50` GB

3. Complete os passos e clique em **Create**

---

#### 3.8.4 Criar Node Group: critical

**Passo a passo no console:**

1. Clique em **Add node group**
2. Preencha:

   **Name:** `critical`
   **Node IAM role:** `k8s-platform-eks-node-role`

   **Scaling:**
   - **Desired:** 2
   - **Min:** 2
   - **Max:** 4

   **Labels:**
   - `node-type` = `critical`
   - `workload` = `databases`

   **Taints:**
   - **Key:** `workload`
   - **Value:** `critical`
   - **Effect:** `NoSchedule`

   **Instance types:** `t3.xlarge`
   **Disk size:** `100` GB

3. Complete os passos e clique em **Create**

---

#### 3.8.5 Configurar kubectl para Acessar o Cluster

**Passo a passo via terminal:**

```bash
# Instalar AWS CLI (se n√£o tiver)
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install

# Configurar credenciais
aws configure
# AWS Access Key ID: <sua-key>
# AWS Secret Access Key: <sua-secret>
# Default region name: us-east-1
# Default output format: json

# Atualizar kubeconfig
aws eks update-kubeconfig --region us-east-1 --name k8s-platform-prod

# Verificar conex√£o
kubectl get nodes
```

---

### üîπ Servi√ßo: ALB (Application Load Balancer)

> **Contexto:** O ALB ser√° gerenciado pelo AWS Load Balancer Controller instalado no EKS. Ele cria ALBs automaticamente para Ingress resources.

#### 3.9.1 Instalar AWS Load Balancer Controller

**Passo a passo via terminal:**

```bash
# Criar IAM Policy para o controller
curl -o iam_policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.7.0/docs/install/iam_policy.json

aws iam create-policy \
    --policy-name AWSLoadBalancerControllerIAMPolicy \
    --policy-document file://iam_policy.json

# Criar IRSA (IAM Role for Service Accounts)
eksctl create iamserviceaccount \
  --cluster=k8s-platform-prod \
  --namespace=kube-system \
  --name=aws-load-balancer-controller \
  --role-name AmazonEKSLoadBalancerControllerRole \
  --attach-policy-arn=arn:aws:iam::<ACCOUNT_ID>:policy/AWSLoadBalancerControllerIAMPolicy \
  --approve

# Instalar via Helm
helm repo add eks https://aws.github.io/eks-charts
helm repo update

helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
  -n kube-system \
  --set clusterName=k8s-platform-prod \
  --set serviceAccount.create=false \
  --set serviceAccount.name=aws-load-balancer-controller
```

---

### üîπ Servi√ßo: Route53

> **Contexto:** Route53 gerenciar√° o DNS para todos os servi√ßos da plataforma. Integra√ß√£o com cert-manager permite certificados autom√°ticos.

#### 3.10.1 Criar Hosted Zone

**Passo a passo no console:**

1. Na barra de busca, digite `Route53` e clique em **Route 53**
2. Clique em **Hosted zones** ‚Üí **Create hosted zone**
3. Preencha:
   - **Domain name:** `k8s-platform.seudominio.com.br`
   - **Description:** `DNS zone para plataforma Kubernetes`
   - **Type:** Public hosted zone

4. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`

5. Clique em **Create hosted zone**

6. **IMPORTANTE:** Copie os 4 nameservers (NS) exibidos e configure-os no seu registrador de dom√≠nio

---

### üîπ Servi√ßo: ACM (AWS Certificate Manager)

> **Contexto:** ACM fornece certificados TLS gratuitos e renova√ß√£o autom√°tica. Ser√° usado pelo ALB para HTTPS.

#### 3.11.1 Solicitar Certificado SSL

**Passo a passo no console:**

1. Na barra de busca, digite `ACM` e clique em **Certificate Manager**
2. Clique em **Request certificate**
3. Selecione **Request a public certificate** ‚Üí **Next**
4. Preencha:

   **Domain names:**
   - `*.k8s-platform.seudominio.com.br`
   - `k8s-platform.seudominio.com.br`

   **Validation method:**
   - Selecione **DNS validation (recommended)**

   **Key algorithm:**
   - Selecione **RSA 2048**

5. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`

6. Clique em **Request**

7. Na lista de certificados, clique no certificado pendente
8. Clique em **Create records in Route 53** para valida√ß√£o autom√°tica
9. Aguarde o status mudar para `Issued` (5-30 minutos)

---

### üîπ Servi√ßo: Secrets Manager

> **Contexto:** Secrets Manager armazena credenciais de forma segura com rota√ß√£o autom√°tica. Integra com EKS via External Secrets Operator.

#### 3.12.1 Criar Secret para RDS

**Passo a passo no console:**

1. Na barra de busca, digite `Secrets Manager` e clique em **Secrets Manager**
2. Clique em **Store a new secret**
3. Preencha:

   **Secret type:**
   - Selecione **Credentials for Amazon RDS database**

   **Credentials:**
   - **User name:** `postgres_admin`
   - **Password:** (a senha master do RDS)

   **Database:**
   - Selecione `k8s-platform-prod-postgresql`

   **Encryption key:**
   - Selecione `alias/k8s-platform-prod`

4. Clique em **Next**

   **Secret name and description:**
   - **Secret name:** `k8s-platform/prod/rds/master`
   - **Description:** `Credenciais master do RDS PostgreSQL`

   **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`

5. Clique em **Next**

   **Configure rotation:**
   - ‚úÖ **Automatic rotation**
   - **Rotation schedule:** 30 days
   - **Rotation function:** Create a new Lambda function

6. Clique em **Next** ‚Üí **Store**

---

#### 3.12.2 Criar Secrets para Aplica√ß√µes

Repita o processo para cada aplica√ß√£o:

| Secret Name | Tipo | Conte√∫do |
|-------------|------|----------|
| `k8s-platform/prod/gitlab/db` | Other type of secret | `{"username":"gitlab_user","password":"..."}` |
| `k8s-platform/prod/keycloak/db` | Other type of secret | `{"username":"keycloak_user","password":"..."}` |
| `k8s-platform/prod/sonarqube/db` | Other type of secret | `{"username":"sonarqube_user","password":"..."}` |
| `k8s-platform/prod/redis` | Other type of secret | `{"auth_token":"..."}` |

---

### üîπ Servi√ßo: CloudWatch

> **Contexto:** CloudWatch centraliza logs e m√©tricas AWS. Container Insights oferece observabilidade nativa para EKS.

#### 3.13.1 Criar Log Groups

**Passo a passo no console:**

1. Na barra de busca, digite `CloudWatch` e clique em **CloudWatch**
2. Menu lateral ‚Üí **Logs** ‚Üí **Log groups**
3. Clique em **Create log group**
4. Preencha:
   - **Log group name:** `/aws/eks/k8s-platform-prod/cluster`
   - **Retention setting:** 30 days
   - **KMS key:** `alias/k8s-platform-prod`

5. **Tags:**
   - `Project` = `k8s-platform`
   - `Environment` = `prod`

6. Clique em **Create**

Repita para:
- `/aws/rds/instance/k8s-platform-prod-postgresql/postgresql`
- `/aws/elasticache/k8s-platform-prod-redis`

---

#### 3.13.2 Habilitar Container Insights

**Passo a passo no console:**

1. Em **CloudWatch**, menu lateral ‚Üí **Container Insights**
2. Clique em **View container insights**
3. Se n√£o estiver configurado, clique em **Quick Start**
4. Selecione o cluster `k8s-platform-prod`
5. Siga o wizard para instalar o CloudWatch Agent via Helm:

```bash
# Instalar CloudWatch Agent
FluentBitHttpPort='2020'
FluentBitReadFromHead='Off'
[[ ${FluentBitReadFromHead} = 'On' ]] && FluentBitReadFromTail='Off'|| FluentBitReadFromTail='On'
[[ -z ${FluentBitHttpPort} ]] && FluentBitHttpServer='Off' || FluentBitHttpServer='On'

ClusterName=k8s-platform-prod
RegionName=us-east-1
LogRegion=us-east-1

curl https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/quickstart/cwagent-fluent-bit-quickstart.yaml | sed 's/{{cluster_name}}/'${ClusterName}'/;s/{{region_name}}/'${RegionName}'/;s/{{http_server_toggle}}/"'${FluentBitHttpServer}'"/;s/{{http_server_port}}/"'${FluentBitHttpPort}'"/;s/{{read_from_head}}/"'${FluentBitReadFromHead}'"/;s/{{read_from_tail}}/"'${FluentBitReadFromTail}'"/' | kubectl apply -f -
```

---

### üîπ Servi√ßo: WAF (Web Application Firewall)

> **Contexto:** WAF protege aplica√ß√µes web contra ataques OWASP Top 10 (SQL Injection, XSS, etc.). Ser√° associado ao ALB.

#### 3.14.1 Criar Web ACL

**Passo a passo no console:**

1. Na barra de busca, digite `WAF` e clique em **WAF & Shield**
2. Clique em **Web ACLs** ‚Üí **Create web ACL**
3. Preencha:

   **Step 1 - Describe web ACL:**
   - **Resource type:** Regional resources (Application Load Balancer, API Gateway, etc.)
   - **Region:** US East (N. Virginia)
   - **Name:** `k8s-platform-prod-waf`
   - **Description:** `WAF para prote√ß√£o da plataforma Kubernetes`
   - **CloudWatch metric name:** `k8s-platform-prod-waf`

4. Clique em **Next**

   **Step 2 - Add rules and rule groups:**

   Clique em **Add rules** ‚Üí **Add managed rule groups**

   Selecione os seguintes **AWS managed rule groups** (gratuitos):
   - ‚úÖ **Core rule set (CRS)** - Prote√ß√£o geral
   - ‚úÖ **Known bad inputs** - Inputs maliciosos conhecidos
   - ‚úÖ **SQL database** - SQL Injection
   - ‚úÖ **Linux operating system** - Ataques espec√≠ficos Linux

   **Default action:**
   - Selecione **Allow**

5. Clique em **Next**

   **Step 3 - Set rule priority:**
   - Deixe a ordem padr√£o

6. Clique em **Next**

   **Step 4 - Configure metrics:**
   - ‚úÖ **Enable CloudWatch metrics**
   - ‚úÖ **Enable sampling of requests**

7. Clique em **Next**

   **Step 5 - Review and create:**
   - Revise as configura√ß√µes

8. Clique em **Create web ACL**

---

### üîπ Servi√ßo: AWS Backup

> **Contexto:** AWS Backup centraliza backups de RDS, EBS e outros servi√ßos. Essencial para Disaster Recovery.

#### 3.15.1 Criar Backup Plan

**Passo a passo no console:**

1. Na barra de busca, digite `AWS Backup` e clique em **AWS Backup**
2. Clique em **Backup plans** ‚Üí **Create backup plan**
3. Selecione **Build a new plan**
4. Preencha:

   **Backup plan name:**
   - **Backup plan name:** `k8s-platform-prod-backup-plan`

   **Backup rule configuration:**
   - **Backup rule name:** `daily-backup`
   - **Backup vault:** Create new vault
     - **Vault name:** `k8s-platform-prod-vault`
     - **Encryption key:** `alias/k8s-platform-prod`
   - **Backup frequency:** Daily
   - **Backup window:** Start within 2 hours of 03:00 UTC
   - **Transition to cold storage:** After 30 days
   - **Retention period:** 90 days
   - ‚úÖ **Enable continuous backups for supported resources** (point-in-time recovery)

5. Clique em **Create plan**

---

#### 3.15.2 Associar Recursos ao Backup Plan

**Passo a passo no console:**

1. No backup plan criado, clique em **Assign resources**
2. Preencha:
   - **Resource assignment name:** `k8s-platform-prod-resources`
   - **IAM role:** Default role

   **Define resource selection:**
   - Selecione **Include specific resource types**
   - **Select specific resource types:**
     - ‚úÖ **RDS**
     - ‚úÖ **EBS**
     - ‚úÖ **S3**

   **Refine selection using tags:**
   - **Tag key:** `Project`
   - **Tag value:** `k8s-platform`

3. Clique em **Assign resources**

---

## 4Ô∏è‚É£ Boas Pr√°ticas DevOps AWS (Obrigat√≥rio)

### 4.1 IAM - Menor Privil√©gio

| Pr√°tica | Implementa√ß√£o |
|---------|---------------|
| **Roles por servi√ßo** | Uma IAM Role para cada componente (EKS, Nodes, etc.) |
| **IRSA** | IAM Roles for Service Accounts - pods com permiss√µes espec√≠ficas |
| **Sem root** | Nunca usar conta root para opera√ß√µes |
| **MFA obrigat√≥rio** | Todos os usu√°rios IAM devem ter MFA habilitado |
| **Access Keys rotativas** | Rota√ß√£o a cada 90 dias |

### 4.2 Tags Obrigat√≥rias

**Todas** as resources devem ter estas tags:

| Tag | Descri√ß√£o | Exemplo |
|-----|-----------|---------|
| `Project` | Nome do projeto | `k8s-platform` |
| `Environment` | Ambiente | `prod`, `staging`, `dev` |
| `Owner` | Time respons√°vel | `devops-team` |
| `CostCenter` | Centro de custo | `infrastructure` |
| `ManagedBy` | Gerenciamento | `terraform`, `manual` |

### 4.3 Separa√ß√£o de Ambientes

```
Op√ß√£o 1: VPCs separadas (recomendado)
‚îú‚îÄ‚îÄ VPC-staging (10.1.0.0/16) ‚Üí Conta AWS: staging
‚îî‚îÄ‚îÄ VPC-prod (10.0.0.0/16)    ‚Üí Conta AWS: prod

Op√ß√£o 2: Namespaces no EKS (custo menor)
‚îú‚îÄ‚îÄ k8s-platform-prod
‚îÇ   ‚îú‚îÄ‚îÄ ns: platform-core
‚îÇ   ‚îú‚îÄ‚îÄ ns: platform-core-staging
‚îÇ   ‚îî‚îÄ‚îÄ ...
```

### 4.4 IaC com Terraform

**Estrutura obrigat√≥ria:**

```
platform-provisioning/
‚îú‚îÄ‚îÄ aws/
‚îÇ   ‚îú‚îÄ‚îÄ environments/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prod/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ terraform.tfvars
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ backend.tf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ staging/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ terraform.tfvars
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ backend.tf
‚îÇ   ‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vpc/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ eks/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rds/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ s3/
‚îÇ   ‚îî‚îÄ‚îÄ main.tf
```

**Backend S3 (obrigat√≥rio):**

```hcl
terraform {
  backend "s3" {
    bucket         = "k8s-platform-terraform-state-{account-id}"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-state-lock"
  }
}
```

### 4.5 Logs e Monitoramento

| Componente | Destino | Reten√ß√£o |
|------------|---------|----------|
| EKS Control Plane | CloudWatch Logs | 30 dias |
| Container Logs | Loki (S3 backend) | 90 dias |
| RDS Logs | CloudWatch Logs | 30 dias |
| VPC Flow Logs | CloudWatch Logs | 7 dias |
| CloudTrail | S3 | 365 dias |

---

## 5Ô∏è‚É£ Estrat√©gia de Testes e Valida√ß√£o

### 5.1 VPC e Networking

| Teste | Comando/A√ß√£o | Resultado Esperado |
|-------|--------------|-------------------|
| Subnets criadas | Console VPC ‚Üí Subnets | 9 subnets (3 public + 3 private + 3 db) |
| NAT Gateway | Console VPC ‚Üí NAT Gateways | Status: Available |
| Route Tables | Console VPC ‚Üí Route Tables | Rotas corretas por subnet |
| Conectividade privada | Ping entre subnets | Resposta OK |

### 5.2 EKS Cluster

| Teste | Comando | Resultado Esperado |
|-------|---------|-------------------|
| Cluster ativo | `kubectl cluster-info` | URLs do cluster |
| Nodes prontos | `kubectl get nodes` | Todos os nodes `Ready` |
| Core DNS | `kubectl get pods -n kube-system` | CoreDNS running |
| Networking | `kubectl run test --image=nginx --restart=Never` | Pod running |

### 5.3 RDS e ElastiCache

| Teste | A√ß√£o | Resultado Esperado |
|-------|------|-------------------|
| RDS dispon√≠vel | Console RDS | Status: Available |
| Conex√£o PostgreSQL | `psql -h <endpoint> -U postgres_admin` | Conex√£o bem-sucedida |
| Redis dispon√≠vel | Console ElastiCache | Status: Available |
| Conex√£o Redis | `redis-cli -h <endpoint> PING` | PONG |

### 5.4 Teste de Carga

```bash
# Instalar k6 para teste de carga
kubectl run k6 --image=grafana/k6 --restart=Never -- run - <<EOF
import http from 'k6/http';
export default function () {
  http.get('https://gitlab.k8s-platform.seudominio.com.br');
}
EOF
```

### 5.5 M√©tricas a Observar

| M√©trica | Threshold Warning | Threshold Critical |
|---------|-------------------|-------------------|
| CPU Nodes | >70% | >85% |
| Memory Nodes | >75% | >90% |
| RDS CPU | >70% | >85% |
| RDS Connections | >80% max | >90% max |
| EBS IOPS | >80% provisioned | >90% provisioned |

---

## 6Ô∏è‚É£ Gest√£o de Custos (FinOps)

### 6.1 Ativar AWS Billing e Cost Explorer

**Passo a passo no console:**

1. Clique no nome da conta (canto superior direito)
2. Clique em **Billing Dashboard**
3. Menu lateral ‚Üí **Cost Management** ‚Üí **Cost Explorer**
4. Clique em **Enable Cost Explorer** (se n√£o estiver ativo)
5. Aguarde 24 horas para dados aparecerem

### 6.2 Criar Or√ßamento (Budget)

**Passo a passo no console:**

1. Em **Billing** ‚Üí **Budgets**
2. Clique em **Create budget**
3. Selecione **Customized - Advanced**
4. Preencha:

   **Budget setup:**
   - **Name:** `k8s-platform-monthly-budget`
   - **Period:** Monthly
   - **Budget effective date:** Recurring budget
   - **Start month:** (m√™s atual)
   - **Budgeting method:** Fixed
   - **Enter your budgeted amount:** `1000` (USD)

   **Budget scope:**
   - **Filter:** Tag ‚Üí `Project` = `k8s-platform`

5. Clique em **Next**

   **Configure alerts:**

   **Alert 1:**
   - **Threshold:** 50% of budgeted amount
   - **Trigger:** Actual
   - **Email:** devops-team@empresa.com.br

   **Alert 2:**
   - **Threshold:** 80% of budgeted amount
   - **Trigger:** Actual
   - **Email:** devops-team@empresa.com.br, finops@empresa.com.br

   **Alert 3:**
   - **Threshold:** 100% of budgeted amount
   - **Trigger:** Forecasted
   - **Email:** (todos + ger√™ncia)

6. Clique em **Create budget**

### 6.3 Servi√ßos Mais Cr√≠ticos em Custo

| Servi√ßo | Custo Estimado | % Total | A√ß√£o de Otimiza√ß√£o |
|---------|---------------|---------|-------------------|
| **EC2 (Node Groups)** | $486/m√™s | 44% | Reserved Instances |
| **RDS PostgreSQL** | $215/m√™s | 19% | Rightsizing ou RI |
| **NAT Gateway** | $121/m√™s | 11% | Reduzir para 1 NAT |
| **ALB** | $75/m√™s | 7% | - |
| **ElastiCache** | $50/m√™s | 4% | - |
| **EKS Control Plane** | $73/m√™s | 6% | - |

### 6.4 Estrat√©gias de Redu√ß√£o de Custo

| Estrat√©gia | Economia Estimada | Esfor√ßo |
|------------|------------------|---------|
| Reserved Instances (1 ano) | 31% em EC2/RDS | M√©dio |
| Savings Plans | 15-20% adicional | Baixo |
| 1 NAT Gateway (dev/staging) | $81/m√™s | Baixo |
| Spot Instances (workloads tolerantes) | 70% em EC2 | Alto |
| S3 Lifecycle (Glacier) | 80% em storage antigo | Baixo |
| Rightsizing RDS | At√© $100/m√™s | M√©dio |

---

## 7Ô∏è‚É£ Estrat√©gia de Desligamento e Economia

### 7.1 Ambiente Staging - Scheduled Stop

**Passo a passo para agendar stop dos nodes:**

1. Crie uma Lambda para stop/start:

```python
# lambda_function.py
import boto3

def lambda_handler(event, context):
    action = event.get('action', 'stop')
    client = boto3.client('eks')
    asg = boto3.client('autoscaling')

    # Obter ASGs do node group staging
    asgs = asg.describe_auto_scaling_groups(
        Filters=[{'Name': 'tag:eks:nodegroup-name', 'Values': ['system', 'workloads']}]
    )

    for group in asgs['AutoScalingGroups']:
        if 'staging' in group['AutoScalingGroupName']:
            if action == 'stop':
                asg.update_auto_scaling_group(
                    AutoScalingGroupName=group['AutoScalingGroupName'],
                    MinSize=0, MaxSize=0, DesiredCapacity=0
                )
            else:
                asg.update_auto_scaling_group(
                    AutoScalingGroupName=group['AutoScalingGroupName'],
                    MinSize=2, MaxSize=4, DesiredCapacity=2
                )

    return {'status': 'success', 'action': action}
```

2. Crie EventBridge Rules:

**Stop (20:00 BRT = 23:00 UTC):**
- Cron: `cron(0 23 ? * MON-FRI *)`
- Target: Lambda ‚Üí `eks-staging-scheduler`
- Input: `{"action": "stop"}`

**Start (08:00 BRT = 11:00 UTC):**
- Cron: `cron(0 11 ? * MON-FRI *)`
- Target: Lambda ‚Üí `eks-staging-scheduler`
- Input: `{"action": "start"}`

### 7.2 RDS Stop/Start

**Passo a passo no console:**

1. **RDS** ‚Üí Selecione a inst√¢ncia staging
2. **Actions** ‚Üí **Stop temporarily**
3. **IMPORTANTE:** RDS para automaticamente ap√≥s 7 dias. Para paradas mais longas, use snapshot + delete.

### 7.3 S3 Lifecycle para Logs

```json
{
    "Rules": [
        {
            "ID": "move-to-glacier",
            "Status": "Enabled",
            "Transitions": [
                {
                    "Days": 30,
                    "StorageClass": "STANDARD_IA"
                },
                {
                    "Days": 90,
                    "StorageClass": "GLACIER"
                }
            ],
            "Expiration": {
                "Days": 365
            }
        }
    ]
}
```

### 7.4 Riscos de Esquecer Recursos Ligados

| Recurso | Custo se Esquecido | Mitiga√ß√£o |
|---------|-------------------|-----------|
| **NAT Gateway** | $32/m√™s (idle) | Budget alert |
| **RDS Multi-AZ** | $200+/m√™s | Lambda scheduled stop |
| **EKS Nodes** | $480+/m√™s | ASG MinSize=0 fora hor√°rio |
| **ALB** | $16/m√™s (idle) | Aceitar custo m√≠nimo |
| **EBS n√£o anexados** | Vari√°vel | Tag `DeleteAfter` + Lambda cleanup |

---

## 8Ô∏è‚É£ Checklist Final DevOps

### Seguran√ßa

- [ ] MFA habilitado para todas as contas IAM
- [ ] IAM Roles com menor privil√©gio
- [ ] VPC com subnets p√∫blicas/privadas separadas
- [ ] Security Groups com regras m√≠nimas
- [ ] KMS encryption habilitada em RDS, S3, EBS, EKS secrets
- [ ] WAF configurado e ativo
- [ ] CloudTrail habilitado
- [ ] Secrets no AWS Secrets Manager (n√£o em c√≥digo)
- [ ] Network Policies no Kubernetes
- [ ] Pod Security Standards aplicados

### Custo

- [ ] Budgets configurados com alertas
- [ ] Tags obrigat√≥rias em todos os recursos
- [ ] Cost Explorer ativado
- [ ] Reserved Instances avaliadas
- [ ] S3 Lifecycle configurado
- [ ] Scheduled stop para staging
- [ ] Rightsizing inicial validado

### Monitoramento

- [ ] CloudWatch Logs habilitados (EKS, RDS, ElastiCache)
- [ ] Container Insights ativo
- [ ] M√©tricas customizadas definidas
- [ ] Alertas de threshold configurados
- [ ] Dashboard de custo criado
- [ ] Prometheus + Grafana instalados no cluster

### Testes

- [ ] Conectividade de rede validada
- [ ] EKS cluster acess√≠vel via kubectl
- [ ] RDS conex√£o testada
- [ ] Redis conex√£o testada
- [ ] DNS resolvendo corretamente
- [ ] Certificado SSL v√°lido
- [ ] ALB respondendo

### Desligamento

- [ ] Lambda de scheduled stop criada
- [ ] EventBridge rules configuradas
- [ ] Procedimento de DR documentado
- [ ] Backups validados (restore test)

### Pronto para Produ√ß√£o?

**Status:** ‚ö†Ô∏è **Parcial**

**Justificativa:**

| Crit√©rio | Status | Coment√°rio |
|----------|--------|------------|
| Infraestrutura base | ‚úÖ | VPC, EKS, RDS prontos |
| Seguran√ßa | ‚ö†Ô∏è | Falta validar Network Policies |
| HA/DR | ‚úÖ | Multi-AZ configurado |
| Backups | ‚úÖ | AWS Backup ativo |
| Monitoramento | ‚ö†Ô∏è | Falta Prometheus/Grafana |
| CI/CD | ‚ùå | GitLab n√£o instalado ainda |
| Documenta√ß√£o | ‚úÖ | ADRs e runbooks |

**Pr√≥ximos passos para produ√ß√£o:**
1. Deploy dos dom√≠nios Kubernetes (platform-core ‚Üí cicd-platform)
2. Valida√ß√£o de Network Policies
3. Teste de DR completo
4. Aprova√ß√£o do time de seguran√ßa

---

## Anexos

### A. Comandos √öteis

```bash
# Verificar custos via CLI
aws ce get-cost-and-usage \
    --time-period Start=2026-01-01,End=2026-01-31 \
    --granularity MONTHLY \
    --metrics "BlendedCost" \
    --filter '{"Tags":{"Key":"Project","Values":["k8s-platform"]}}'

# Listar recursos por tag
aws resourcegroupstaggingapi get-resources \
    --tag-filters Key=Project,Values=k8s-platform

# Verificar status do cluster
aws eks describe-cluster --name k8s-platform-prod --query 'cluster.status'

# Verificar nodes
aws eks list-nodegroups --cluster-name k8s-platform-prod
```

### B. Links √öteis

- [AWS EKS Best Practices](https://aws.github.io/aws-eks-best-practices/)
- [AWS Well-Architected Framework](https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html)
- [EKS Workshop](https://www.eksworkshop.com/)
- [AWS Pricing Calculator](https://calculator.aws/)

---

**Documento gerado em:** 2026-01-19
**Autor:** DevOps AWS Specialist
**Vers√£o:** 1.0
**Pr√≥xima revis√£o:** Ap√≥s deploy inicial

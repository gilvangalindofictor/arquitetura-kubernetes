# ğŸ““ DiÃ¡rio de Bordo - ImplementaÃ§Ã£o AWS EKS

**Projeto:** Plataforma Kubernetes Corporativa Multi-DomÃ­nio
**RegiÃ£o:** us-east-1 (N. Virginia)
**InÃ­cio:** 2026-01-22
**ResponsÃ¡vel:** DevOps Team
**Status:** ğŸŸ¡ Em AnÃ¡lise e PreparaÃ§Ã£o

---

## ğŸ“‹ Ãndice

- [Objetivo](#objetivo)
- [Descobertas e AnÃ¡lises](#descobertas-e-anÃ¡lises)
  - [2026-01-22 - AnÃ¡lise de Reaproveitamento de VPC](#2026-01-22---anÃ¡lise-de-reaproveitamento-de-vpc)
- [DecisÃµes TÃ©cnicas](#decisÃµes-tÃ©cnicas)
- [PrÃ³ximos Passos](#prÃ³ximos-passos)
- [ReferÃªncias](#referÃªncias)

---

## ğŸ¯ Objetivo

Este documento registra o progresso da implementaÃ§Ã£o da plataforma Kubernetes na AWS, incluindo descobertas tÃ©cnicas, decisÃµes arquiteturais, problemas encontrados e suas soluÃ§Ãµes. Serve como histÃ³rico vivo do projeto e referÃªncia para auditoria futura.

---

## ğŸ” Descobertas e AnÃ¡lises

### 2026-01-22 - AnÃ¡lise de Reaproveitamento de VPC

#### ğŸ“Œ Contexto

Durante o planejamento inicial, identificamos que jÃ¡ existe uma VPC na conta AWS (`vpc-0b1396a59c417c1f0`) utilizada para outros fins (identificada pelas tags `fictor-*`). Surgiu a questÃ£o: **devemos reaproveitar esta VPC ou criar uma nova?**

#### ğŸ”¬ AnÃ¡lise TÃ©cnica Realizada

**Comandos executados para diagnÃ³stico:**

```bash
# 1. Verificar CIDR da VPC
aws ec2 describe-vpcs --vpc-ids vpc-0b1396a59c417c1f0 --query 'Vpcs[0].CidrBlock'
# Resultado: "10.0.0.0/16"

# 2. Listar subnets existentes
aws ec2 describe-subnets --filters "Name=vpc-id,Values=vpc-0b1396a59c417c1f0" \
    --query 'Subnets[*].[SubnetId,CidrBlock,AvailabilityZone,AvailableIpAddressCount]' \
    --output table

# 3. Verificar NAT Gateways
aws ec2 describe-nat-gateways --filter "Name=vpc-id,Values=vpc-0b1396a59c417c1f0"

# 4. Verificar Internet Gateway
aws ec2 describe-internet-gateways --filters "Name=attachment.vpc-id,Values=vpc-0b1396a59c417c1f0"
```

#### ğŸ“Š Resultado da AnÃ¡lise

**Infraestrutura Atual Identificada:**

```
VPC: 10.0.0.0/16 (vpc-0b1396a59c417c1f0)
â”‚
â”œâ”€â”€ us-east-1a
â”‚   â”œâ”€â”€ subnet-0b5e0cae5658ea993 | 10.0.0.0/20   | PÃºblica  | 4.089 IPs disponÃ­veis
â”‚   â”œâ”€â”€ subnet-0472ab28726cdf745 | 10.0.128.0/20 | Privada  | 4.091 IPs disponÃ­veis
â”‚   â””â”€â”€ NAT Gateway: nat-03512e5ee0642dcf2 (EIP: 52.204.176.103)
â”‚
â”œâ”€â”€ us-east-1b
â”‚   â”œâ”€â”€ subnet-07dca8ceb9882ba66 | 10.0.16.0/20  | PÃºblica  | 4.090 IPs disponÃ­veis
â”‚   â”œâ”€â”€ subnet-0288a67cd352effa7 | 10.0.144.0/20 | Privada  | 4.091 IPs disponÃ­veis
â”‚   â””â”€â”€ NAT Gateway: nat-0be570edfb2eff63e (EIP: 98.90.225.155)
â”‚
â””â”€â”€ Internet Gateway: igw-0a8a1ad9cfddd037e
```

**Naming Convention Identificada:**
- Prefixo: `fictor-*` (workloads legados)
- NAT Gateways: `fictor-nat-public{1,2}-us-east-1{a,b}`
- Internet Gateway: `fictor-igw`

#### âœ… AvaliaÃ§Ã£o por CritÃ©rio

| CritÃ©rio | Requisito Original | VPC Atual | Status | ComentÃ¡rio |
|----------|-------------------|-----------|--------|------------|
| **CIDR Block** | /16 ou maior | âœ… 10.0.0.0/16 | âœ… **PASS** | 65.536 IPs totais |
| **Availability Zones** | 3 AZs (1a, 1b, 1c) | âš ï¸ 2 AZs (1a, 1b) | âš ï¸ **LIMITADO** | **Falta us-east-1c** |
| **Subnets Privadas** | MÃ­nimo 3x /24 | âœ… 2x /20 disponÃ­veis | âœ… **PASS** | 4.091 IPs cada (sobra) |
| **NAT Gateway** | MÃ­nimo 1 | âœ… 2 NATs (Multi-AZ) | âœ… **EXCELENTE** | Alta disponibilidade |
| **Internet Gateway** | ObrigatÃ³rio | âœ… 1 IGW ativo | âœ… **PASS** | Funcional |
| **EspaÃ§o CIDR Livre** | ~3.000 IPs | âœ… ~48.000 IPs livres | âœ… **PASS** | Sobra significativa |

#### ğŸ”´ Problema CrÃ­tico Identificado

**Apenas 2 Availability Zones configuradas**

O plano original ([aws-console-execution-plan.md](aws-console-execution-plan.md)) prevÃª 3 AZs para alta disponibilidade em produÃ§Ã£o:

```
Plano Original (3 AZs):          VPC Atual (2 AZs):
â”œâ”€â”€ us-east-1a âœ…                â”œâ”€â”€ us-east-1a âœ…
â”œâ”€â”€ us-east-1b âœ…                â”œâ”€â”€ us-east-1b âœ…
â””â”€â”€ us-east-1c âœ…                â””â”€â”€ us-east-1c âŒ AUSENTE
```

**Impactos da limitaÃ§Ã£o:**

| Componente | Impacto | Severidade |
|------------|---------|------------|
| EKS Control Plane | âš ï¸ Funciona, mas HA reduzida | MÃ‰DIA |
| Node Groups | âš ï¸ 2 AZs para distribuiÃ§Ã£o | MÃ‰DIA |
| RDS Multi-AZ | âš ï¸ Failover limitado a 2 AZs | MÃ‰DIA |
| ElastiCache | âš ï¸ 2 replicas ao invÃ©s de 3 | BAIXA |
| ALB | âœ… Opera normalmente com 2 AZs | NENHUM |

#### ğŸ“ Mapeamento de CIDR DisponÃ­vel

**EspaÃ§o utilizado pelos workloads legados:**

```
OCUPADO:
- 10.0.0.0/20    â†’ 10.0.15.255   (4.096 IPs) - Subnet pÃºblica 1a
- 10.0.16.0/20   â†’ 10.0.31.255   (4.096 IPs) - Subnet pÃºblica 1b
- 10.0.128.0/20  â†’ 10.0.143.255  (4.096 IPs) - Subnet privada 1a
- 10.0.144.0/20  â†’ 10.0.159.255  (4.096 IPs) - Subnet privada 1b

Total ocupado: 16.384 IPs (25% da VPC)
```

**EspaÃ§o livre para o cluster EKS:**

```
DISPONÃVEL PARA EKS:
- 10.0.32.0/19   â†’ 10.0.63.255   (8.192 IPs)   ğŸŸ¢ Range A
- 10.0.64.0/18   â†’ 10.0.127.255  (16.384 IPs)  ğŸŸ¢ Range B
- 10.0.160.0/19  â†’ 10.0.191.255  (8.192 IPs)   ğŸŸ¢ Range C
- 10.0.192.0/18  â†’ 10.0.255.255  (16.384 IPs)  ğŸŸ¢ Range D

Total disponÃ­vel: ~49.152 IPs (75% da VPC)
```

**ConclusÃ£o:** EspaÃ§o de endereÃ§amento **mais que suficiente** para o cluster EKS + workloads futuros.

#### ğŸ’° AnÃ¡lise de Impacto Financeiro

**ComparaÃ§Ã£o de Custos:**

| CenÃ¡rio | NAT Gateways | Elastic IPs | Custo Mensal | Economia |
|---------|--------------|-------------|--------------|----------|
| **VPC Nova (3 AZs)** | 3 novos | +3 EIPs | +$96/mÃªs | Baseline |
| **Reaproveitar (2 AZs)** | 2 existentes | 0 EIPs novos | **$0** | **-$96/mÃªs** ğŸ‰ |
| **Reaproveitar + 3Âª AZ** | 2 existentes + 1 novo | +1 EIP | +$32/mÃªs | **-$64/mÃªs** |

**Breakdown de custos NAT Gateway:**
- Custo por hora: $0.045/hora
- Custo mensal por NAT: $32.40/mÃªs
- Custo de transferÃªncia de dados: $0.045/GB

**Economia estimada ao reaproveitar:**
- **CenÃ¡rio conservador (2 AZs):** $96/mÃªs = $1.152/ano
- **CenÃ¡rio HA total (3 AZs):** $64/mÃªs = $768/ano

#### ğŸ—ï¸ Arquitetura Proposta: VPC Compartilhada com Isolamento

**Design de subnets para o cluster EKS:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              VPC: 10.0.0.0/16 (vpc-0b1396a59c417c1f0)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  ğŸ”µ WORKLOADS LEGADOS (fictor-*) - NÃƒO MODIFICAR                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ us-east-1a                                                     â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ 10.0.0.0/20    (subnet-0b5e0cae5658ea993)   [PÃºblica]    â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ 10.0.128.0/20  (subnet-0472ab28726cdf745)   [Privada]    â”‚ â”‚
â”‚  â”‚  â””â”€â”€ NAT: nat-03512e5ee0642dcf2                               â”‚ â”‚
â”‚  â”‚                                                                 â”‚ â”‚
â”‚  â”‚ us-east-1b                                                     â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ 10.0.16.0/20   (subnet-07dca8ceb9882ba66)   [PÃºblica]    â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ 10.0.144.0/20  (subnet-0288a67cd352effa7)   [Privada]    â”‚ â”‚
â”‚  â”‚  â””â”€â”€ NAT: nat-0be570edfb2eff63e                               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                      â”‚
â”‚  ğŸŸ¢ CLUSTER EKS (k8s-platform-prod) - NOVO E ISOLADO                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ us-east-1a                                                     â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ 10.0.40.0/24  - eks-public-1a   (ALB, Ingress)          â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ 10.0.50.0/24  - eks-private-1a  (EKS Nodes)             â”‚ â”‚
â”‚  â”‚  â””â”€â”€ 10.0.51.0/24  - eks-db-1a       (RDS, ElastiCache)      â”‚ â”‚
â”‚  â”‚                                                                 â”‚ â”‚
â”‚  â”‚ us-east-1b                                                     â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ 10.0.41.0/24  - eks-public-1b   (ALB, Ingress)          â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ 10.0.52.0/24  - eks-private-1b  (EKS Nodes)             â”‚ â”‚
â”‚  â”‚  â””â”€â”€ 10.0.53.0/24  - eks-db-1b       (RDS, ElastiCache)      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                      â”‚
â”‚  ğŸ”´ OPCIONAL: 3Âª AZ para HA Total                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ us-east-1c (A CRIAR)                                           â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ 10.0.42.0/24  - eks-public-1c   (ALB, Ingress)          â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ 10.0.54.0/24  - eks-private-1c  (EKS Nodes)             â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ 10.0.55.0/24  - eks-db-1c       (RDS, ElastiCache)      â”‚ â”‚
â”‚  â”‚  â””â”€â”€ NAT: nat-XXXXX (novo NAT Gateway - custo: +$32/mÃªs)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**AlocaÃ§Ã£o de CIDR:**

| Subnet | CIDR | IPs | AZ | PropÃ³sito |
|--------|------|-----|----|-----------|
| eks-public-1a | 10.0.40.0/24 | 256 | us-east-1a | ALB, Ingress Controllers |
| eks-public-1b | 10.0.41.0/24 | 256 | us-east-1b | ALB, Ingress Controllers |
| eks-public-1c | 10.0.42.0/24 | 256 | us-east-1c | ALB, Ingress Controllers (opcional) |
| eks-private-1a | 10.0.50.0/24 | 256 | us-east-1a | EKS Worker Nodes |
| eks-private-1b | 10.0.52.0/24 | 256 | us-east-1b | EKS Worker Nodes |
| eks-private-1c | 10.0.54.0/24 | 256 | us-east-1c | EKS Worker Nodes (opcional) |
| eks-db-1a | 10.0.51.0/24 | 256 | us-east-1a | RDS, ElastiCache |
| eks-db-1b | 10.0.53.0/24 | 256 | us-east-1b | RDS, ElastiCache |
| eks-db-1c | 10.0.55.0/24 | 256 | us-east-1c | RDS, ElastiCache (opcional) |

**Total alocado:** 2.304 IPs (1.536 para 2 AZs, 2.304 para 3 AZs)
**Margem de crescimento:** ~46.848 IPs restantes (95% da VPC ainda livre)

#### ğŸ”’ EstratÃ©gia de Isolamento de SeguranÃ§a

**Camadas de isolamento obrigatÃ³rias:**

1. **Security Groups Dedicados:**
   ```
   â”œâ”€â”€ sg-eks-cluster       â†’ Control Plane EKS
   â”œâ”€â”€ sg-eks-nodes         â†’ Worker Nodes (isolado de workloads legados)
   â”œâ”€â”€ sg-eks-rds           â†’ RDS PostgreSQL
   â”œâ”€â”€ sg-eks-redis         â†’ ElastiCache Redis
   â””â”€â”€ sg-eks-alb           â†’ Application Load Balancer
   ```

2. **Network Policies (Kubernetes):**
   - Default deny-all por namespace
   - Whitelist explÃ­cita de comunicaÃ§Ã£o pod-to-pod
   - Bloqueio de trÃ¡fego para subnets legadas (`10.0.0.0/20`, `10.0.16.0/20`, etc.)

3. **Route Tables Separadas:**
   - Route table dedicada para subnets EKS privadas
   - AssociaÃ§Ã£o aos NAT Gateways existentes (reaproveitamento)
   - Zero modificaÃ§Ã£o nas route tables de workloads legados

4. **Tags de IdentificaÃ§Ã£o:**
   ```json
   {
     "Project": "k8s-platform",
     "Environment": "prod",
     "Owner": "devops-team",
     "ManagedBy": "terraform",
     "IsolationZone": "eks-cluster"
   }
   ```

#### âš ï¸ Riscos Identificados e MitigaÃ§Ãµes

| Risco | Probabilidade | Impacto | MitigaÃ§Ã£o |
|-------|---------------|---------|-----------|
| **Conflito de rotas** | BAIXO | ALTO | Route tables dedicadas, zero sobreposiÃ§Ã£o de CIDR |
| **ComunicaÃ§Ã£o nÃ£o autorizada** | MÃ‰DIO | ALTO | Security Groups rÃ­gidos + Network Policies |
| **ExaustÃ£o de IPs** | MUITO BAIXO | MÃ‰DIO | Monitoramento de uso via CloudWatch |
| **Falha de AZ (2 AZs)** | MÃ‰DIO | MÃ‰DIO | Adicionar 3Âª AZ ou aceitar RTO/RPO maior |
| **Impacto em workloads legados** | BAIXO | CRÃTICO | Zero alteraÃ§Ã£o em subnets/SGs existentes |
| **Blast radius de incidente** | BAIXO | ALTO | Isolamento por Security Groups + Network ACLs |

**MitigaÃ§Ã£o prioritÃ¡ria:**
- âœ… Criar Security Groups ANTES de qualquer recurso EKS
- âœ… Testar isolamento com instÃ¢ncia EC2 de teste
- âœ… Documentar todas as alteraÃ§Ãµes em route tables
- âš ï¸ Avaliar criaÃ§Ã£o de 3Âª AZ para produÃ§Ã£o crÃ­tica

---

## ğŸ¯ DecisÃµes TÃ©cnicas

### DecisÃ£o #001: Reaproveitamento de VPC Existente

**Data:** 2026-01-22
**Decisores:** DevOps Team + Arquiteto de SoluÃ§Ãµes
**Status:** âœ… **APROVADO COM CONDIÃ‡Ã•ES**

**DecisÃ£o:**
Reaproveitar a VPC existente (`vpc-0b1396a59c417c1f0`) para o cluster EKS, criando subnets dedicadas e isoladas dos workloads legados.

**Justificativa:**
1. âœ… Economia de $64-96/mÃªs em NAT Gateways
2. âœ… CIDR /16 com 75% de espaÃ§o livre (~48.000 IPs)
3. âœ… Infraestrutura de rede jÃ¡ estabelecida (NAT, IGW)
4. âœ… Isolamento tÃ©cnico viÃ¡vel via Security Groups + Network Policies
5. âš ï¸ LimitaÃ§Ã£o de 2 AZs aceitÃ¡vel para fase inicial (pode escalar para 3)

**CondiÃ§Ãµes obrigatÃ³rias:**
- [ ] Criar 6 novas subnets dedicadas (public, private, db Ã— 2 AZs)
- [ ] Security Groups completamente isolados (zero comunicaÃ§Ã£o com `fictor-*`)
- [ ] Network Policies Kubernetes com default deny-all
- [ ] Route tables dedicadas sem impacto em workloads legados
- [ ] Monitoramento de uso de IPs via CloudWatch
- [ ] DocumentaÃ§Ã£o de toda a segmentaÃ§Ã£o de rede

**Alternativas consideradas:**
1. **VPC Nova Dedicada:** Rejeitada (custo adicional $96/mÃªs sem benefÃ­cio tÃ©cnico proporcional)
2. **VPC Peering:** Rejeitada (complexidade desnecessÃ¡ria para este cenÃ¡rio)
3. **VPC Compartilhada (ESCOLHIDA):** Economia + isolamento adequado

**Impacto:**
- ğŸ’° Financeiro: Economia de ~$768-1.152/ano
- ğŸ• Timeline: Zero atraso (infraestrutura base jÃ¡ existe)
- ğŸ”’ SeguranÃ§a: Risco BAIXO com isolamento adequado
- ğŸ—ï¸ Arquitetura: FlexÃ­vel para adicionar 3Âª AZ no futuro

**ValidaÃ§Ã£o:**
- [ ] AprovaÃ§Ã£o do time de seguranÃ§a
- [ ] Teste de isolamento de rede
- [ ] ValidaÃ§Ã£o de capacidade de IPs

---

### DecisÃ£o #002: Arquitetura com 2 Availability Zones (fase inicial)

**Data:** 2026-01-22
**Decisores:** DevOps Team + Especialista AWS
**Status:** âœ… **APROVADO DEFINITIVAMENTE**

**DecisÃ£o:**
Iniciar com 2 Availability Zones (us-east-1a, us-east-1b) ao invÃ©s das 3 AZs previstas no plano original, com possibilidade de expansÃ£o futura sem downtime.

**Contexto do negÃ³cio:**
Este projeto Ã© uma **plataforma de engenharia/esteira de tecnologia** (GitLab, ArgoCD, SonarQube, Harbor, Keycloak), **NÃƒO** sÃ£o workloads crÃ­ticos de produÃ§Ã£o voltados para usuÃ¡rios finais. As ferramentas servem times internos de desenvolvimento que toleram breves interrupÃ§Ãµes planejadas ou nÃ£o.

**Justificativa tÃ©cnica:**
1. âœ… VPC atual (`vpc-0b1396a59c417c1f0`) sÃ³ tem infraestrutura em 2 AZs
2. âœ… Economia de $32/mÃªs (1 NAT Gateway a menos) = **$384/ano**
3. âœ… HA reduzida aceitÃ¡vel para plataforma DevOps nÃ£o-crÃ­tica
4. âœ… Possibilidade de escalar para 3Âª AZ **SEM downtime** no futuro
5. âœ… Time-to-market mais rÃ¡pido (menos recursos para configurar)
6. âœ… ValidaÃ§Ã£o da stack completa com menor investimento inicial

**Infraestrutura atual reaproveitada:**
```
vpc-0b1396a59c417c1f0 (10.0.0.0/16)
â”œâ”€â”€ NAT Gateway 1: nat-03512e5ee0642dcf2 (us-east-1a) â†’ 52.204.176.103
â”œâ”€â”€ NAT Gateway 2: nat-0be570edfb2eff63e (us-east-1b) â†’ 98.90.225.155
â””â”€â”€ Internet Gateway: igw-0a8a1ad9cfddd037e

âœ… BenefÃ­cio: Reaproveitamento de $96/mÃªs em NAT Gateways jÃ¡ pagos
```

**AnÃ¡lise de Pontos Fortes e Fracos:**

#### âœ… **PONTOS FORTES**

| Aspecto | BenefÃ­cio | Impacto |
|---------|-----------|---------|
| **Custo-benefÃ­cio** | Economia de $384-1.152/ano sem perda funcional significativa | ğŸŸ¢ ALTO |
| **Reaproveitamento de recursos** | NAT Gateways e IGW jÃ¡ existentes e pagos | ğŸŸ¢ ALTO |
| **Simplicidade inicial** | 6 subnets ao invÃ©s de 9, menos complexidade para debugar | ğŸŸ¢ MÃ‰DIO |
| **Velocidade de deploy** | Menos recursos = deploy mais rÃ¡pido, gera valor antes | ğŸŸ¢ MÃ‰DIO |
| **Flexibilidade** | ExpansÃ£o para 3 AZs sem downtime quando necessÃ¡rio | ğŸŸ¢ ALTO |
| **EspaÃ§o CIDR abundante** | 75% da VPC livre (~48.000 IPs) para crescimento | ğŸŸ¢ ALTO |
| **Isolamento viÃ¡vel** | Security Groups dedicados garantem separaÃ§Ã£o de workloads legados | ğŸŸ¢ ALTO |
| **HA suficiente para DevOps** | EKS Control Plane ainda Ã© tolerante a falhas com 2 AZs | ğŸŸ¡ MÃ‰DIO |
| **RDS Multi-AZ funcional** | Failover automÃ¡tico entre us-east-1a â†” us-east-1b | ğŸŸ¢ MÃ‰DIO |
| **Risk mitigation** | Possibilidade de adicionar 3Âª AZ em 2-3 horas, zero downtime | ğŸŸ¢ ALTO |

**Economia total estimada:**
- **Ano 1 (2 AZs):** $1.152 economizado vs criar VPC nova
- **ApÃ³s expansÃ£o (3 AZs):** $768/ano economizado vs criar VPC nova
- **ROI da expansÃ£o:** Se houver 1+ incidente de AZ/ano, adicionar 3Âª AZ vale a pena

#### âš ï¸ **PONTOS FRACOS (Riscos Aceitos)**

| Risco | Probabilidade | Impacto Real | Severidade | MitigaÃ§Ã£o |
|-------|---------------|--------------|------------|-----------|
| **Falha de 1 AZ** | BAIXO (~1-2x/ano na AWS) | DegradaÃ§Ã£o de performance | ğŸŸ¡ MÃ‰DIA | AceitÃ¡vel para DevOps tools |
| **Capacidade reduzida** | BAIXO (sÃ³ em falha de AZ) | 50% de nodes disponÃ­veis | ğŸŸ¡ MÃ‰DIA | Cluster continua operando |
| **RDS failover limitado** | MUITO BAIXO | Apenas 1 standby disponÃ­vel | ğŸŸ¢ BAIXA | Multi-AZ ainda funciona |
| **Redis com 1 replica** | BAIXO | Cache miss temporÃ¡rio | ğŸŸ¢ BAIXA | Dados nÃ£o sÃ£o persistentes |
| **RTO/RPO maior** | BAIXO | RecuperaÃ§Ã£o pode levar mais tempo | ğŸŸ¡ MÃ‰DIA | Documentar runbooks |
| **SLA reduzido** | N/A | ~99.5% ao invÃ©s de 99.9% | ğŸŸ¡ MÃ‰DIA | AceitÃ¡vel para esteira interna |

**Impacto em cenÃ¡rio de falha de 1 AZ:**

| Componente | Comportamento com 2 AZs | Impacto nos UsuÃ¡rios |
|------------|------------------------|---------------------|
| **EKS Control Plane** | âœ… Continua operando normalmente | ğŸŸ¢ Nenhum |
| **Worker Nodes** | âš ï¸ 50% de capacidade (1 AZ restante) | ğŸŸ¡ GitLab pode ficar lento |
| **RDS PostgreSQL** | âœ… Failover automÃ¡tico para AZ saudÃ¡vel | ğŸŸ¢ ~30s de interrupÃ§Ã£o |
| **ElastiCache Redis** | âš ï¸ 1 replica restante (de 2) | ğŸŸ¡ Cache pode ter miss temporÃ¡rio |
| **ALB** | âœ… Roteia 100% para AZ saudÃ¡vel | ğŸŸ¢ Nenhum |
| **GitLab** | âš ï¸ Pods redistribuÃ­dos, pode ter fila | ğŸŸ¡ Push/clone podem demorar |
| **ArgoCD/Harbor** | âš ï¸ Pods redistribuÃ­dos automaticamente | ğŸŸ¡ Deploy pode atrasar 5-10 min |

**FrequÃªncia histÃ³rica de falhas de AZ na AWS:**
- Incidentes por ano: ~1-2 eventos globais
- DuraÃ§Ã£o mÃ©dia: 30 minutos - 4 horas
- Probabilidade de afetar us-east-1a ou 1b: <0.1%

**Custo de indisponibilidade calculado:**
```
CenÃ¡rio conservador: Falha de 1 AZ por 2 horas/ano
â”œâ”€â”€ Desenvolvedores afetados: ~30
â”œâ”€â”€ Custo/hora mÃ©dio: $50
â”œâ”€â”€ Perda de produtividade: 30 Ã— 2h Ã— $50 = $3.000
â””â”€â”€ Investimento no 3Âº NAT: $384/ano

ROI: Se houver 1 incidente/ano com 2h+ de duraÃ§Ã£o, vale adicionar 3Âª AZ
```

**ConclusÃ£o sobre pontos fracos:**
- âš ï¸ Riscos sÃ£o **ACEITÃVEIS** para plataforma DevOps interna
- âœ… UsuÃ¡rios (desenvolvedores) toleram breves interrupÃ§Ãµes
- âœ… NÃ£o hÃ¡ SLA contratual com penalidades financeiras
- âœ… Ferramentas nÃ£o sÃ£o revenue-generating (nÃ£o afetam clientes finais)

#### ğŸ¯ **AnÃ¡lise Comparativa: 2 AZs vs 3 AZs**

| CritÃ©rio | 2 AZs (Escolhido) | 3 AZs (Futuro) | Vencedor |
|----------|-------------------|----------------|----------|
| **Custo inicial** | $700/mÃªs | $732/mÃªs | ğŸ† 2 AZs |
| **HA para DevOps** | âœ… Suficiente | âœ… Excelente | ğŸ¤ Empate |
| **HA para ProduÃ§Ã£o** | âš ï¸ Limitado | âœ… Ideal | ğŸ† 3 AZs |
| **Complexidade** | âœ… Menor | âš ï¸ Maior | ğŸ† 2 AZs |
| **Time-to-market** | âœ… RÃ¡pido | âš ï¸ Normal | ğŸ† 2 AZs |
| **Blast radius** | âš ï¸ 50% em falha | âœ… 33% em falha | ğŸ† 3 AZs |
| **EsforÃ§o de expansÃ£o** | N/A | âœ… 2-3h, zero downtime | ğŸ† 2 AZs |

**EstratÃ©gia vencedora:** ComeÃ§ar com 2 AZs, escalar quando necessÃ¡rio.

**Riscos aceitos formalmente:**
- âš ï¸ RTO/RPO ligeiramente maior em caso de falha de AZ (aceitÃ¡vel)
- âš ï¸ SLA interno de ~99.5% ao invÃ©s de 99.9% (aceitÃ¡vel para DevOps)
- âš ï¸ DegradaÃ§Ã£o de performance temporÃ¡ria em falha de AZ (aceitÃ¡vel)

**Plano de evoluÃ§Ã£o:**
- **Fase 1 (Q1 2026 - atual):** 2 AZs - ValidaÃ§Ã£o e onboarding de times
- **Fase 2 (Q2-Q3 2026 - condicional):** Adicionar 3Âª AZ se:
  - [ ] Cluster hospedar aplicaÃ§Ãµes crÃ­ticas de produÃ§Ã£o
  - [ ] HistÃ³rico de incidentes de rede/infra (>2 por trimestre)
  - [ ] >50 usuÃ¡rios ativos diÃ¡rios dependendo da plataforma
  - [ ] Compliance/auditoria exigir HA documentada
  - [ ] Budget aprovado para custo adicional (+$32/mÃªs)
- **CritÃ©rio de upgrade:** 2 ou mais condiÃ§Ãµes acima verdadeiras

**Processo de expansÃ£o (quando necessÃ¡rio):**
```bash
# Processo validado pelo especialista AWS: 2-3 horas, ZERO downtime
1. Criar 3 novas subnets em us-east-1c (public, private, db)
2. Criar NAT Gateway em us-east-1c (+$32/mÃªs)
3. Atualizar Node Groups para incluir 1c (rolling update automÃ¡tico)
4. Adicionar subnet 1c aos DB Subnet Groups
5. Validar distribuiÃ§Ã£o de pods e nodes

âœ… Resultado: Cluster expande de 2â†’3 AZs sem interromper workloads
```

**ReversÃ£o:**
Adicionar 3Âª AZ pode ser feito a qualquer momento sem impacto nos workloads existentes. Processo Ã© **aditivo** (apenas cria recursos novos), nÃ£o requer alteraÃ§Ã£o dos existentes.

---

### DecisÃ£o #003: Estrutura de DiretÃ³rios Terraform

**Data:** 2026-01-22
**Decisores:** DevOps Team + Especialista DevOps
**Status:** âœ… **APROVADO**

**DecisÃ£o:**
Utilizar a estrutura `platform-provisioning/aws/kubernetes/terraform/` existente, expandindo com novos mÃ³dulos e separaÃ§Ã£o por ambientes.

**LocalizaÃ§Ã£o Base:**
```
/home/gilvangalindo/projects/Arquitetura/Kubernetes/platform-provisioning/aws/kubernetes/terraform/
```

**Estrutura Aprovada:**

```
platform-provisioning/aws/
â”‚
â”œâ”€â”€ README.md                                    # DocumentaÃ§Ã£o geral AWS
â”‚
â”œâ”€â”€ kubernetes/
â”‚   â”œâ”€â”€ terraform/
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ environments/                        # ğŸ†• Ambientes isolados
â”‚   â”‚   â”‚   â”œâ”€â”€ prod/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ backend.tf                   # S3 backend (state remoto)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ main.tf                      # OrquestraÃ§Ã£o de mÃ³dulos
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ terraform.tfvars             # VariÃ¡veis de produÃ§Ã£o
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚   â”‚   â””â”€â”€ staging/
â”‚   â”‚   â”‚       â”œâ”€â”€ backend.tf
â”‚   â”‚   â”‚       â”œâ”€â”€ main.tf
â”‚   â”‚   â”‚       â”œâ”€â”€ terraform.tfvars
â”‚   â”‚   â”‚       â””â”€â”€ README.md
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ modules/                             # MÃ³dulos reutilizÃ¡veis
â”‚   â”‚   â”‚   â”œâ”€â”€ vpc/                             # âœ… Existe
â”‚   â”‚   â”‚   â”œâ”€â”€ subnets/                         # ğŸ†• Subnets EKS dedicadas
â”‚   â”‚   â”‚   â”œâ”€â”€ security-groups/                 # ğŸ†• SGs isolados
â”‚   â”‚   â”‚   â”œâ”€â”€ eks/                             # âœ… Existe (atualizar)
â”‚   â”‚   â”‚   â”œâ”€â”€ rds/                             # ğŸ†• PostgreSQL Multi-AZ
â”‚   â”‚   â”‚   â”œâ”€â”€ elasticache/                     # ğŸ†• Redis Cluster
â”‚   â”‚   â”‚   â”œâ”€â”€ s3/                              # âœ… Existe (expandir)
â”‚   â”‚   â”‚   â”œâ”€â”€ iam/                             # âœ… Existe (expandir)
â”‚   â”‚   â”‚   â”œâ”€â”€ kms/                             # ğŸ†• Encryption Keys
â”‚   â”‚   â”‚   â”œâ”€â”€ secrets-manager/                 # ğŸ†• AWS Secrets Manager
â”‚   â”‚   â”‚   â””â”€â”€ route53/                         # ğŸ†• DNS Management
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ main.tf                              # âœ… Existe (atualizar)
â”‚   â”‚   â”œâ”€â”€ provider.tf                          # ğŸ†• AWS Provider config
â”‚   â”‚   â”œâ”€â”€ versions.tf                          # ğŸ†• Terraform/Provider versions
â”‚   â”‚   â”œâ”€â”€ variables.tf                         # âœ… Existe (expandir)
â”‚   â”‚   â”œâ”€â”€ outputs.tf                           # âœ… Existe (expandir)
â”‚   â”‚   â””â”€â”€ README.md                            # ğŸ†• InstruÃ§Ãµes detalhadas
â”‚   â”‚
â”‚   â””â”€â”€ docs/
â”‚       â”œâ”€â”€ architecture.md                      # ğŸ†• Arquitetura AWS
â”‚       â”œâ”€â”€ networking.md                        # ğŸ†• Networking detalhado
â”‚       â”œâ”€â”€ runbook.md                           # ğŸ†• Procedimentos operacionais
â”‚       â””â”€â”€ troubleshooting.md                   # ğŸ†• SoluÃ§Ã£o de problemas
â”‚
â””â”€â”€ scripts/                                     # ğŸ†• Scripts auxiliares
    â”œâ”€â”€ setup-terraform.sh                       # Setup inicial
    â”œâ”€â”€ create-backend-bucket.sh                 # Criar S3 backend
    â”œâ”€â”€ validate-vpc.sh                          # Validar VPC existente
    â””â”€â”€ apply-with-approval.sh                   # Terraform apply interativo
```

**Justificativa:**

1. âœ… **Aproveita estrutura existente:** 4 mÃ³dulos jÃ¡ criados (vpc, eks, s3, iam)
2. âœ… **SeparaÃ§Ã£o de ambientes:** `environments/` para isolamento de prod/staging
3. âœ… **ModularizaÃ§Ã£o granular:** Cada componente em mÃ³dulo dedicado
4. âœ… **Alinhamento com ADRs:** Segue ADR-020 (cloud-specific separado)
5. âœ… **Escalabilidade:** FÃ¡cil adicionar novos mÃ³dulos no futuro

**MÃ³dulos Novos a Criar:**

| MÃ³dulo | Prioridade | Sprint | FunÃ§Ã£o |
|--------|-----------|--------|--------|
| `subnets/` | ğŸ”´ ALTA | Sprint 1 | Criar 6 subnets EKS (2 AZs) |
| `security-groups/` | ğŸ”´ ALTA | Sprint 1 | 5 SGs isolados |
| `kms/` | ğŸ”´ ALTA | Sprint 1 | Customer managed key |
| `rds/` | ğŸŸ¡ MÃ‰DIA | Sprint 2 | PostgreSQL Multi-AZ |
| `elasticache/` | ğŸŸ¡ MÃ‰DIA | Sprint 2 | Redis Cluster |
| `secrets-manager/` | ğŸŸ¡ MÃ‰DIA | Sprint 3 | Secrets centralizados |
| `route53/` | ğŸŸ¢ BAIXA | Sprint 3 | DNS management |

**MÃ³dulos Existentes a Atualizar:**

| MÃ³dulo | AÃ§Ã£o | Sprint |
|--------|------|--------|
| `eks/` | Adicionar 3 node groups | Sprint 2 |
| `s3/` | Adicionar buckets (backups, artifacts) | Sprint 2 |
| `iam/` | Adicionar IRSA roles | Sprint 3 |

**Plano de ImplementaÃ§Ã£o:**

#### **SPRINT 1: Networking Foundation** (Semana 1)

**Objetivo:** Criar base de rede isolada para o cluster EKS

```
Dia 1-2: Setup Inicial
â”œâ”€â”€ environments/prod/backend.tf           # Backend S3 configurado
â”œâ”€â”€ environments/prod/main.tf              # OrquestraÃ§Ã£o inicial
â”œâ”€â”€ environments/prod/terraform.tfvars     # VariÃ¡veis de produÃ§Ã£o
â””â”€â”€ scripts/create-backend-bucket.sh       # Script de setup

Dia 3-4: MÃ³dulos de Rede
â”œâ”€â”€ modules/kms/                           # Encryption primeiro
â”œâ”€â”€ modules/security-groups/               # SGs antes de recursos
â””â”€â”€ modules/subnets/                       # Subnets EKS dedicadas

Dia 5: ValidaÃ§Ã£o
â”œâ”€â”€ terraform plan                         # Revisar mudanÃ§as
â”œâ”€â”€ terraform apply                        # Criar recursos
â””â”€â”€ scripts/validate-vpc.sh                # Validar isolamento
```

**Entregas Sprint 1:**
- âœ… 6 subnets EKS criadas (10.0.40-53.0/24)
- âœ… 5 Security Groups configurados
- âœ… KMS key para encryption
- âœ… Route tables associadas aos NAT Gateways existentes
- âœ… Tags Kubernetes aplicadas
- âœ… Isolamento de rede validado

#### **SPRINT 2: Compute & Databases** (Semana 2)

**Objetivo:** Provisionar cluster EKS e bancos de dados

```
Dia 1-2: EKS Cluster
â”œâ”€â”€ modules/eks/ (atualizado)
â”‚   â”œâ”€â”€ main.tf                            # Cluster config
â”‚   â”œâ”€â”€ node-groups.tf                     # 3 node groups
â”‚   â””â”€â”€ addons.tf                          # AWS LB Controller, EBS CSI

Dia 3-4: Databases
â”œâ”€â”€ modules/rds/                           # PostgreSQL Multi-AZ (2 AZs)
â”œâ”€â”€ modules/elasticache/                   # Redis Cluster (2 AZs)
â””â”€â”€ modules/s3/ (atualizado)               # Novos buckets

Dia 5: ValidaÃ§Ã£o
â”œâ”€â”€ kubectl get nodes                      # Verificar nodes
â”œâ”€â”€ kubectl get storageclasses             # Verificar storage
â””â”€â”€ Testar conectividade EKS â†’ RDS/Redis
```

**Entregas Sprint 2:**
- âœ… Cluster EKS operacional (1.29)
- âœ… 7 worker nodes distribuÃ­dos (2 AZs)
- âœ… RDS PostgreSQL Multi-AZ disponÃ­vel
- âœ… ElastiCache Redis Cluster ativo
- âœ… S3 buckets criados (backups, artifacts, state)
- âœ… kubectl configurado e testado

#### **SPRINT 3: Secrets & Security** (Semana 3)

**Objetivo:** Configurar gestÃ£o de secrets e seguranÃ§a

```
Dia 1-2: Secrets Management
â”œâ”€â”€ modules/secrets-manager/               # Secrets para RDS, Redis
â””â”€â”€ modules/iam/ (atualizado)              # IRSA roles

Dia 3-4: DNS e DocumentaÃ§Ã£o
â”œâ”€â”€ modules/route53/                       # DNS management
â”œâ”€â”€ docs/architecture.md                   # Arquitetura AWS
â”œâ”€â”€ docs/networking.md                     # Networking detalhado
â””â”€â”€ docs/runbook.md                        # Procedimentos operacionais

Dia 5: Environment Staging
â””â”€â”€ environments/staging/                  # Replicar estrutura prod
```

**Entregas Sprint 3:**
- âœ… AWS Secrets Manager configurado
- âœ… IRSA roles para Service Accounts
- âœ… Route53 hosted zone criada
- âœ… DocumentaÃ§Ã£o completa
- âœ… Ambiente staging funcional

#### **SPRINT 4: Observability & Validation** (Semana 4)

**Objetivo:** Habilitar observabilidade e validar plataforma

```
Dia 1-2: Observability
â”œâ”€â”€ CloudWatch Container Insights          # Habilitado
â”œâ”€â”€ VPC Flow Logs                          # Configurado
â””â”€â”€ CloudWatch Alarms                      # Alertas bÃ¡sicos

Dia 3-4: Security Hardening
â”œâ”€â”€ Network Policies                       # Default deny-all
â”œâ”€â”€ Pod Security Standards                 # Enforced
â””â”€â”€ Security Groups Review                 # Auditoria

Dia 5: Validation & Handoff
â”œâ”€â”€ Testes de carga                        # Stress test
â”œâ”€â”€ Disaster Recovery test                 # Simular falha de AZ
â””â”€â”€ DocumentaÃ§Ã£o de handoff                # TransferÃªncia para time
```

**Entregas Sprint 4:**
- âœ… Observabilidade AWS configurada
- âœ… Security hardening aplicado
- âœ… Plataforma validada e documentada
- âœ… Pronta para deploy dos domÃ­nios

**Outputs Terraform Esperados:**

```hcl
# Cluster EKS
cluster_endpoint          # URL Kubernetes API
cluster_ca_certificate    # Certificado CA
cluster_name              # k8s-platform-prod
cluster_version           # 1.29

# Networking
vpc_id                    # vpc-0b1396a59c417c1f0
private_subnet_ids        # [subnet-eks-private-1a, subnet-eks-private-1b]
public_subnet_ids         # [subnet-eks-public-1a, subnet-eks-public-1b]
db_subnet_ids             # [subnet-eks-db-1a, subnet-eks-db-1b]

# Databases
rds_endpoint              # hostname:5432
redis_endpoint            # hostname:6379

# Storage
s3_bucket_backups         # Nome do bucket
s3_bucket_artifacts       # Nome do bucket

# IAM
eks_cluster_role_arn      # ARN da role
eks_node_role_arn         # ARN da role

# Encryption
kms_key_id                # alias/k8s-platform-prod
```

**ValidaÃ§Ã£o:**
- [ ] Terraform plan sem erros
- [ ] Terraform apply bem-sucedido
- [ ] Todos os outputs disponÃ­veis
- [ ] kubectl get nodes retorna todos os nodes
- [ ] Conectividade EKS â†’ RDS testada
- [ ] Conectividade EKS â†’ Redis testada
- [ ] Isolamento de rede validado
- [ ] DocumentaÃ§Ã£o completa

---

## ğŸ“‹ PrÃ³ximos Passos

### âœ… ConcluÃ­do
- [x] AnÃ¡lise de viabilidade da VPC existente
- [x] Mapeamento de CIDR e subnets
- [x] ValidaÃ§Ã£o de NAT Gateways e Internet Gateway
- [x] AnÃ¡lise de custos comparativa
- [x] Design de arquitetura com isolamento
- [x] CriaÃ§Ã£o de documento de contexto (este arquivo)
- [x] Scripts de Marco 0 (engenharia reversa + incremental)
- [x] ValidaÃ§Ã£o de ambiente WSL para testes locais

### ğŸ”„ Em Progresso
- [ ] EstruturaÃ§Ã£o de mÃ³dulos Terraform
- [ ] ExecuÃ§Ã£o do script de engenharia reversa

### ğŸ“… Planejado

**SPRINT 1: PreparaÃ§Ã£o de Rede (Semana 1)**
- [ ] Criar 6 subnets EKS (public, private, db Ã— 2 AZs)
- [ ] Configurar route tables dedicadas
- [ ] Adicionar tags Kubernetes nas subnets
- [ ] Criar Security Groups isolados
- [ ] Validar conectividade e isolamento

**SPRINT 2: Deploy EKS Cluster (Semana 2)**
- [ ] Criar cluster EKS com subnets privadas
- [ ] Deploy de 3 Node Groups (system, workloads, critical)
- [ ] Instalar AWS Load Balancer Controller
- [ ] Configurar kubectl local
- [ ] Validar conectividade ao cluster

**SPRINT 3: ServiÃ§os de Dados (Semana 3)**
- [ ] Criar RDS PostgreSQL Multi-AZ (2 AZs)
- [ ] Criar ElastiCache Redis Cluster (2 AZs)
- [ ] Criar DB Subnet Group
- [ ] Configurar Security Groups de DB
- [ ] Testar conectividade EKS â†’ RDS/Redis

**SPRINT 4: Observabilidade e SeguranÃ§a (Semana 4)**
- [ ] Habilitar CloudWatch Container Insights
- [ ] Configurar VPC Flow Logs
- [ ] Deploy de Network Policies (default deny-all)
- [ ] Instalar Prometheus + Grafana
- [ ] Configurar alertas de seguranÃ§a

**BACKLOG:**
- [ ] Avaliar criaÃ§Ã£o de 3Âª AZ (us-east-1c) para HA total
- [ ] Implementar AWS Backup para RDS e EBS
- [ ] Configurar WAF para ALB
- [ ] Deploy dos 6 domÃ­nios da plataforma (GitLab, Keycloak, etc.)

---

### DecisÃ£o #004: Marco 0 - Engenharia Reversa e Abordagem Incremental

**Data:** 2026-01-22
**Decisores:** DevOps Team + Especialista DevOps AWS
**Status:** âœ… **APROVADO E IMPLEMENTADO**

**DecisÃ£o:**
Implementar Marco 0 como baseline da infraestrutura atual usando **engenharia reversa** da VPC existente, seguido de scripts incrementais para expansÃ£o gradual.

**Contexto:**
O projeto segue um plano de execuÃ§Ã£o detalhado ([aws-console-execution-plan.md](aws-console-execution-plan.md)), mas a VPC atual (`vpc-0b1396a59c417c1f0`) jÃ¡ possui infraestrutura provisionada manualmente. Precisamos de uma estratÃ©gia para:
1. Documentar o estado atual como cÃ³digo (baseline)
2. Permitir evoluÃ§Ã£o incremental sem downtime
3. Viabilizar testes locais no WSL antes de aplicar na AWS

**Abordagem Implementada:**

#### Script 1: Engenharia Reversa (`00-marco0-reverse-engineer-vpc.sh`)

**PropÃ³sito:** Extrair configuraÃ§Ã£o atual da VPC e gerar Terraform equivalente.

**Funcionalidades:**
- âœ… ExtraÃ§Ã£o automatizada via AWS CLI de:
  - VPC (CIDR, DNS settings, tags)
  - Subnets (4 subnets em us-east-1a e us-east-1b)
  - Internet Gateway
  - NAT Gateways (2, um por AZ)
  - Route Tables (pÃºblicas e privadas)
- âœ… GeraÃ§Ã£o de mÃ³dulos Terraform modulares:
  - `modules/vpc/`
  - `modules/subnets/`
  - `modules/nat-gateways/`
  - `modules/internet-gateway/`
  - `modules/route-tables/`
- âœ… DocumentaÃ§Ã£o automÃ¡tica (JSONs brutos + README + SUMMARY)
- âœ… Outputs Terraform para integraÃ§Ã£o

**Resultado Esperado:**
```
vpc-reverse-engineered/
â”œâ”€â”€ terraform/              # CÃ³digo Terraform equivalente ao estado atual
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ outputs.tf
â”‚   â””â”€â”€ modules/
â””â”€â”€ docs/                   # DocumentaÃ§Ã£o + JSONs da AWS
    â”œâ”€â”€ vpc-raw.json
    â”œâ”€â”€ subnets-raw.json
    â”œâ”€â”€ nat-gateways-raw.json
    â”œâ”€â”€ igw-raw.json
    â”œâ”€â”€ route-tables-raw.json
    â””â”€â”€ SUMMARY.md
```

**Uso:**
```bash
cd platform-provisioning/aws/scripts
./00-marco0-reverse-engineer-vpc.sh
cd vpc-reverse-engineered/terraform
terraform init
terraform plan  # Validar equivalÃªncia com estado atual
```

#### Script 2: Incremental - Adicionar us-east-1c (`01-marco0-incremental-add-region.sh`)

**PropÃ³sito:** Adicionar 3Âª Availability Zone (us-east-1c) sem impactar recursos existentes.

**Funcionalidades:**
- âœ… CriaÃ§Ã£o de 3 novas subnets:
  - `eks-public-1c` (10.0.42.0/24) - ALB, Ingress
  - `eks-private-1c` (10.0.54.0/24) - EKS Nodes
  - `eks-db-1c` (10.0.55.0/24) - RDS, ElastiCache
- âœ… NAT Gateway opcional (variÃ¡vel `enable_nat_gateway_1c`):
  - `true`: Cria NAT dedicado (+$32/mÃªs, HA total)
  - `false`: Usa NAT de us-east-1a como fallback (economia)
- âœ… Route Tables dedicadas para us-east-1c
- âœ… Zero impacto em recursos existentes (100% incremental)
- âœ… Makefile para automaÃ§Ã£o:
  - `make plan` - Dry-run
  - `make apply-no-nat` - Aplicar sem NAT dedicado
  - `make apply-with-nat` - Aplicar com NAT dedicado
  - `make validate` - Validar recursos criados
  - `make destroy` - Rollback

**Resultado Esperado:**
```
marco0-incremental-1c/
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ outputs.tf
â”‚   â””â”€â”€ modules/
â”‚       â”œâ”€â”€ subnets-1c/
â”‚       â”œâ”€â”€ nat-gateway-1c/
â”‚       â””â”€â”€ route-tables-1c/
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â””â”€â”€ SUMMARY.md
```

**Uso:**
```bash
cd platform-provisioning/aws/scripts
./01-marco0-incremental-add-region.sh
cd marco0-incremental-1c
make init
make plan
make apply-no-nat  # OpÃ§Ã£o econÃ´mica (recomendada inicialmente)
# OU
make apply-with-nat  # HA total (+$32/mÃªs)
make validate
```

**Impacto Financeiro:**

| CenÃ¡rio | Custo Adicional | BenefÃ­cio |
|---------|-----------------|-----------|
| **Incremental SEM NAT** | $0/mÃªs | Economia, usa NAT existente |
| **Incremental COM NAT** | +$32/mÃªs | HA total, AZ independente |

**Justificativa da Abordagem:**

1. âœ… **Rastreabilidade:** Baseline documentado como cÃ³digo (IaC)
2. âœ… **SeguranÃ§a:** Zero risco de modificar recursos em produÃ§Ã£o (engenharia reversa Ã© read-only)
3. âœ… **Testabilidade:** Scripts validÃ¡veis localmente no WSL antes de aplicar
4. âœ… **Incrementalidade:** ExpansÃ£o gradual (2 AZs â†’ 3 AZs) sem downtime
5. âœ… **Economia:** OpÃ§Ã£o de usar NAT existente reduz custo inicial
6. âœ… **Flexibilidade:** Possibilidade de adicionar NAT dedicado posteriormente sem downtime

**ValidaÃ§Ã£o de Ambiente WSL:**

O ambiente WSL estÃ¡ **100% instrumentado** para execuÃ§Ã£o dos scripts:

```
âœ… AWS CLI v2.33.4 (compatÃ­vel)
âœ… Terraform v1.14.3 (latest)
âœ… kubectl v1.34.1 (latest)
âœ… Docker v29.1.3 (para testes de containers)
âœ… jq v1.7 (para parsing JSON)
âœ… git v2.43.0 (para versionamento)
âœ… curl v8.5.0 (para HTTP requests)
âœ… Credenciais AWS configuradas (regiÃ£o: us-east-1)
```

**Testes Locais PossÃ­veis:**

- âœ… `terraform plan` - Validar sintaxe e mudanÃ§as planejadas
- âœ… `terraform validate` - Validar configuraÃ§Ã£o
- âœ… Scripts Bash - Executar dry-run completo
- âœ… AWS CLI - Consultar recursos via read-only APIs
- âŒ `terraform apply` - **NÃƒO** executar em WSL (risco de criar recursos duplicados)

**Workflow Recomendado:**

```bash
# 1. WSL: Engenharia Reversa (read-only, seguro)
./00-marco0-reverse-engineer-vpc.sh
cd vpc-reverse-engineered/terraform
terraform init
terraform plan  # Validar equivalÃªncia

# 2. WSL: Preparar Incremental (validaÃ§Ã£o local)
cd ../../
./01-marco0-incremental-add-region.sh
cd marco0-incremental-1c
make init
make plan  # Revisar mudanÃ§as planejadas

# 3. AWS Console ou CI/CD: Aplicar (produÃ§Ã£o)
make apply-no-nat  # Executar APENAS em ambiente controlado
make validate      # Verificar recursos criados
```

**CondiÃ§Ãµes obrigatÃ³rias:**
- [x] Ambiente WSL instrumentado e validado
- [x] Scripts de engenharia reversa criados
- [x] Scripts incrementais criados
- [x] DocumentaÃ§Ã£o de uso completa
- [ ] ExecuÃ§Ã£o do script de engenharia reversa
- [ ] ValidaÃ§Ã£o do Terraform gerado
- [ ] ExecuÃ§Ã£o do script incremental (ambiente controlado)
- [ ] ValidaÃ§Ã£o de recursos criados na AWS

**Alternativas consideradas:**
1. **Terraform Import Manual:** Rejeitada (trabalhoso, propenso a erros, nÃ£o escalÃ¡vel)
2. **RecriaÃ§Ã£o Total da VPC:** Rejeitada (downtime, custo adicional, risco)
3. **Engenharia Reversa + Incremental (ESCOLHIDA):** Baseline + evoluÃ§Ã£o gradual

**Impacto:**
- ğŸ• Timeline: Marco 0 pronto em ~2-3 horas (execuÃ§Ã£o dos scripts)
- ğŸ’° Financeiro: $0 (engenharia reversa) + $0-32/mÃªs (incremental, conforme escolha)
- ğŸ”’ SeguranÃ§a: Risco ZERO (read-only + validaÃ§Ã£o local antes de apply)
- ğŸ—ï¸ Arquitetura: Baseline sÃ³lido para evoluÃ§Ã£o futura

**ValidaÃ§Ã£o:**
- [x] Scripts criados e validados
- [x] Ambiente WSL instrumentado
- [x] DocumentaÃ§Ã£o completa
- [ ] ExecuÃ§Ã£o bem-sucedida do script de engenharia reversa
- [ ] Terraform plan validado (equivalÃªncia com estado atual)
- [ ] ExecuÃ§Ã£o do script incremental (ambiente controlado)
- [ ] Recursos de us-east-1c criados e validados

---

## ğŸ“š ReferÃªncias

### Documentos do Projeto
- [Plano de ExecuÃ§Ã£o AWS Console](aws-console-execution-plan.md)
- [Ãndice Geral](00-indice-geral.md)
- [Infraestrutura Base AWS](01-infraestrutura-base-aws.md)

### DocumentaÃ§Ã£o AWS
- [Amazon EKS Best Practices](https://aws.github.io/aws-eks-best-practices/)
- [VPC and Subnet Sizing](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html)
- [EKS Network Requirements](https://docs.aws.amazon.com/eks/latest/userguide/network_reqs.html)
- [Security Groups for EKS](https://docs.aws.amazon.com/eks/latest/userguide/sec-group-reqs.html)

### ADRs (Architecture Decision Records)
- [ADR-001: AWS EKS como plataforma de orquestraÃ§Ã£o](../../adr/ADR-001-escolha-kubernetes-eks.md)
- [ADR-002: Kyverno como Policy Engine](../../adr/ADR-002-policy-engine-kyverno.md)

---

## ğŸ”„ Changelog

| Data | VersÃ£o | AlteraÃ§Ãµes | Autor |
|------|--------|------------|-------|
| 2026-01-22 | 1.0 | CriaÃ§Ã£o do diÃ¡rio de bordo, anÃ¡lise de VPC existente | DevOps Team |

---

**Ãšltima atualizaÃ§Ã£o:** 2026-01-22
**PrÃ³xima revisÃ£o:** ApÃ³s criaÃ§Ã£o das subnets EKS
**Mantenedor:** DevOps Team

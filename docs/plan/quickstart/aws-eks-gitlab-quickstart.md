# AWS EKS Quickstart ‚Äî GitLab, Observability e Servi√ßos B√°sicos

**√öltima atualiza√ß√£o:** 2026-01-07

Resumo executivo r√°pido para o time terceirizado: plano estrat√©gico para provisionar um ambiente AWS/EKS operacional com GitLab (h√≠brido Helm + servi√ßos gerenciados), observability (OpenTelemetry + Prometheus/Grafana/Loki/Tempo) e servi√ßos b√°sicos (RDS Postgres, Redis e RabbitMQ via Helm). A abordagem √© "clickOps r√°pido".

**Novidades nesta vers√£o:**
- ‚úÖ **Estrat√©gia de 2 ambientes (Staging + Prod)** - Ambiente Dev removido ap√≥s an√°lise de custo-benef√≠cio
- ‚úÖ Diagramas de rede e security groups adicionados (expand√≠veis)
- ‚úÖ Especifica√ß√µes t√©cnicas de node groups definidas
- ‚úÖ Helm charts principais listados com vers√µes recomendadas
- ‚úÖ Definition of Done (DoD) detalhado para cada sprint
- ‚úÖ √âpico J adicionado: Disaster Recovery Drill obrigat√≥rio no Sprint 3
- ‚úÖ Mesa t√©cnica completa para tomada de decis√£o (ver [technical-roundtable.md](technical-roundtable.md))

**Decis√µes chave**
- **Arquitetura de 2 ambientes**: Staging (testes + homologa√ß√£o) e Prod (produ√ß√£o), sem ambiente Dev dedicado para otimiza√ß√£o de custos
- Instalar GitLab via Helm (umbrella chart) em modo *hybrid*: desabilitar subcharts de DB/Redis e apontar para RDS PostgreSQL (gerenciado) e Redis via Helm; `gitlab-runner` como release separado.
- Observability: OpenTelemetry Collector (DaemonSet + Gateway) + Prometheus (kube-prometheus-stack) + Grafana + Loki + Tempo.
- Servi√ßos de dados iniciais: Amazon RDS (Postgres) Multi-AZ gerenciado, Redis (bitnami/redis) e RabbitMQ (bitnami/rabbitmq) via Helm no cluster.
- Secrets iniciais: Kubernetes Secrets (encrypted-at-rest via EBS + KMS). Vault fica para pr√≥ximo ciclo.

---

## Arquitetura da Plataforma

![Arquitetura AWS EKS GitLab Platform](diagrams/gitlab-eks-platform.svg)

**Componentes Principais:**

- **Camada de Entrada**: Internet ‚Üí Route53 ‚Üí ALB (WAF + IP Allowlist) ‚Üí EKS
- **Ambientes Segregados**:
  - **Staging (namespace staging)**: GitLab para testes, experimenta√ß√£o e homologa√ß√£o
  - **Prod (namespace prod)**: GitLab produ√ß√£o com recursos dedicados
- **Observability (namespace observability)**: OTEL Collector ‚Üí Prometheus/Loki/Tempo ‚Üí Grafana (compartilhado entre ambientes)
- **Sistema (namespace kube-system)**: AWS Load Balancer Controller, EBS CSI Driver, cert-manager, CoreDNS
- **Node Groups**: 3 grupos auto-scaling (system/workloads/critical) com inst√¢ncias t3
- **Servi√ßos Gerenciados AWS**: RDS PostgreSQL Multi-AZ (1 inst√¢ncia staging, 1 inst√¢ncia prod)
- **Storage**: S3 para backups (GitLab, Loki, Tempo) e EBS gp3 para volumes persistentes (Redis, RabbitMQ, etc)

---

**Diagramas de Rede e Seguran√ßa**

<details>
<summary><b>VPC Network Architecture (clique para expandir)</b></summary>

![VPC Network Architecture](diagrams/vpc-network-architecture.svg)

**Estrutura de Rede:**
- **VPC CIDR**: 10.0.0.0/16
- **3 Availability Zones**: us-east-1a, us-east-1b, us-east-1c
- **Subnets por AZ**:
  - Public Subnets (10.0.x.0/24): NAT Gateways, ALB
  - Private Subnets (10.0.1x.0/24): EKS Worker Nodes
  - Data Subnets (10.0.2x.0/24): RDS PostgreSQL
- **Node Groups**:
  - `system`: t3.medium (2 vCPU, 4GB RAM) - System workloads
  - `workloads`: t3.large (2 vCPU, 8GB RAM) - Application workloads
  - `critical`: t3.xlarge (4 vCPU, 16GB RAM) - GitLab, critical services
</details>

<details>
<summary><b>Security Groups & Network Flow (clique para expandir)</b></summary>

![Security Groups](diagrams/security-groups.svg)

**Regras de Seguran√ßa:**
- **ALB-SG**: Aceita HTTPS (443) apenas de IPs corporativos na allowlist + WAF
- **EKS Control Plane SG**: Comunica√ß√£o bidirecional com nodes (443, 10250)
- **EKS Nodes SG**:
  - Ingress: ALB (NodePort range 30000-32767), Control Plane (443, 10250)
  - Egress: RDS (5432), S3 (443 via Gateway)
- **Data Layer SGs**: Apenas EKS Nodes SG permitido
- **S3 Access**: Via VPC Gateway Endpoint (sem transit por Internet Gateway)
</details>

---

**Deploy Order (recomendado)**

1. Provision VPC / subnets / Route53 / IAM / EKS cluster and node groups.
2. Prepare cluster: namespaces, StorageClass (gp3 CSI), cert-manager (staging), RBAC m√≠nimo.
3. Provision gerenciados: RDS PostgreSQL, S3 backup.
4. Deploy Redis e RabbitMQ via Helm (bitnami/redis, bitnami/rabbitmq).
5. Deploy GitLab (Helm hybrid) + runners.
6. Deploy Observability (OTEL Collector ‚Üí Prometheus ‚Üí Loki ‚Üí Tempo ‚Üí Grafana).
7. Smoke tests, backups e monitoramento.

---

## Helm Charts Principais

Os seguintes Helm charts ser√£o utilizados para provisionar os componentes da plataforma:

### GitLab & CI/CD

- **gitlab/gitlab** (v7.7.x ou superior)
  - Chart umbrella com todos os componentes GitLab
  - Configura√ß√£o hybrid: desabilitar subcharts `postgresql`, `redis`, `minio`
  - Conectar a RDS, ElastiCache e S3 externos
  - Repository: `https://charts.gitlab.io/`

- **gitlab/gitlab-runner** (v0.60.x ou superior)
  - Deploy separado para runners Kubernetes
  - Executor: `kubernetes` com privileged mode (opcional para DinD)
  - Repository: `https://charts.gitlab.io/`

### Observability Stack

- **open-telemetry/opentelemetry-collector** (v0.76.x ou superior)
  - Dois deploys: DaemonSet (node collector) + Deployment (gateway)
  - Receivers: OTLP, Prometheus, Jaeger
  - Exporters: Prometheus, Loki, Tempo
  - Repository: `https://open-telemetry.github.io/opentelemetry-helm-charts`

- **prometheus-community/kube-prometheus-stack** (v55.x ou superior)
  - Inclui: Prometheus Operator, Grafana, Alertmanager, Node Exporter, Kube State Metrics
  - ServiceMonitors pr√©-configurados para componentes K8s
  - Repository: `https://prometheus-community.github.io/helm-charts`

- **grafana/loki** (v5.x ou superior)
  - Deploy: Simple Scalable mode (read/write paths separados)
  - Storage: S3 backend
  - Repository: `https://grafana.github.io/helm-charts`

- **grafana/tempo** (v1.7.x ou superior)
  - Deploy: Distributed mode
  - Storage: S3 backend
  - Repository: `https://grafana.github.io/helm-charts`

### Infraestrutura & Messaging

- **jetstack/cert-manager** (v1.13.x ou superior)
  - ACME/Let's Encrypt integration (staging inicial)
  - ClusterIssuers para HTTP01 e DNS01 challenges
  - Repository: `https://charts.jetstack.io`

- **bitnami/redis** (v18.x ou superior)
  - Deploy: Master-Replica com Sentinel (HA mode)
  - Features: Persistence habilitada (PVC), metrics para Prometheus
  - Repository: `https://charts.bitnami.com/bitnami`

- **bitnami/rabbitmq** (v12.x ou superior)
  - Deploy: StatefulSet com persistent volumes
  - Features: Management UI habilitado, metrics para Prometheus
  - Repository: `https://charts.bitnami.com/bitnami`

**Nota**: Vers√µes espec√≠ficas ser√£o definidas nos `values.yaml` de cada ambiente. Manter charts atualizados com patch versions para corre√ß√µes de seguran√ßa.

---

**√âpicos, Features e Tasks (fatiado por sprints ‚Äî 2 semanas cada)**

Nota: estimativas em person-hours para um time pequeno (1-2 engenheiros plenos). Ajuste conforme FTE.

### Sprint 1 ‚Äî Prepara√ß√£o e GitLab m√≠nimo (88h)

- √âpico A: Prepara√ß√£o do Cluster (20h)
  - Task A.1 Criar VPC multi-AZ, subnets p√∫blicas/privadas, NAT/IGW (6h)
  - Task A.2 Criar EKS cluster e 3 node groups (`system`,`workloads`,`critical`) (8h)
  - Task A.3 Criar StorageClass gp3 (CSI) e PVC templates (2h)
  - Task A.4 Configurar IAM roles/IRSA e RBAC m√≠nimo (4h)

- √âpico B: GitLab Hybrid Deploy (48h)
  - Task B.1 Criar Route53 hosted zone e ALB (6h)
  - Task B.2 Helm: preparar `values.yaml` (externalURL, storage, ingress, disable subcharts) (8h)
  - Task B.3 Instalar `gitlab` Helm chart (umbrella) apontando para RDS/Redis (12h)
  - Task B.4 Configurar S3 backups e RBAC para backup agent (6h)
  - Task B.5 Provisionar 1‚Äì2 `gitlab-runner` (k8s executor, nodeSelector `critical`) (8h)
  - Task B.6 Capturar initial root password / documentar (4h)

- √âpico C: Provisionamento de DB e Data Services (20h)
  - Task C.1 Provisionar RDS Postgres Multi-AZ (4h)
  - Task C.2 Deploy Redis via Helm chart (bitnami/redis) com HA (8h)
  - Task C.3 Deploy RabbitMQ via Helm chart (bitnami/rabbitmq) (8h)

#### Definition of Done - Sprint 1

- [ ] **Infraestrutura Base**
  - [ ] VPC criada com 3 AZs, subnets p√∫blicas/privadas/data configuradas
  - [ ] NAT Gateways (3) e Internet Gateway operacionais
  - [ ] EKS cluster (vers√£o 1.28+) provisionado e acess√≠vel via `kubectl`
  - [ ] 3 Node groups criados e nodes aparecem como `Ready` no cluster
  - [ ] StorageClass gp3 configurado como default

- [ ] **GitLab Operacional**
  - [ ] GitLab UI acess√≠vel via HTTPS no dom√≠nio configurado
  - [ ] Login com root password funcional
  - [ ] RDS Postgres conectado (verificar logs sem erros de conex√£o)
  - [ ] Redis conectado (cache funcionando)
  - [ ] Pelo menos 1 GitLab runner registrado e com status "online"
  - [ ] Criar projeto de teste e executar pipeline b√°sico (hello-world) com sucesso

- [ ] **Data Services (DB, Cache, Messaging)**
  - [ ] RDS Multi-AZ provisionado, encrypted-at-rest, backups autom√°ticos habilitados
  - [ ] Redis instalado via Helm (bitnami/redis) em modo HA (master-replica com Sentinel)
  - [ ] Redis com persistence habilitada (PVC) e replica√ß√£o funcional
  - [ ] RabbitMQ instalado via Helm chart (bitnami/rabbitmq) no cluster
  - [ ] RabbitMQ Management UI acess√≠vel e funcional
  - [ ] Credentials de acesso aos servi√ßos documentadas em Kubernetes Secrets

- [ ] **Documenta√ß√£o**
  - [ ] Diagramas as-built da VPC e Security Groups atualizados
  - [ ] Credenciais root do GitLab documentadas em local seguro
  - [ ] IDs de recursos AWS documentados (VPC ID, Subnet IDs, Security Group IDs)
  - [ ] Comandos de acesso ao cluster documentados

### Sprint 2 ‚Äî Observability baseline (84h)

- √âpico D: OTEL & Metrics (34h)
  - Task D.1 Deploy OpenTelemetry Collector (DaemonSet + Gateway) e configurar OTLP receivers (12h)
  - Task D.2 Deploy `kube-prometheus-stack` (Prometheus Operator, ServiceMonitors) (16h)
  - Task D.3 Configure Prometheus scraping & retention basic (6h)

- √âpico E: Logs & Traces (28h)
  - Task E.1 Deploy Loki (and promtail or fluent-bit) (12h)
  - Task E.2 Deploy Tempo (8h)
  - Task E.3 Wire OTEL pipelines: traces ‚Üí Tempo, logs ‚Üí Loki, metrics ‚Üí Prometheus (8h)

- √âpico F: Visualization & Alerts (22h)
  - Task F.1 Deploy Grafana, add datasources (Prometheus, Loki, Tempo) (6h)
  - Task F.2 Provision baseline dashboards (k8s health, gitlab CI, key SLIs) (10h)
  - Task F.3 Configure Alertmanager & Grafana alerts (6h)

#### Definition of Done - Sprint 2

- [ ] **M√©tricas (Prometheus)**
  - [ ] Prometheus Operator instalado e operacional
  - [ ] ServiceMonitors configurados para: kube-state-metrics, node-exporter, GitLab
  - [ ] Reten√ß√£o configurada (m√≠nimo 15 dias)
  - [ ] Prometheus UI acess√≠vel e exibindo m√©tricas de todos os nodes e pods
  - [ ] TSDB storage configurado com PVC (m√≠nimo 50GB)

- [ ] **Logs (Loki)**
  - [ ] Loki instalado em modo Simple Scalable (read/write paths)
  - [ ] Fluent-bit ou Promtail coletando logs de todos os pods
  - [ ] Logs do GitLab vis√≠veis no Loki
  - [ ] Reten√ß√£o configurada (m√≠nimo 30 dias)
  - [ ] S3 backend configurado para chunks

- [ ] **Traces (Tempo)**
  - [ ] Tempo instalado em modo distribu√≠do
  - [ ] OTLP receiver configurado e acess√≠vel
  - [ ] S3 backend configurado para traces
  - [ ] Sample trace manual enviado e visualizado com sucesso

- [ ] **OpenTelemetry Collector**
  - [ ] DaemonSet collector rodando em todos os nodes
  - [ ] Gateway collector recebendo e roteando telemetria
  - [ ] Pipelines configurados: metrics ‚Üí Prometheus, logs ‚Üí Loki, traces ‚Üí Tempo
  - [ ] Health check endpoints respondendo

- [ ] **Visualiza√ß√£o (Grafana)**
  - [ ] Grafana acess√≠vel via HTTPS
  - [ ] Datasources configurados: Prometheus, Loki, Tempo (todos com status "success")
  - [ ] Dashboards instalados:
    - [ ] Kubernetes Cluster Monitoring
    - [ ] Node Exporter Full
    - [ ] GitLab CI Pipeline Metrics
    - [ ] Pod/Container Resources
  - [ ] Alertmanager configurado com pelo menos 3 alertas cr√≠ticos:
    - [ ] Node down
    - [ ] Pod CrashLooping
    - [ ] PVC usage > 80%

- [ ] **Valida√ß√£o End-to-End**
  - [ ] Deploy de aplica√ß√£o de teste gerando m√©tricas, logs e traces vis√≠veis em Grafana
  - [ ] Correla√ß√£o funcional: clicar em trace leva aos logs correspondentes

### Sprint 3 ‚Äî Hardening, Network & Smoke Tests (80h)

- √âpico G: Network & Security (30h)
  - Task G.1 Security Groups: restrict DB/ElastiCache access to EKS SGs (8h)
  - Task G.2 ALB WAF / IP allowlist / basic VPN (client) plan (8h)
  - Task G.3 Implement minimal NetworkPolicies `deny-all` + opens for pods (14h)

- √âpico H: RBAC & Backups (24h)
  - Task H.1 RBAC least-privilege for critical SAs (12h)
  - Task H.2 Validate backups to S3 and restore test (12h)

- √âpico I: Smoke & End-to-end (26h)
  - Task I.1 CI pipeline smoke test com aplica√ß√£o exemplo (12h)
  - Task I.2 Kong/Ingress/Keycloak basic flow smoke (if present) (8h)
  - Task I.3 Remediations and hotfixes (6h)

- √âpico J: Disaster Recovery Drill (10h)
  - Task J.1 Documentar procedimentos de backup e restore (3h)
  - Task J.2 Simular falha de RDS e restore de snapshot (3h)
  - Task J.3 Simular perda de namespace GitLab e restore completo (4h)

#### Definition of Done - Sprint 3

- [ ] **Seguran√ßa de Rede**
  - [ ] Security Groups revisados e restritos:
    - [ ] RDS aceita apenas conex√µes de EKS Nodes SG (porta 5432)
  - [ ] ALB WAF configurado com OWASP rules habilitadas
  - [ ] IP allowlist configurada no ALB (lista de IPs corporativos documentada)
  - [ ] NetworkPolicies implementadas:
    - [ ] Default deny-all em namespaces cr√≠ticos (gitlab, observability)
    - [ ] Policies espec√≠ficas para permitir comunica√ß√£o necess√°ria
    - [ ] Valida√ß√£o: tentar acessar pod sem policy resulta em timeout

- [ ] **RBAC & Acesso**
  - [ ] ServiceAccounts espec√≠ficos para cada componente (n√£o usar default)
  - [ ] Roles/RoleBindings configurados com princ√≠pio de least-privilege
  - [ ] IRSA configurado para pods que acessam S3/RDS
  - [ ] Valida√ß√£o: pods n√£o conseguem acessar recursos sem permiss√£o

- [ ] **Backups & Restore**
  - [ ] Backup autom√°tico do GitLab para S3 configurado (di√°rio)
  - [ ] Snapshots autom√°ticos RDS configurados (reten√ß√£o 7 dias)
  - [ ] Velero (ou similar) instalado para backup de recursos K8s
  - [ ] **Teste de restore realizado com sucesso**:
    - [ ] RDS restaurado de snapshot em < 30 minutos
    - [ ] GitLab namespace restaurado e aplica√ß√£o funcional
    - [ ] Dados de teste verificados ap√≥s restore

- [ ] **Smoke Tests & Valida√ß√£o**
  - [ ] Pipeline CI completo funcional com aplica√ß√£o de exemplo (app Python FastAPI com Postgres/Redis/RabbitMQ)
  - [ ] M√©tricas, logs e traces da pipeline vis√≠veis em Grafana
  - [ ] Alertas testados (simular condi√ß√µes de alerta e verificar notifica√ß√µes)

- [ ] **Disaster Recovery Drill** üî¥
  - [ ] Runbook de DR documentado com step-by-step procedures
  - [ ] Simula√ß√£o de falha catastr√≥fica executada:
    - [ ] Cen√°rio 1: Falha de RDS ‚Üí restore de snapshot ‚Üí GitLab funcional
    - [ ] Cen√°rio 2: Delete acidental de namespace ‚Üí restore via Velero ‚Üí dados recuperados
    - [ ] Cen√°rio 3: Perda de n√≥ cr√≠tico ‚Üí validar HA e redistribui√ß√£o de workloads
  - [ ] Tempos de recupera√ß√£o (RTO/RPO) medidos e documentados:
    - [ ] RTO GitLab: < 1 hora
    - [ ] RPO GitLab: < 24 horas
  - [ ] Li√ß√µes aprendidas documentadas e melhorias identificadas

- [ ] **Documenta√ß√£o & Handoff**
  - [ ] Runbooks operacionais criados:
    - [ ] Como acessar o cluster
    - [ ] Como fazer backup manual
    - [ ] Como fazer restore
    - [ ] Troubleshooting comum (pods CrashLooping, PVC full, etc)
  - [ ] Diagramas as-built finais
  - [ ] Invent√°rio completo de recursos AWS (IDs, custos estimados)
  - [ ] Lista de credenciais e secrets (em local seguro)
  - [ ] Sess√£o de knowledge transfer realizada com time interno

---

## Resumo de Estimativas

| Sprint | √âpicos | Horas Estimadas |
|--------|--------|-----------------|
| Sprint 1 | A: Prepara√ß√£o Cluster (20h)<br>B: GitLab Deploy (48h)<br>C: DB e Data Services (20h) | **88h** |
| Sprint 2 | D: OTEL & Metrics (34h)<br>E: Logs & Traces (28h)<br>F: Visualization (22h) | **84h** |
| Sprint 3 | G: Network & Security (30h)<br>H: RBAC & Backups (24h)<br>I: Smoke Tests (26h)<br>J: DR Drill (10h) | **90h** |
| **TOTAL** | **10 √âpicos** | **262 person-hours** |

**Equival√™ncia em dias √∫teis**: 262h √∑ 8h/dia = **~33 dias** para 1 engenheiro ou **~17 dias** para 2 engenheiros trabalhando em paralelo.

---

## Estimativa de Custos (2 Ambientes: Staging + Prod)

**‚ö†Ô∏è Nota sobre custos:** Valores baseados em cota√ß√£o USD‚ÜíBRL R$ 6,00 (jan/2026), regi√£o us-east-1, modelo on-demand. Varia√ß√£o esperada: ¬±10-15% devido a flutua√ß√£o cambial e ajustes de pre√ßos AWS. Detalhes completos em [cost-assumptions.md](cost-assumptions.md).

---

### Estrat√©gia Adotada: Staging com Automa√ß√£o Start/Stop

**Contexto:** Como o time de desenvolvimento trabalha em **hor√°rio comercial** (seg-sex, 8h-18h, conforme estimativas de 262 person-hours), o ambiente Staging ser√° configurado para **desligar automaticamente fora desse per√≠odo**, gerando economia significativa sem impactar a produtividade.

---

### Staging (Testes + Homologa√ß√£o) - 50h/semana

**Schedule:** Segunda a sexta, 8h-18h (desliga automaticamente √† noite e finais de semana)

- EKS Control Plane (compartilhado): $73/m√™s √∑ 2 = ~$37/m√™s (rateio)
- 2 EC2 nodes t3.medium (50h/semana): ~$18/m√™s
- RDS db.t3.small Multi-AZ (auto-pause): ~$30/m√™s
- Redis (bitnami/redis) - scaled to 0 fora hor√°rio: ~$8/m√™s
- RabbitMQ (bitnami/rabbitmq) - scaled to 0 fora hor√°rio: ~$7/m√™s
- EBS volumes (50GB) + S3 backups: ~$12/m√™s
- **SUBTOTAL STAGING**: ~$112/m√™s USD (~**R$ 672/m√™s**)

**Economia vs Staging 24/7:** R$ 450/m√™s (R$ 5.400/ano)

---

### Prod (Produ√ß√£o) - 24/7 Alta Disponibilidade

**Opera√ß√£o cont√≠nua (24/7):**
- EKS Control Plane (compartilhado): $73/m√™s √∑ 2 = ~$37/m√™s (rateio)
- 3 EC2 nodes t3.large (24/7, 3 AZs): ~$180/m√™s
- RDS db.t3.medium Multi-AZ (24/7): ~$120/m√™s
- Redis (bitnami/redis) HA com Sentinel: ~$30/m√™s
- RabbitMQ (bitnami/rabbitmq) cluster: ~$30/m√™s
- EBS volumes (100GB) + S3 backups + replication: ~$40/m√™s
- ALB + WAF: ~$30/m√™s
- **SUBTOTAL PROD**: ~$467/m√™s USD (~**R$ 2.802/m√™s**)

---

### Observability (Compartilhada entre Staging e Prod)

- Prometheus + Grafana + Loki + Tempo: Roda nos nodes existentes
- Storage adicional (m√©tricas/logs): ~$25/m√™s
- **SUBTOTAL OBSERVABILITY**: ~$25/m√™s USD (~**R$ 150/m√™s**)

---

### Total Consolidado (Estrat√©gia Adotada)

| Componente | Staging (scheduled) | Prod (24/7) | Observability | **TOTAL** |
|------------|---------------------|-------------|---------------|-----------|
| **Custo Mensal (USD)** | $112 | $467 | $25 | **$604** |
| **Custo Mensal (BRL)** | R$ 672 | R$ 2.802 | R$ 150 | **R$ 3.624** |
| **Custo Anual (BRL)** | R$ 8.064 | R$ 33.624 | R$ 1.800 | **R$ 43.488** |

---

### Comparativo: Estrat√©gias de Custo

| Cen√°rio | Custo Mensal | Custo Anual | Economia |
|---------|--------------|-------------|----------|
| **3 Ambientes (Dev + Staging + Prod, todos 24/7)** | R$ 5.100 | R$ 61.200 | Baseline |
| **2 Ambientes sem otimiza√ß√£o (Staging 24/7 + Prod)** | R$ 4.074 | R$ 48.888 | -20% (-R$ 12.312/ano) |
| **2 Ambientes ADOTADO (Staging scheduled + Prod)** | **R$ 3.624** | **R$ 43.488** | **-29% (-R$ 17.712/ano)** |

**Decis√µes arquiteturais:**
1. **2 ambientes vs 3:** Staging assume papel dual (dev + homologa√ß√£o), eliminando ambiente Dev dedicado
2. **Automa√ß√£o de custo:** Staging desliga automaticamente fora do hor√°rio comercial (compat√≠vel com modelo de trabalho do time interno)

---

### Implementa√ß√£o da Automa√ß√£o Start/Stop

**Ferramenta:** AWS EventBridge + Lambda functions
**Esfor√ßo:** ~2 horas (Sprint 3 ou posterior)
**Schedule:**
- **Start:** Segunda a sexta, 8h (BRT)
- **Stop:** Segunda a sexta, 18h (BRT)
- **Finais de semana:** Desligado

**Recursos afetados:**
- EC2 instances (stop/start)
- RDS (stop-db-instance/start-db-instance)
- Pods K8s (scale to 0 / scale up)

**Dados preservados:** 100% dos dados mantidos em volumes persistentes (EBS, S3)

**Tempo de inicializa√ß√£o:** ~10-15 minutos (cold start pela manh√£)

---

### Notas Importantes

**Varia√ß√µes esperadas:**
- ¬±10-15% devido a flutua√ß√£o cambial USD/BRL
- ¬±2-5% anual por ajustes de pre√ßos AWS
- Data transfer out n√£o inclu√≠do (estimado +5-10% do custo total)

**Gest√£o financeira:**
- Configurar AWS Budgets com alerta em R$ 4.000/m√™s
- Monitorar AWS Cost Explorer semanalmente (primeiros 2 meses)
- Revisar custos reais vs projetados mensalmente

**Otimiza√ß√µes futuras (Ano 2+):**
- Savings Plans (1 ano): -20% EC2/RDS ‚Üí economia adicional ~R$ 5.000/ano
- Reserved Instances (3 anos): -40% EC2/RDS ‚Üí economia adicional ~R$ 10.000/ano

## Observa√ß√µes

**Arquitetura de 2 Ambientes:**
- **Staging**: Ambiente para testes, experimenta√ß√£o, valida√ß√£o e homologa√ß√£o. Developers podem testar aqui antes de prod.
- **Prod**: Ambiente de produ√ß√£o com recursos dedicados e alta disponibilidade (Multi-AZ).
- **Sem Dev dedicado**: Decis√£o baseada em an√°lise custo-benef√≠cio (ver [technical-roundtable.md](technical-roundtable.md)). Staging assume papel de dev+homologa√ß√£o.

**Uso do Ambiente Staging:**
- Testes de novas features e integra√ß√µes
- POCs e experimenta√ß√µes (novos charts, vers√µes, configura√ß√µes)
- Valida√ß√£o de upgrades antes de aplicar em prod
- Troubleshooting de bugs reportados em prod
- Treinamento de novos membros do time
- Smoke tests antes de promo√ß√£o para prod

**Schedule de Opera√ß√£o Staging:**
- **Hor√°rio ativo:** Segunda a sexta, 8h-18h (hor√°rio comercial do time)
- **Automa√ß√£o:** Desligamento autom√°tico √†s 18h, inicializa√ß√£o √†s 8h via AWS EventBridge + Lambda
- **Tempo de cold start:** ~10-15 minutos pela manh√£ (aceit√°vel para modelo de trabalho do time)
- **Dados preservados:** 100% dos dados mantidos em volumes persistentes durante desligamento

**Isolamento entre Ambientes:**
- Namespaces Kubernetes segregados (`staging` e `prod`)
- RDS PostgreSQL separados (1 inst√¢ncia por ambiente)
- Redis e RabbitMQ isolados por namespace
- RBAC: acesso controlado por ambiente
- Network Policies: staging n√£o acessa prod diretamente

**Backups e Persist√™ncia:**
- RDS PostgreSQL: backups autom√°ticos gerenciados pela AWS (snapshots di√°rios, reten√ß√£o 7 dias).
- Redis: dados persistidos em PVC (EBS gp3). Backups via Velero (snapshot de PVCs) ou redis-cli BGSAVE + c√≥pia para S3.
- RabbitMQ: dados persistidos em PVC (EBS gp3). Backups de defini√ß√µes (exchanges, queues) via Management API + Velero para PVCs.
- GitLab: backup completo para S3 via GitLab backup task (inclui repositories, DB, uploads).

**Processo:**
- Estimativas para 1‚Äì2 engenheiros; paralelizar reduz calendar time.
- Integra√ß√£o Microsoft Entra ID: fase posterior. Inicialmente, utilizar usu√°rios locais no GitLab com e-mails corporativos corretos para rastreabilidade e auditoria. Acesso restringido por allowlist de IPs no ALB e WAF. Preparar estrutura OIDC/SAML, grupos de seguran√ßa e mapeamento de permiss√µes para futura integra√ß√£o com Entra ID, mantendo sincroniza√ß√£o de e-mails corporativos e controle de acesso baseado em dom√≠nios Microsoft.

**Riscos e Mitiga√ß√µes:**
- Risco: exposi√ß√£o p√∫blica do GitLab ‚Üí Mitigante: ALB + IP allowlist + WAF + for√ßar 2FA; adiar AD integration.
- Risco: backups/restore n√£o testados ‚Üí Mitigante: testar restaura√ß√£o em staging antes do cutover.
- Risco: performance de GitLab sob-resourced ‚Üí Mitigante: usar node group `critical`, monitorar e ajustar recursos/scale.
- **Risco: varia√ß√£o cambial (USD/BRL)** ‚Üí Mitigante: AWS Budgets com alertas (R$ 4.000/m√™s), revis√£o mensal de custos, considerar hedge cambial se necess√°rio.
- **Risco: ajuste de pre√ßos AWS** ‚Üí Mitigante: monitorar AWS Price List API, assinatura de notifica√ß√µes de mudan√ßas de pre√ßo.

## Entreg√°veis

Ao final dos 3 sprints, os seguintes entreg√°veis devem estar prontos:

### Infraestrutura

- ‚úÖ VPC multi-AZ configurada (VPC/Subnets/NAT/IGW/Security Groups)
- ‚úÖ EKS cluster operacional com 3 node groups
- ‚úÖ StorageClass gp3 configurado
- ‚úÖ RDS PostgreSQL Multi-AZ
- ‚úÖ Redis (via Helm - bitnami/redis HA)
- ‚úÖ RabbitMQ (via Helm - bitnami/rabbitmq)
- ‚úÖ S3 buckets para backups e artifacts

### Aplica√ß√µes

- ‚úÖ GitLab CE instalado via Helm (hybrid mode)
- ‚úÖ GitLab Runners funcionais (m√≠nimo 1)
- ‚úÖ Redis com HA (master-replica + Sentinel)
- ‚úÖ RabbitMQ com Management UI
- ‚úÖ OpenTelemetry Collector (DaemonSet + Gateway)
- ‚úÖ Prometheus + Alertmanager
- ‚úÖ Grafana com dashboards baseline
- ‚úÖ Loki para agrega√ß√£o de logs
- ‚úÖ Tempo para distributed tracing

### Seguran√ßa & Compliance

- ‚úÖ WAF configurado no ALB
- ‚úÖ IP allowlist implementada
- ‚úÖ NetworkPolicies aplicadas
- ‚úÖ RBAC com least-privilege
- ‚úÖ Encryption-at-rest em todos os servi√ßos de dados
- ‚úÖ Backups autom√°ticos configurados

### Documenta√ß√£o

- ‚úÖ Runbooks operacionais
- ‚úÖ Diagramas as-built (VPC, Security Groups, Arquitetura)
- ‚úÖ Procedimentos de DR testados
- ‚úÖ Invent√°rio de recursos AWS
- ‚úÖ Knowledge transfer realizado

---

## Pr√≥ximos Passos (Fora do Escopo - Fases Futuras)

Os seguintes itens **N√ÉO** fazem parte deste quickstart e ser√£o abordados em fases posteriores:

1. **Integra√ß√£o Microsoft Entra ID (Azure AD)**
   - OIDC/SAML configuration
   - Group sync e RBAC mapping

2. **Platform Core (Kong + Keycloak + Linkerd)**
   - Service Mesh completo
   - API Gateway centralizado
   - Identity Provider pr√≥prio

3. **Secrets Management (HashiCorp Vault)**
   - Dynamic secrets
   - Rota√ß√£o autom√°tica

4. **Advanced Security (Kyverno + Falco)**
   - Policy as Code
   - Runtime threat detection

5. **Data Services (PostgreSQL HA Operator, RabbitMQ Operator)**
   - Migra√ß√£o de managed services para operators K8s
   - True cloud-agnostic data layer

6. **Backstage Developer Portal**
   - Self-service templates
   - Service catalog

---

## Estrat√©gia de Evolu√ß√£o

Este quickstart foi projetado com **funda√ß√µes arquiteturais corretas** que permitem crescimento exponencial sem necessidade de refatora√ß√£o brutal.

Para entender o roadmap completo de evolu√ß√£o (5 fases de maturidade, custos projetados, gatekeepers de transi√ß√£o, e exemplos pr√°ticos), consulte:

**üìò [Estrat√©gia de Evolu√ß√£o Completa](evolution-strategy.md)**

O documento de evolu√ß√£o detalha:
- Roadmap de crescimento: Do ambiente √∫nico at√© Platform Engineering completo
- Tabela comparativa de maturidade por fase
- Custos evolutivos (AWS)
- Decis√µes de arquitetura evolutivas (namespaces, RBAC, network policies, Helm)
- Mapeamento de conformidade com ADRs
- Checklists de valida√ß√£o por fase

---

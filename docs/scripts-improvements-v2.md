# Scripts Operacionais v2.0 - Li√ß√µes Aprendidas Implementadas

**Data:** 2026-01-27
**Sess√£o:** Continua√ß√£o ap√≥s compaction
**Objetivo:** Incorporar todas as li√ß√µes aprendidas durante deployment Marco 1 e Marco 2

---

## üìã Resumo Executivo

Ap√≥s enfrentarmos diversos desafios durante o deployment inicial (token expiration, PVCs stuck, EBS CSI permissions, Helm release conflicts), todos os scripts operacionais foram melhorados com valida√ß√µes proativas e automa√ß√£o para prevenir esses problemas em futuros deployments.

### ‚úÖ Status Atual
- **Marco 1:** Completo e operacional (Cluster EKS + 7 nodes + 4 add-ons)
- **Marco 2:** Completo e operacional (Prometheus + Grafana + Loki + Fluent Bit)
- **Scripts:** Todos atualizados para v2.0 com li√ß√µes aprendidas

---

## üöÄ Script: startup-cluster-v2.sh

**Arquivo:** `platform-provisioning/aws/kubernetes/terraform/envs/marco1/scripts/startup-cluster-v2.sh`

### Melhorias Implementadas

#### 1. Configura√ß√£o Autom√°tica EBS CSI Driver IAM Role
**Problema Original:**
- PVCs ficavam stuck em Pending
- Erro: "failed to provision volume: get credentials: no EC2 IMDS role found"

**Solu√ß√£o Implementada:**
```bash
configure_ebs_csi_driver() {
    # Cria IAM Role via eksctl se n√£o existir
    eksctl create iamserviceaccount \
        --name ebs-csi-controller-sa \
        --role-name AmazonEKS_EBS_CSI_DriverRole \
        --attach-policy-arn arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy

    # Atualiza add-on com service account role
    aws eks update-addon --addon-name aws-ebs-csi-driver \
        --service-account-role-arn $role_arn

    # Reinicia pods para aplicar novo IAM role
    kubectl rollout restart deployment ebs-csi-controller -n kube-system
}
```

**Benef√≠cio:** PVCs s√£o provisionados automaticamente sem interven√ß√£o manual.

---

#### 2. Cria√ß√£o Autom√°tica StorageClass gp3
**Problema Original:**
- StorageClass gp3 n√£o existia (apenas gp2 default)
- M√≥dulos Terraform configurados para gp3, causando PVCs Pending

**Solu√ß√£o Implementada:**
```bash
create_storageclass_gp3() {
    # Remove default da gp2
    kubectl annotate storageclass gp2 storageclass.kubernetes.io/is-default-class=false

    # Cria StorageClass gp3 como default
    kubectl apply -f - <<EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: gp3
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: ebs.csi.aws.com
parameters:
  type: gp3
  encrypted: "true"
volumeBindingMode: WaitForFirstConsumer
EOF
}
```

**Benef√≠cio:** gp3 (mais barato e perform√°tico) √© configurado automaticamente como default.

---

#### 3. Valida√ß√£o providers.tf do Marco 2
**Problema Original:**
- Token est√°tico do Kubernetes provider expirava ap√≥s ~15 minutos
- Deployments longos (Prometheus) falhavam com "server has asked for credentials"

**Solu√ß√£o Implementada:**
```bash
validate_marco2_providers() {
    # Verifica se providers.tf usa exec token din√¢mico
    if grep -q "exec {" "$providers_file" && grep -q "get-token" "$providers_file"; then
        log_success "providers.tf usa exec token (correto)"
    else
        log_warning "providers.tf N√ÉO usa exec token"
        log_warning "Deployments longos podem falhar com token expirado"
    fi
}
```

**Arquivo corrigido:** `platform-provisioning/aws/kubernetes/terraform/envs/marco2/providers.tf`
```hcl
provider "kubernetes" {
  exec {
    api_version = "client.authentication.k8s.io/v1beta1"
    command     = "aws"
    args = ["eks", "get-token", "--cluster-name", var.cluster_name]
  }
}
```

**Benef√≠cio:** Tokens s√£o renovados automaticamente durante deployments longos.

---

#### 4. Aguardar Cluster Completamente Pronto
**Problema Original:**
- Script tentava configurar recursos antes do cluster estar pronto
- Nodes e pods ainda iniciando causavam falhas nas valida√ß√µes

**Solu√ß√£o Implementada:**
```bash
wait_cluster_ready() {
    # Aguarda todos os 7 nodes ficarem Ready (timeout: 5min)
    while [ $attempt -lt 30 ]; do
        ready_nodes=$(kubectl get nodes --no-headers | grep -c " Ready ")
        if [ "$ready_nodes" -eq 7 ]; then break; fi
        sleep 10
    done

    # Aguarda 90% dos pods kube-system ficarem Running (timeout: 3min)
    while [ $attempt -lt 18 ]; do
        percentage=$((running_pods * 100 / total_pods))
        if [ $percentage -ge 90 ]; then break; fi
        sleep 10
    done
}
```

**Benef√≠cio:** Cluster √© validado antes de prosseguir com configura√ß√µes.

---

#### 5. Import Autom√°tico de Recursos Existentes
**Problema Original:**
- Terraform tentava criar recursos que j√° existiam na AWS
- KMS Alias causava erro "already exists"
- Cluster existente era marcado para replacement

**Solu√ß√£o Implementada:**
```bash
import_existing_resources() {
    # Detecta cluster EKS existente
    cluster_exists=$(aws eks describe-cluster --name k8s-platform-prod)

    if [ -n "$cluster_exists" ]; then
        # Importa para Terraform state se n√£o estiver
        if ! terraform state list | grep -q "aws_eks_cluster.main"; then
            terraform import aws_eks_cluster.main k8s-platform-prod
        fi
    fi

    # Mesmo para KMS Alias
    if aws kms list-aliases | grep -q "k8s-platform-prod-eks-secrets"; then
        terraform import aws_kms_alias.eks alias/k8s-platform-prod-eks-secrets
    fi
}
```

**Benef√≠cio:** Evita conflitos e replacement desnecess√°rio de recursos.

---

### Resumo Li√ß√µes Aprendidas - startup-cluster-v2.sh
```
‚úÖ EBS CSI Driver configurado com IAM Role (previne erro de credentials)
‚úÖ StorageClass gp3 criado (previne PVCs Pending)
‚úÖ Valida√ß√£o de providers.tf do Marco 2 (previne timeout de token)
‚úÖ Cluster aguarda todos os nodes Ready antes de prosseguir
‚úÖ Import autom√°tico de recursos existentes
```

---

## üõë Script: shutdown-cluster.sh (v2.0)

**Arquivo:** `platform-provisioning/aws/kubernetes/terraform/envs/marco1/scripts/shutdown-cluster.sh`

### Melhorias Implementadas

#### 1. Op√ß√£o de Economia Parcial
**Nova Funcionalidade:**
```bash
./shutdown-cluster.sh                # Destrui√ß√£o completa (economia: 100%)
./shutdown-cluster.sh --keep-cluster # Apenas nodes (economia: ~70%)
```

**Modo Keep-Cluster:**
- Mant√©m: Cluster EKS (Control Plane), Add-ons, Security Groups, KMS Key
- Destr√≥i: Apenas os 7 nodes EC2
- Economia: ~70% (de $0.86/hora para $0.10/hora)
- Benef√≠cio: Startup mais r√°pido no dia seguinte (~5min vs ~15min)

---

#### 2. Limpeza IAM Role do EBS CSI Driver
**Problema Original:**
- IAM Role criado via eksctl n√£o era removido pelo Terraform
- Roles √≥rf√£os acumulavam na conta

**Solu√ß√£o Implementada:**
```bash
cleanup_ebs_csi_iam_role() {
    # Remove service account via eksctl (remove role e policies)
    eksctl delete iamserviceaccount \
        --name ebs-csi-controller-sa \
        --cluster k8s-platform-prod
}
```

**Benef√≠cio:** Cleanup completo de todos os recursos criados.

---

#### 3. Retry Logic
**Nova Funcionalidade:**
```bash
# Primeira tentativa
terraform destroy -auto-approve

# Se falhar, limpa locks e tenta novamente
if [ $? -ne 0 ]; then
    clean_terraform_locks
    terraform destroy -auto-approve  # Tentativa 2/2
fi
```

**Benef√≠cio:** Maior resili√™ncia a locks inesperados.

---

#### 4. Backup Autom√°tico do State
**Funcionalidade Melhorada:**
```bash
BACKUP_DIR="$HOME/.terraform-backups/marco1"
terraform state pull > "$BACKUP_DIR/terraform.tfstate.backup.$TIMESTAMP"
```

**Benef√≠cio:** Recupera√ß√£o poss√≠vel em caso de falha no destroy.

---

## üìä Script: status-cluster.sh (v2.0)

**Arquivo:** `platform-provisioning/aws/kubernetes/terraform/envs/marco1/scripts/status-cluster.sh`

### Melhorias Implementadas

#### 1. Modo Detalhado
```bash
./status-cluster.sh            # Valida√ß√£o b√°sica (Marco 1)
./status-cluster.sh --detailed # Valida√ß√£o completa (Marco 1 + Marco 2)
```

---

#### 2. Valida√ß√£o Completa Marco 2
**Verifica√ß√µes Implementadas:**
- ‚úÖ Namespace monitoring existe
- ‚úÖ Pods monitoring (32/32 Running)
- ‚úÖ Helm releases (kube-prometheus-stack, loki, fluent-bit)
- ‚úÖ Servi√ßos cr√≠ticos (Prometheus, Grafana, Loki, Fluent Bit)
- ‚úÖ DaemonSet Fluent Bit em todos os nodes (7/7)

---

#### 3. Valida√ß√£o Pr√©-requisitos
**Checks Autom√°ticos:**
```
‚úÖ StorageClass gp3 existe
‚úÖ EBS CSI Driver tem IAM Role configurado
‚úÖ Marco 2 providers.tf usa exec token
```

---

#### 4. Recomenda√ß√µes Inteligentes de Pr√≥ximas A√ß√µes
**Baseado no Estado Atual:**

**Se Marco 1 incompleto:**
```
‚ö†Ô∏è  Marco 1 INCOMPLETO - Execute os passos de corre√ß√£o
1. cd scripts && ./startup-cluster-v2.sh
```

**Se Marco 1 completo, Marco 2 pendente:**
```
‚úÖ Marco 1 COMPLETO - Pronto para Marco 2!
Pr√≥ximo passo: Deploy Observability Stack
1. cd ../marco2 && terraform apply
```

**Se ambos completos:**
```
‚úÖ Marco 1 e Marco 2 COMPLETOS!
Pr√≥ximos passos:
1. Acessar Grafana: kubectl port-forward svc/kube-prometheus-stack-grafana 3000:80
2. Consultar logs no Loki via Grafana
3. Iniciar Marco 3 (Data Services)
```

---

## üìà Outras Corre√ß√µes Importantes

### 1. Terraform main.tf - bootstrap_self_managed_addons
**Arquivo:** `platform-provisioning/aws/kubernetes/terraform/envs/marco1/main.tf`

**Problema:**
- Cluster importado tinha `bootstrap_self_managed_addons = false` (AWS default)
- C√≥digo Terraform tinha implicitamente `true`
- Terraform planejava replacement do cluster

**Corre√ß√£o:**
```hcl
resource "aws_eks_cluster" "main" {
  name     = var.cluster_name
  version  = var.cluster_version
  role_arn = var.eks_cluster_role_arn

  # IMPORTANTE: Evita replace ao importar clusters existentes
  bootstrap_self_managed_addons = false

  # ... resto da config
}
```

---

### 2. Loki S3 Bucket - Lifecycle Protection
**Arquivo:** `platform-provisioning/aws/kubernetes/terraform/envs/marco2/modules/loki/main.tf`

**Prote√ß√£o Implementada:**
```hcl
resource "aws_s3_bucket" "loki" {
  bucket = local.s3_bucket_name

  # IMPORTANTE: Proteger bucket contra dele√ß√£o acidental
  lifecycle {
    prevent_destroy = true
    ignore_changes = [bucket]
  }
}
```

**Benef√≠cio:** Logs hist√≥ricos protegidos contra `terraform destroy` acidental.

---

### 3. Helm Timeout - kube-prometheus-stack
**Arquivo:** `platform-provisioning/aws/kubernetes/terraform/envs/marco2/modules/kube-prometheus-stack/main.tf`

**Problema:**
- Timeout padr√£o de 600s (10min) insuficiente
- Deploy falhava durante cria√ß√£o de CRDs

**Corre√ß√£o:**
```hcl
resource "helm_release" "kube_prometheus_stack" {
  # ... config

  # Timeout aumentado para 30 minutos (primeira instala√ß√£o)
  timeout = 1800
}
```

**Benef√≠cio:** Deploy completo sem timeouts.

---

## üìä M√©tricas de Sucesso

### Antes (v1.0)
- ‚ùå 5 tentativas de startup falharam
- ‚ùå PVCs stuck em Pending (sem StorageClass gp3)
- ‚ùå EBS CSI Driver sem permissions
- ‚ùå Token expirado durante deploy Prometheus
- ‚ùå Helm release conflicts

### Depois (v2.0)
- ‚úÖ Startup completo em 1 tentativa
- ‚úÖ Todos os pr√©-requisitos configurados automaticamente
- ‚úÖ Marco 2 deployed com sucesso (32/32 pods Running)
- ‚úÖ Zero interven√ß√£o manual necess√°ria
- ‚úÖ Scripts robustos e prontos para uso di√°rio

---

## üéØ Pr√≥ximos Passos Recomendados

### 1. Validar Grafana e Loki
```bash
# Acessar Grafana
kubectl port-forward -n monitoring svc/kube-prometheus-stack-grafana 3000:80

# URL: http://localhost:3000
# User: admin
# Password: K8sPlatform2026!

# Consultar logs no Loki
# Grafana > Explore > DataSource: Loki
# Query: {namespace="kube-system"}
```

### 2. Marco 3 - Data Services (Pendente)
- PostgreSQL Operator (CloudNativePG)
- Redis Operator
- RabbitMQ Operator

### 3. Opera√ß√£o Di√°ria
```bash
# Manh√£ - Ligar cluster
cd platform-provisioning/aws/kubernetes/terraform/envs/marco1/scripts
./startup-cluster-v2.sh

# Validar status
./status-cluster.sh --detailed

# Fim do dia - Desligar cluster
./shutdown-cluster.sh                # Destrui√ß√£o completa (economia: $18.37/dia)
./shutdown-cluster.sh --keep-cluster # Parcial (economia: $12.76/dia)
```

---

## üìù Conclus√£o

Todos os scripts operacionais foram significativamente melhorados com base nas li√ß√µes aprendidas durante esta sess√£o. As melhorias implementadas garantem:

1. **Automa√ß√£o Total:** Zero interven√ß√£o manual para configura√ß√µes cr√≠ticas
2. **Preven√ß√£o Proativa:** Valida√ß√µes impedem problemas antes que ocorram
3. **Resili√™ncia:** Retry logic e tratamento de erros robusto
4. **Observabilidade:** Status detalhado e recomenda√ß√µes inteligentes
5. **Economia:** Op√ß√µes flex√≠veis de shutdown para otimizar custos

**Status Final:**
- ‚úÖ Marco 1: Completo e validado
- ‚úÖ Marco 2: Completo e operacional
- ‚úÖ Scripts v2.0: Prontos para uso em produ√ß√£o
- ‚úÖ Documenta√ß√£o: Atualizada com todas as li√ß√µes aprendidas

**Custo Atual:** $0.86/hora (~$625/m√™s) com cluster ativo
**Economia com Shutdown:** $18.37/dia (100%) ou $12.76/dia (70%)
